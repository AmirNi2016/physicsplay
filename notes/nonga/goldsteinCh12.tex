\documentclass{article}

\input{../peeters_macros.tex}
\newcommand{\Brho}[0]{\boldsymbol{\rho}}
\newcommand{\LL}[0]{\mathcal{L}}
\newcommand{\Abs}[1]{\left\lvert{#1}\right\rvert}
\newcommand{\qdot}[0]{\dot{q}}
\newcommand{\qddot}[0]{\ddot{q}}
\newcommand{\xdot}[0]{\dot{x}}
\newcommand{\xddot}[0]{\ddot{x}}
\newcommand{\ydot}[0]{\dot{y}}
\newcommand{\yddot}[0]{\ddot{y}}
\newcommand{\dotalpha}[0]{\dot{\alpha}}
\newcommand{\ddotalpha}[0]{\ddot{\alpha}}
\newcommand{\dottheta}[0]{\dot{\theta}}
\newcommand{\ddottheta}[0]{\ddot{\theta}}
\newcommand{\dotphi}[0]{\dot{\phi}}
\newcommand{\ddotphi}[0]{\ddot{\phi}}
% == \partial_{#1} {#2}
\newcommand{\PD}[2]{\frac{\partial {#2}}{\partial {#1}}}
\newcommand{\PDD}[3]{\frac{\partial^2 {#3}}{\partial {#1}\partial {#2}}}

% <grade selection>
%
\newcommand{\gpgrade}[2] {{\left\langle{{#1}}\right\rangle}_{#2}}

\newcommand{\gpgradezero}[1] {\gpgrade{#1}{}}
%\newcommand{\gpscalargrade}[1] {{\left\langle{{#1}}\right\rangle}}
%\newcommand{\gpgradezero}[1] {\gpgrade{#1}{0}}

%\newcommand{\gpgradeone}[1] {{\left\langle{{#1}}\right\rangle}_{1}}
\newcommand{\gpgradeone}[1] {\gpgrade{#1}{1}}

\newcommand{\gpgradetwo}[1] {\gpgrade{#1}{2}}
\newcommand{\gpgradethree}[1] {\gpgrade{#1}{3}}
\newcommand{\gpgradefour}[1] {\gpgrade{#1}{4}}
%
% </grade selection>


\usepackage[bookmarks=true]{hyperref}

\usepackage{color,cite,graphicx}
   % use colour in the document, put your citations as [1-4]
   % rather than [1,2,3,4] (it looks nicer, and the extended LaTeX2e
   % graphics package. 
\usepackage{latexsym,amssymb,epsf} % don't remember if these are
   % needed, but their inclusion can't do any damage



\title{Attempts at solutions for some Goldstein Mechanics problems.}
\author{Peeter Joot \quad peeter.joot@gmail.com }

\date{ Sep 02, 2008.  Last Revision: $Date: 2009/02/23 01:16:36 $ }

\begin{document}             

\maketitle{}

\section{ Motivation. }

Now have the so often sited \cite{goldstein1951cm} book to study (an ancient
version from the 50's).  Here's an attempt at a few of the problems.  Some
problems were tackled but omitted here since they overlapped with those written up in
\cite{PJTongMf1} before getting this book.

\section{ Problem 1.7 }

Barbell shape, equal masses.  center of rod between masses constrained to circular motion.

Assuming motion in a plane, the equation for the center of the rod is:

\begin{equation*}
c = a e^{i\theta}
\end{equation*}

and the two mass points positions are:
\begin{align*}
q_1 &= c + (l/2) e^{i\alpha} \\
q_2 &= c - (l/2) e^{i\alpha}
\end{align*}

taking derivatives:
\begin{align*}
\qdot_1 &= a i \dottheta e^{i\theta} + (l/2) i \dotalpha e^{i\alpha} \\
\qdot_2 &= a i \dottheta e^{i\theta} - (l/2) i \dotalpha e^{i\alpha} \\
\end{align*}

and squared magnitudes:

\begin{align*}
\qdot_{\pm}
&= \Abs{a \dottheta \pm (l/2) \dotalpha e^{i(\alpha - \theta)}}^2 \\
&= \left(a \dottheta   \pm   \inv{2} l \dotalpha \cos(\alpha - \theta)\right)^2 + \left(\inv{2} l \dotalpha \sin(\alpha - \theta)\right)^2
\end{align*}

Summing the kinetic terms yeilds

\begin{equation*}
K = m \left(a \dottheta \right)^2 + m \left(\inv{2} l \dotalpha\right)^2
\end{equation*}

Summing the potential energies, presuming that the motion is verticle, we have:

\begin{equation*}
V = m g (l/2) \cos\theta - m g (l/2) \cos \theta
\end{equation*}

So, the Lagrangian is just the Kinetic energy.

Taking derivatives to get the OEMs we have:

\begin{align*}
(m a^2 \dottheta)' &= 0 \\
\left(\inv{4} m l^2 \dotalpha \right)' &= 0
\end{align*}

This is suprising seeming.  Is this correct?

\section{ Problem 1.8 }

\subsection{ Problem statement. }

Hopefully, not a copyright violation, but here is the problem verbatim:

A system is composed of three particles of equal mass m.  Between any two of them there are forces derivable from a potential

\begin{equation*}
V = -g e^{-\mu r}
\end{equation*}

where r is the disance between the two particles.  In addition, two of the particles each exert a force on the third which can be obtained from a generalized potential of the form

\begin{equation*}
U = -f \Bv \cdot \Br
\end{equation*}

$\Bv$ being the relative velocity of the interacting particles and f a constant.  Set up the Lagragian for the system, using as coordinates the radius vector $\BR$ of the center of mass and the two vectors

\begin{align*}
\Brho_1 &= \Br_1 - \Br_3 \\
\Brho_2 &= \Br_2 - \Br_3
\end{align*}

Is the total angular momentum of the system conserved?

\subsection{ Solution attempt. }

The center of mass vector is:

\begin{equation*}
\BR = \inv{3}(\Br_1 + \Br_2 + \Br_3)
\end{equation*}

This can be used to express each of the position vectors in terms of the $\Brho_i$ vectors:

\begin{align*}
3 m \BR &= m (\Brho_1 + \Br_3) + m(\Brho_2 + \Br_3) + m \Br_3 \\
        &= 2 m (\Brho_1 + \Brho_2) + 3 m \Br_3 \\
  \Br_3 &= \BR - \inv{3}(\Brho_1 + \Brho_2) \\
\Br_2 = \Brho_2 + \Br_3 &= \Brho_2 + \Br_3 = \frac{2}{3} \Brho_2 - \inv{2} \Brho_1 + \BR \\
\Br_1 = \Brho_1 + \Br_3 &= \frac{2}{3} \Brho_1 - \inv{2} \Brho_2 + \BR \\
\end{align*}

Now, that is enough to specify the part of the Lagrangian from the potentials that act between all the particles

\begin{equation*}
\LL_V = \sum -V_{ij} = g \left( e^{-\mu \Abs{\Brho_1}} + e^{-\mu \Abs{\Brho_2}} + e^{-\mu \Abs{ \Brho_1 - \Brho_2 }} \right)
\end{equation*}

Now, we need to calculate the two $U$ potential terms.  If we consider with positions $\Br_1$, and $\Br_2$ to be the ones
that can exert a force on the third, the velocities of those masses relative to $\Br_3$ are:

\begin{equation*}
(\Br_3 - \Br_i)' = \dot{\Brho_i}
\end{equation*}

So, the potential parts of the Lagrangian are
%Adding this to the first half of the Lagrangian we have:
%So, for the second half of the Lagrangian we have:

\begin{equation*}
\LL_{U+V} =
g \left( e^{-\mu \Abs{\Brho_1}} + e^{-\mu \Abs{\Brho_2}} + e^{-\mu \Abs{ \Brho_1 - \Brho_2 }} \right)
+ f \left(\BR - \inv{3}(\Brho_1 + \Brho_2) \right) \cdot \left( \dot{\Brho_1} + \dot{\Brho_2} \right)
\end{equation*}

The Kinetic part (omitting the m/2 factor), in terms of the CM and relative vectors is

\begin{align*}
%\inv{2}m 
%\left( 
(\Bv_1)^2 
+(\Bv_2)^2 
+(\Bv_3)^2 %\right)
&= \left(\frac{2}{3} \dot{\Brho}_1 - \inv{2} \dot{\Brho}_2 + \dot{\BR}\right)^2 + \left(\frac{2}{3} \dot{\Brho}_2 - \inv{2} \dot{\Brho}_1 + \dot{\BR}\right)^2 + \left(\dot{\BR} - \inv{3}(\dot{\Brho}_1 + \dot{\Brho}_2)\right)^2 \\
&=
 3 \dot{\BR}^2 + (5/9 + 1/4) ((\dot{\Brho}_1)^2 + (\dot{\Brho}_2)^2 ) \\
&+ 2 (-2/3 + 1/9) \dot{\Brho}_1 \cdot \dot{\Brho}_1 
+ 2 (1/3-1/2) (\dot{\Brho}_1 + \dot{\Brho}_2) \cdot \dot{\BR}  \\
\end{align*}

So the Kinetic part of the Lagrangian is

\begin{align*}
\LL_K &= \frac{3m}{2} \dot{\BR}^2 + \frac{29 m}{72} ((\dot{\Brho}_1)^2 + (\dot{\Brho}_2)^2 ) 
- \frac{5 m}{9} \dot{\Brho}_1 \cdot \dot{\Brho}_2 
- \frac{m}{6} (\dot{\Brho}_1 + \dot{\Brho}_2) \cdot \dot{\BR}  \\
\end{align*}

and finally, the total Lagrangian is

\begin{align*}
\LL =
\frac{3m}{2} \dot{\BR}^2 + \frac{29 m}{72} ((\dot{\Brho}_1)^2 + (\dot{\Brho}_2)^2 ) 
- \frac{5 m}{9} \dot{\Brho}_1 \cdot \dot{\Brho}_2 
- \frac{m}{6} (\dot{\Brho}_1 + \dot{\Brho}_2) \cdot \dot{\BR}  \\
+g \left( e^{-\mu \Abs{\Brho_1}} + e^{-\mu \Abs{\Brho_2}} + e^{-\mu \Abs{ \Brho_1 - \Brho_2 }} \right)
+ f \left(\BR - \inv{3}(\Brho_1 + \Brho_2) \right) \cdot \left( \dot{\Brho_1} + \dot{\Brho_2} \right)
\end{align*}

\subsection{ Angular momentum conservation? }

How about the angular momentum conservation question?  How to answer that?  One way would be to compute the forces from the Lagrangian, and take cross products but is that really the best way?  Perhaps the answer is as simple as observing that there are no external torque's on the system, thus $d\BL/dt = 0$, or angular momentum for the system is constant (conserved).  Is that actually the case 
with these velocity dependent potentials?

It was suggested to me on PF that I should look at how this Lagrangian transforms under rotation, and use Noether's theorem.
The goldstein book doesn't explicitly mention this theorem that I can see, and I don't think it was covered yet if it did.

Suppose we did know about Noether's theorem for this problem (as I know do now that I'm revisiting it), we'd have to
see if the Lagrangian is invariant under rotation.  Suppose that a rigid rotation is introduced, which we can write in GA
formalism using dual sided quaternion products

\begin{align*}
\Bx \rightarrow \Bx' = e^{-i\ncap \alpha/2} \Bx e^{i\ncap\alpha/2}
\end{align*}

(could probably also use a matrix formulation, but the parameterization is messier).

For all the relative vectors $\Brho_i$ we have

\begin{align*}
\Abs{\Brho_i'} &= \Abs{\Brho_i}
\end{align*}

So all the $V$ potential interactions are invariant.  

Since the rotation quaternion here is a fixed non-time dependent quantity we have

\begin{align*}
\dot{\Brho}_i' = e^{-i\ncap \alpha/2} \dot{\Brho}_i e^{i\ncap\alpha/2}
\end{align*}

,so for the dot product in the the remaining potential term we have

\begin{align*}
\left( \BR' - \inv{3}\left(\Brho_1' + \Brho_2'\right) \right) \cdot \left({\dot{\Brho}}_1' + {\dot{\Brho}}_2'\right) 
&= 
\left(e^{-i\ncap \alpha/2} \left( \BR - \inv{3}\left(\Brho_1 + \Brho_2\right) \right) e^{i\ncap\alpha/2}\right) \cdot
\left(e^{-i\ncap \alpha/2} \dot{\Brho}_1 + \dot{\Brho_2} e^{i\ncap\alpha/2}\right) \\
&= 
\gpgradezero{
e^{-i\ncap \alpha/2} \left( \BR - \inv{3}\left(\Brho_1 + \Brho_2\right) \right) e^{i\ncap\alpha/2}
e^{-i\ncap \alpha/2} \dot{\Brho}_1 + \dot{\Brho_2} e^{i\ncap\alpha/2}
} \\
&= 
\gpgradezero{
e^{-i\ncap \alpha/2} \left( \BR - \inv{3}\left(\Brho_1 + \Brho_2\right) \right) \left(\dot{\Brho}_1 + \dot{\Brho_2}\right) e^{i\ncap\alpha/2}
} \\
&= 
\gpgradezero{
e^{i\ncap\alpha/2}
e^{-i\ncap \alpha/2} \left( \BR - \inv{3}\left(\Brho_1 + \Brho_2\right) \right) \left(\dot{\Brho}_1 + \dot{\Brho_2}\right) 
} \\
&= 
\gpgradezero{
\left( \BR - \inv{3}\left(\Brho_1 + \Brho_2\right) \right) \left(\dot{\Brho}_1 + \dot{\Brho_2}\right) 
} \\
&= 
\left( \BR - \inv{3}\left(\Brho_1 + \Brho_2\right) \right) \cdot \left(\dot{\Brho}_1 + \dot{\Brho_2}\right) 
\end{align*}

So, presuming I interpretted the $\Br$ in $\Bv \cdot \Br$ correctly,
all the vector quantites in the Lagrangian are rotation invariant, and by Noether's we should have system angular momentum 
conservation.

FIXME: Invoking Noether's here seems like cheating.  Should try something more direct here for comparision.  As a bare minimum the conserved current should
also be computed (which should be the angular momentum).

\subsection{ Evaluate the equations of motion. }

Unless the angular momentum question implicitly requires evaluating the Lagrangian this isn't required for the problem.  Let's try it
anyways, but instead generalize the Lagrangian slightly to get rid of all the peculiar and specific numerical constants.  Suppose that we let
$\rho_3 = \BR$, then our Lagrangian has the functional form

\begin{align*}
\LL = \alpha^{ij} \dot{\Brho}_i \cdot \dot{\Brho}_i 
+ g^i e^{-\mu \Abs{\Brho_i}}
+ g^{ij} e^{-\mu \Abs{ \Brho_i - \Brho_j }}
+ f^i \Brho_i \cdot ( \dot{\Brho}_1 + \dot{\Brho}_2 )
\end{align*}

To match up with the original Lagrangian not all the $g^{ij}$ are non-zero.

\section{ Problem 2.1 }

Prove that the shortest length curve between two points in space is a straight line.

A first attempt of this I used:

\begin{equation*}
ds = \sqrt{ 1 + (dy/dx)^2 + (dz/dx)^2 } dx
\end{equation*}

Application of the Euler-Lagrange equations does show that one ends up with a linear relation between the y and z coordinates, but no mention of x.  Rather than write that up, consider instead a parameterization of the coordinates:

\begin{align*}
x &= x_1(\lambda) \\
y &= x_2(\lambda) \\
z &= x_3(\lambda)
\end{align*}

in terms of this arbitrary parameterization we have a segment length of:

\begin{equation*}
ds = \sqrt{ \sum \left(\frac{d x_i}{d\lambda}\right)^2 } d \lambda = f\left(x_i\right) d\lambda
\end{equation*}

Application of the Euler-Lagrange equation to $f$ we have:

\begin{align*}
\PD{x_i}{f} 
&= 0 \\
&= \frac{d}{d\lambda} \PD{\xdot_i}{} \sqrt{ \sum {\xdot_j}^2 } \\
&= \frac{d}{d\lambda} \frac{ \xdot_i }{\sqrt{ \sum {\xdot_j}^2 }}
\end{align*}

Therefore each of these quotients can be equated to a constant:

\begin{align*}
\frac{ \xdot_i }{\sqrt{ \sum {\xdot_j}^2 }} &= {c_i}^{-2} \\
{c_i}^2 \xdot_i^2 &= \sum {\xdot_j}^2 \\
({c_i}^2 -1)\xdot_i^2 &= \sum_{j \ne i} {\xdot_j}^2 \\
(1 - {c_i}^2)\xdot_i^2 + \sum_{j \ne i} {\xdot_j}^2 &= 0 
\end{align*}

This last form shows explicitly that not all of these squared derivative terms can be linearly independent.  In particular, we have a
zero determinant:

\begin{equation*}
0 =
\begin{vmatrix}
1 - c_1^2   & 1            & 1         & 1 & \hdots \\
1           & 1 - c_2^2    & 1         & 1 & \vdots \\
1           & 1            & 1 - c_3^2 & 1 & \\
            &              &           & \ddots & \\
            &              &           &        & 1 - {c_n}^2
\end{vmatrix}
\end{equation*}

Now, expanding this for a couple specific cases isn't too hard.  For $n=2$ we have:

\begin{align*}
0 &= (1 - c_1^2)(1-c_2^2) - 1 \\
c_1^2 + c_2^2 &= c_1^2 c_2^2 \\
c_1^2 &= \frac{c_2^2}{ c_2^2 - 1 } \\
c_2^2 - 1 &= \frac{c_2^2}{ c_1^2 }
\end{align*}

This can be substuited back into one our $c_2^2$ equation:

\begin{align*}
({c_2}^2 -1)\xdot_2^2 &= {\xdot_1}^2 \\
\frac{c_2^2}{ c_1^2 } \xdot_2^2 &= {\xdot_1}^2 \\
\pm \frac{c_2}{ c_1 } \xdot_2 &= {\xdot_1} \\
\pm \frac{c_2}{ c_1 } x_2 &= x_1 + \kappa \\
\end{align*}

This is precisely the straight line that was desired, but we have setup for proving that consideration of all path variations from two points 
in \R{N} space has the shortest distance when that path is a straight line.

Despite the general setup, I'm going to chicken out and show this only for the \R{3} case.  In that case our determinant expands to:

\begin{equation*}
c_1^2 + c_2^2 + c_3^2 = c_1^2 c_2^2 c_3^2
\end{equation*}

Since not all of the $\xdot_i^2$ can be linearly independent, one can be eliminated:

\begin{align*}
(1 - c_1^2) \xdot_1^2 + \xdot_2^2 + \xdot_3^2 &= 0 \\
(1 - c_2^2) \xdot_2^2 + \xdot_3^2 + \xdot_1^2 &= 0 \\
(1 - c_3^2) \xdot_3^2 + \xdot_1^2 + \xdot_2^2 &= 0
\end{align*}

Let's pick $\xdot_1^2$ to eliminate, and subst 2 into 3:

\begin{align*}
%(1 - c_1^2) (-(1 - c_2^2) \xdot_2^2 - \xdot_3^2) + \xdot_2^2 + \xdot_3^2 &= 0 \\
(1 - c_3^2) \xdot_3^2 + (-(1 - c_2^2) \xdot_2^2 - \xdot_3^2) + \xdot_2^2 &= 0
\implies \\
%\xdot_2^2 ( 1 - (1 - c_1^2)(1 - c_2^2) ) + \xdot_3^2 ( 1 - (1 - c_1^2) ) &= 0 \\
- c_3^2 \xdot_3^2 + c_2^2 \xdot_2 &= 0 \\
\pm c_3 \xdot_3 &= c_2 \xdot_2 \\
\end{align*}

%Which is, once again a straight line:
%
%\begin{equation*}
%\pm c_3 x_3 = c_2 x_2 + \kappa
%\end{equation*}

Since these equations are symmetric, we can do this for all, with the result:
\begin{align*}
\pm c_3 \xdot_3 &= c_2 \xdot_2 \\
\pm c_3 \xdot_3 &= c_1 \xdot_1 \\
\pm c_2 \xdot_2 &= c_1 \xdot_1 \\
\end{align*}

Since the $c_i$ constants are arbitrary, then we can for example pick the negative sign for $\pm c_2$, and the positive for the rest, then add all of these, and scale by two:

\begin{equation*}
c_3 \xdot_3 - c_2 \xdot_2 = c_1 \xdot_1
\end{equation*}

and integrating:

\begin{equation*}
c_3 x_3 - c_2 x_2 = c_1 x_1 + \kappa
\end{equation*}

Again, we have the general equation of a line, subject to the desired constraints on the end points.  In the end we didn't need to 
evaluate the determinant after all, as done in the 
\R{2} case.

\section{ Problem 2.2 }

Prove that the geodesics (shortest length paths) on a spherical surface are great circles.

As a variational problem, the first step is to formulate an element of length on the surface.  If we write our vector in spherical coordinates ($\phi$ on the equator, and $\theta$ measuring from the north pole) we have:

FIXME: Scan picture.

\begin{equation*}
\Br = (x, y, z) = R( \sin\theta cos\phi, \sin\theta \sin\phi, \cos\theta)
\end{equation*}

A differential vector element on the surface is (set $R=1$ without loss of generality) :

\begin{align*}
d \Br 
&= \frac{d\Br}{d \theta} \frac{d \theta}{d \lambda} d \lambda + \frac{d\Br}{d \phi} \frac{d \phi}{d \lambda} d \lambda \\
&=
 ( \cos\theta \cos\phi, \cos\theta \sin\phi, -\sin\theta) \dottheta d\lambda
+( -\sin\theta \sin\phi, \sin\theta \cos\phi, 0) \dotphi d\lambda \\
&=
 ( \cos\theta \cos\phi \dottheta - \sin\theta \sin\phi \dotphi,
   \cos\theta \sin\phi \dottheta + \sin\theta \cos\phi \dotphi,
  -\sin\theta \dottheta) d\lambda
\end{align*}

Calculation of the length $ds$ of this vector yields:

\begin{equation*}
ds = \Abs{ d\Br} = \sqrt{\dottheta^2 + (\sin\theta)^2 \dotphi^2} d\lambda
\end{equation*}

This completes the setup for the minimization problem, and we want to 
minimize:

\begin{equation*}
s = \int \sqrt{\dottheta^2 + ( \dotphi \sin\theta )^2 } d\lambda
\end{equation*}

and can therefore apply the Euler-Lagrange equations to the function

\begin{equation*}
f(\theta, \phi, \dottheta, \dotphi, \lambda) = 
\sqrt{\dottheta^2 + ( \dotphi \sin\theta )^2 }
\end{equation*}

The $\phi$ is cyclic, and we have:

\begin{equation*}
\PD{\phi}{f} = 0 = \frac{d}{d\lambda} \frac{\dotphi \sin^2\theta}{f}
\end{equation*}

Thus we have:
\begin{align*}
\dotphi^2 \sin^4\theta &= K^2 \left(\dottheta^2 + ( \dotphi \sin\theta )^2 \right) \\
\dotphi^2 \sin^2\theta( \sin^2\theta - K^2 ) &= K^2 \dottheta^2 \\
\dotphi^2 
&= \frac{K^2 \dottheta^2 }{ \sin^2\theta ( \sin^2\theta - K^2 ) } \\
\dotphi
&= \frac{K \dottheta }{ \sin\theta \sqrt{ \sin^2\theta - K^2 } } \\
\end{align*}

This is in a nicely separated form, but it is not obvious that this describes paths that are great circles.

Let's have a look at the second equation.
\begin{align*}
\PD{\theta}{f} &= \frac{d}{d\lambda} \PD{\dottheta}{f} \\
\frac{\sin\theta\cos\theta \dotphi^2}{f}
&= \frac{d}{d\lambda} \frac{\dottheta}{f} \\
&= \frac{\ddottheta}{f} - \inv{2} \frac{ (\dottheta^2 + ( \dotphi \sin\theta )^2 )' }{f^3} \\
&= \frac{\ddottheta}{f} - \frac{ \dottheta \ddottheta + \dotphi \sin\theta ( \ddotphi \sin\theta + \dotphi \cos\theta \dottheta ) }{f^3} \\
\implies
-\sin\theta\cos\theta \dotphi^2 ( \dottheta^2 + ( \dotphi \sin\theta )^2 )
&= -\ddottheta ( \dottheta^2 + ( \dotphi \sin\theta )^2 )
   + \dottheta \ddottheta 
   + \dotphi \sin\theta ( \ddotphi \sin\theta + \dotphi \cos\theta \dottheta ) \\
\end{align*}

Or,
\begin{equation*}
- \ddottheta \dottheta^2 
- \ddottheta \dotphi^2 \sin^2\theta 
+ \dottheta \ddottheta 
+ \dotphi \ddotphi \sin^2\theta
+ \dotphi^2 \dottheta \sin\theta \cos\theta
+ \dotphi^2 \dottheta^2 \sin\theta \cos\theta 
+ \dotphi^4 \sin^3\theta \cos\theta 
= 0
\end{equation*}

What a mess!  I don't feel inclined to try to reduce this at the moment.  I'll come back to this problem later.  Perhaps there's a better parameterization?

\section{ Problem 2.3 }

For $f = f( y, \ydot, \yddot, x )$, find the equations for extreme values of

\begin{equation*}
I = \int_a^b f dx
\end{equation*}

Here we want $y$ and $\ydot$ fixed at the end points.  Following the first derivative derivation write the 
functions in terms of the desired extremum functions plus a set of arbitrary functions:

\begin{align*}
y( x, \alpha ) &= y( x, 0 ) + \alpha n(x) \\
\ydot( x, \alpha ) &= \ydot( x, 0 ) + \alpha m(x)
\end{align*}

Here we specify that these arbitrary variational functions vanish at the endpoints:

\begin{equation*}
n(a) = n(b) = m(a) = m(b) = 0
\end{equation*}

The functions $y(x, 0)$, and $\ydot(x, 0)$ are the functions we are looking for as solutions to the min/max problem.

Calculating derivatives we have:

\begin{equation*}
\frac{dI}{d\alpha} = 
\int \left( 
\PD{y}{f} \PD{\alpha}{y}
+\PD{\ydot}{f} \PD{\alpha}{\ydot}
+\PD{\yddot}{f} \PD{\alpha}{\yddot}
\right) d x
\end{equation*}

Assuming sufficient continuity look at the second term where we have:

\begin{align*}
\PD{\alpha}{\ydot} 
&= \PD{\alpha}{} \PD{x}{y} \\
&= \PD{x}{} \PD{\alpha}{y} \\
&= \PD{x}{} n(x) \\
&= \frac{d}{ d x} n(x) \\
&= \frac{d}{ d x} \PD{\alpha}{y} \\
\end{align*}

Similarily for the third term we have:

\begin{equation*}
\PD{\alpha}{\ydot} = \frac{d}{ d x} \PD{\alpha}{\ydot}
\end{equation*}

\begin{equation*}
\frac{dI}{d\alpha} = 
\int \PD{y}{f} \PD{\alpha}{y} d x +
\underbrace{\PD{\ydot}{f} \frac{d}{ d x} \PD{\alpha}{y}}_{ u v' = (u v)' - u' v } d x
+\PD{\yddot}{f} \frac{d}{ d x} \PD{\alpha}{\ydot} d x
\end{equation*}

Now integrating by parts:
\begin{align*}
\frac{dI}{d\alpha} &= 
 \int \PD{y}{f} \PD{\alpha}{y} d x
+\int \PD{\ydot}{f} \frac{d}{ d x} \PD{\alpha}{y} d x
+\int \PD{\yddot}{f} \frac{d}{ d x} \PD{\alpha}{\ydot} d x \\
\frac{dI}{d\alpha} &= 
 \int \PD{y}{f} \PD{\alpha}{y} d x
+\left(\PD{\ydot}{f} \underbrace{\PD{\alpha}{y}}_{n(x)}\right)_a^b - \int \PD{\alpha}{y} \frac{d}{ d x} \PD{\ydot}{f} d x
+\left(\PD{\yddot}{f} \underbrace{\PD{\alpha}{\ydot}}_{m(x)} \right)_a^b
-\int \PD{\alpha}{\ydot} \frac{d}{ d x} \PD{\yddot}{f} d x
\end{align*}

Because $m(a) = m(b) = n(a) = n(b)$ the non-integral terms are all zero, leaving:

\begin{align*}
\frac{dI}{d\alpha} &= 
  \int \PD{y}{f} \PD{\alpha}{y} d x
- \int \PD{\alpha}{y} \frac{d}{ d x} \PD{\ydot}{f} d x
- \int \PD{\alpha}{\ydot} \frac{d}{ d x} \PD{\yddot}{f} d x
\end{align*}

Now consider just this last integral, which we can again integrate by parts:
\begin{align*}
\int \PD{\alpha}{\ydot} \frac{d}{ d x} \PD{\yddot}{f} d x
&= \int \underbrace{\frac{d}{dx} \PD{\alpha}{y}}_{u'} \underbrace{\frac{d}{ d x} \PD{\yddot}{f}}_{v} d x \\
&= 
\left( \underbrace{\PD{\alpha}{y}}_{n(x)} {\frac{d}{ d x} \PD{\yddot}{f}} \right)_a^b
-\int \PD{\alpha}{y} \frac{d}{dx} {\frac{d}{ d x} \PD{\yddot}{f}} d x \\
&= 
-\int \PD{\alpha}{y} \frac{d^2}{dx^2} \PD{\yddot}{f} d x \\
\end{align*}

This gives:
\begin{align*}
\frac{dI}{d\alpha} &= 
  \int \PD{y}{f} \PD{\alpha}{y} d x
- \int \PD{\alpha}{y} \frac{d}{ d x} \PD{\ydot}{f} d x
+ \int \PD{\alpha}{y} \frac{d^2}{dx^2} \PD{\yddot}{f} d x \\
\frac{dI}{d\alpha} 
&= \int d x \PD{\alpha}{y} \left( \PD{y}{f} - \frac{d}{ d x} \PD{\ydot}{f} + \frac{d^2}{dx^2} \PD{\yddot}{f} \right) \\
&= \int d x n(x) \left( \PD{y}{f} - \frac{d}{ d x} \PD{\ydot}{f} + \frac{d^2}{dx^2} \PD{\yddot}{f} \right)
\end{align*}

So, if we want this derivative to equal zero for any $n(x)$ we require the inner quantity to by zero:

\begin{equation}
\PD{y}{f} - \frac{d}{ d x} \PD{\ydot}{f} + \frac{d^2}{dx^2} \PD{\yddot}{f} = 0
\end{equation}

Question.  Goldstein writes this in total differential form instead of a derivative:

\begin{align*}
dI &= \frac{dI}{d\alpha} d\alpha \\
&= \int d x \left(\PD{\alpha}{y} d \alpha\right) \left( \PD{y}{f} - \frac{d}{ d x} \PD{\ydot}{f} + \frac{d^2}{dx^2} \PD{\yddot}{f} \right) \\
\end{align*}

and then calls this quantity $\PD{\alpha}{y} d \alpha = \delta y$, the variation of $y$.  There must be a mathematical subtlety which motivates this
but it isn't clear to me what that is.  Since the variational calculus texts go a different route, with norms on functional spaces and so forth, perhaps
understanding that motivation isn't worthwhile.  In the end, the conclusion is the same, namely that the inner expression must equal zero for the extremum
condition.

\bibliographystyle{plainnat}
\bibliography{myrefs}

\end{document}               % End of document.
