\documentclass{article}

\input{../peeters_macros.tex}
\input{../peeters_macros2.tex}

\newcommand{\T}[0]{{\text{T}}}

\usepackage[bookmarks=true]{hyperref}

\title{ 2D matrix vs. GA wedge-dot vector to vector function. }
\author{Peeter Joot \quad peeter.joot@gmail.com}
\date{ Nov 25, 2008.  Last Revision: $Date: 2009/02/22 15:11:52 $ }

\begin{document}

\maketitle{}

%\tableofcontents
\section{ Motivation. }

Persuing an email thread with Lut.  
Consider a simpler case of Lut's mapping of matrix to wedge-dot operator form.

GA has natural operator representations of a number of common geometric
operations that can also be expressed as matrix transformations.  Examples
are reflection, rotation, projection and rejection:

Examples of GA linear functions are

\begin{itemize}
\item reflection
\begin{align*}
R(x) = -n x \inv{n}
\end{align*}

\item rotation, boost (composition of two reflections)
\begin{align*}
R(x)
%&= \phi x \phi^\dagger \quad \text{where $\phi$ has only even grades.} \\
&= m n x \inv{n} \inv{m} \\
\end{align*}

\item projection onto direction vector

\begin{align*}
\Proj_v(x) 
&= \inv{v} v \cdot x \\
&= \inv{2v} (v x + x v) \\
\end{align*}

with matrix equivalent
\begin{align*}
\Proj_v(x) = \left(v \inv{v^\T v} v^\T \right) x
\end{align*}

(subspace projection takes similar to the vector forms for both GA and matrixes).

\item rejection from direction vector

\begin{align*}
\Proj_v(x) 
&= \inv{v} v \wedge x \\
&= \inv{2v} (v x - x v) \\
\end{align*}

matrix equivalent?

\end{itemize}

Given an arbitrary general matrix such as 

\begin{align*}
M = 
\begin{bmatrix}
a & b & c \\
d & e & f \\
g & h & i \\
\end{bmatrix}
\end{align*}

is there a natural way to represent this operation as a GA operation, perhaps first decomposing it into symmetric and antisymmetric parts?

\section{ Simpler case. }

A generalization of the rejection operation of the form

\begin{align*}
(a \wedge x ) \cdot b 
&= \inv{4} ( a x b - x a b - b a x + b x a )
\end{align*}

is a natural operator to consider as a relativity simple form that neccessarily maps vectors to vectors.  What is the matrix equivalent of this?

Consider to start just the 2D case.  Expanding this by coordinates one has for the wedge

\begin{align*}
(a \wedge x)
&= ((a_1 e_1 + a_2 e_2) \wedge (x_1 e_1 + x_2 e_2) \\
&= (a_1 x_2 - a_2 x_1) e_1 \wedge e_2
\end{align*}

so taking dot products one has

\begin{align*}
(a \wedge x ) \cdot b
&= (a_1 x_2 - a_2 x_1) (e_1 \wedge e_2) \cdot (b_1 e_1 + b_2 e_2) \\
&= (a_1 x_2 - a_2 x_1) (e_1 b_2 - e_2 b_1) \\
\end{align*}

For the matrix with respect to the standard basis of this linear transformation we then have

\begin{align*}
\begin{bmatrix}
(a_1 x_2 - a_2 x_1) b_2 \\
(a_1 x_2 - a_2 x_1) (-b_1) \\
\end{bmatrix}
=
\begin{bmatrix}
- a_2 b_2 & a_1 b_2  \\
a_2 b_1 & -a_1 b_1 \\
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
\end{align*}

This matrix can be factored, which highlights some of the structure
\begin{align}\label{eqn:matrixOfOperator}
\begin{bmatrix}
- a_2 b_2 & a_1 b_2  \\
a_2 b_1 & -a_1 b_1 \\
\end{bmatrix}
=
\begin{bmatrix}
0 & -1 \\
1 & 0 \\
\end{bmatrix}
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
\begin{bmatrix}
a_1 & a_2 \\
\end{bmatrix}
\begin{bmatrix}
0 & -1 \\
1 & 0 \\
\end{bmatrix}
\end{align}

Writing $A$, and $B$ for the coordinate column vectors, and $R = R_{\pi/2}$ for the antisymetric permutation matrix one has 

\begin{align*}
\begin{bmatrix}
(a \wedge x) \cdot b
\end{bmatrix}
=
R B A^\T R
\end{align*}

This seems to be a pretty specific form and I would guess that one can't go the other way around to find a wedge-dot operator representation of a general two by two matrix such as

\begin{align*}
\begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}
\end{align*}

To demonstrate this equate the two
\begin{align*}
\begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}
=
\begin{bmatrix}
- a_2 b_2 & a_1 b_2  \\
a_2 b_1 & -a_1 b_1 \\
\end{bmatrix}
\end{align*}

writing $a_2 = -a/b_2$, and $a_1 = b/b_2$ we have

\begin{align*}
\begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}
=
\begin{bmatrix}
a & b \\
-a (b_1/b_2) & -b (b_1/b_2) \\
\end{bmatrix}
\end{align*}

With $c = -a(b_1/b_2)$ or $b_1 = -c b_2 /a$ the $2,2$ term of the matrix
is left with the value $-b (-c b_2 /a / b_2 ) = -b (-c /a )$.  Therefore 
this matrix can only represent the
polynomial vector function $f(x) = (a \wedge x) \cdot b$ if 
$d = bc/a$, or $ad - bc = 0$.  The matrix must must have zero determinant
to have a representation of this form.

This can be seen directly by taking the determinant of 
or matrix in equation \ref{eqn:matrixOfOperator}

\begin{align*}
a_2 b_2 a_1 b_1 - a_2 b_1 a_1 b_2 = 0
\end{align*}

Now, is there a natural representation of an arbitrary matrix in polynomial form.  There are many possible
vector polynomials that map vectors to vectors.  Seeing the form of the polynomials for reflection, rotation, projection, rejection, and this wedge-dot operation (name?), one could guess that some hybrid that includes some subset of the 
all possible such variations would do.  Perhaps the best way to followup on this idea would be to consider the eigenvector and generalized eigenvector (Jordan form) decomposition of the general matrix to be considered.  The eigenvectors give a projective breakdown of the matrix, and each of those projections can be represented in GA form.  For the jordon blocks in the generalized eigenvalue decomposition, perhaps null determinant operators such as this wedge-dot function can represent those?

%\bibliographystyle{plainnat}
%\bibliography{myrefs}

\end{document}
