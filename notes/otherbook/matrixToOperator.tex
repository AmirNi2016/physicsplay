\documentclass{article}

\input{../peeters_macros.tex}
\input{../peeters_macros2.tex}

\newcommand{\T}[0]{{\text{T}}}

\usepackage[bookmarks=true]{hyperref}

\title{ 2D matrix vs. GA wedge-dot vector to vector function. }
\author{Peeter Joot}
\date{ Nov 25, 2008.  Last Revision: $Date: 2008/11/26 03:46:36 $ }

\begin{document}

\maketitle{}

%\tableofcontents
\section{ Motivation. }

Consider a simpler case of Lut's mapping of matrix to wedge-dot operator form.

GA has natural operator representations of a number of common geometric
operations that can also be expressed as matrix transformations.  Examples
are reflection, rotation, projection and rejection:


Examples of GA linear functions are

\begin{itemize}
\item reflection
\begin{align*}
R(x) = -n x \inv{n}
\end{align*}

\item rotation, boost
\begin{align*}
R(x) = \phi x \phi^\dagger
\end{align*}

\item projection onto direction vector

\begin{align*}
\Proj_v(x) = \inv{v} v \cdot x
\end{align*}

with matrix equivalent
\begin{align*}
\Proj_v(x) = \left(v \inv{v^\T v} v^\T \right) x
\end{align*}

(subspace projection takes similar to the vector forms for both GA and matrixes).

\item rejection from direction vector

\begin{align*}
\Proj_v(x) = \inv{v} v \wedge x
\end{align*}

matrix equivalent?

\end{itemize}

Given an arbitrary general matrix such as 

\begin{align*}
M = 
\begin{bmatrix}
a & b & c \\
d & e & f \\
g & h & i \\
\end{bmatrix}
\end{align*}

is there a natural way to represent this operation as a GA operation, perhaps first decomposing it into symmetric and antisymmetric parts?

\section{ Simpler case. }

A generalization of the rejection operation of the form

\begin{align*}
(a \wedge x ) \cdot b
\end{align*}

is a natural operator to consider as a relativity simple form that neccessarily maps vectors to vectors.  What is the matrix equivalent of this?

Consider to start just the 2D case.  Expanding this by coordinates one has for the wedge

\begin{align*}
(a \wedge x)
&= ((a_1 e_1 + a_2 e_2) \wedge (x_1 e_1 + x_2 e_2) \\
&= (a_1 x_2 - a_2 x_1) e_1 \wedge e_2
\end{align*}

so taking dot products one has

\begin{align*}
(a \wedge x ) \cdot b
&= (a_1 x_2 - a_2 x_1) (e_1 \wedge e_2) \cdot (b_1 e_1 + b_2 e_2) \\
&= (a_1 x_2 - a_2 x_1) (e_1 b_2 - e_2 b_1) \\
\end{align*}

For the matrix with respect to the standard basis of this linear transformation we then have

\begin{align*}
\begin{bmatrix}
(a_1 x_2 - a_2 x_1) b_2 \\
(a_1 x_2 - a_2 x_1) (-b_1) \\
\end{bmatrix}
=
\begin{bmatrix}
- a_2 b_2 & a_1 b_2  \\
a_2 b_1 & -a_1 b_1 \\
\end{bmatrix}
\begin{bmatrix}
x_1 \\
x_2 \\
\end{bmatrix}
\end{align*}

This matrix can be factored, which highlights some of the structure
\begin{align*}
\begin{bmatrix}
- a_2 b_2 & a_1 b_2  \\
a_2 b_1 & -a_1 b_1 \\
\end{bmatrix}
=
\begin{bmatrix}
0 & -1 \\
1 & 0 \\
\end{bmatrix}
\begin{bmatrix}
b_1 \\
b_2 \\
\end{bmatrix}
\begin{bmatrix}
a_1 & a_2 \\
\end{bmatrix}
\begin{bmatrix}
0 & -1 \\
1 & 0 \\
\end{bmatrix}
\end{align*}

Writing $A$, and $B$ for the coordinate column vectors, and $R = R_{\pi/2}$ for the antisymetric permutation matrix one has 

\begin{align*}
\begin{bmatrix}
(a \wedge x) \cdot b
\end{bmatrix}
=
R B A^\T R
\end{align*}

Lut, This seems to be a pretty specific form and I would guess that one can't go the other way around to find a wedge-dot operator representation of a general two by two
matrix such as

\begin{align*}
\begin{bmatrix}
a & b \\
c & d \\
\end{bmatrix}
\end{align*}

Can you come up with a counter example to demonstrate that?

%\bibliographystyle{plainnat}
%\bibliography{myrefs}

\end{document}
