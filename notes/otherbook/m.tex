\documentclass{article}      % Specifies the document class

\input{../peeters_macros.tex}

%
% The real thing:
%

\usepackage[bookmarks=true]{hyperref}

                             % The preamble begins here.
%\title{} % Declares the document's title.
%\author{Peeter Joot}         % Declares the author's name.
%\date{ Last Revision: $Date: 2008/10/06 13:09:32 $ } % Deleting this command produces today's date.

\begin{document}             % End of preamble and beginning of text.

%\maketitle{}

%\tableofcontents

%\section{ Q. }
%
%Thanks for suggesting those book; especially for geometric algebra for computer science which is very interesting.
%About the problems we were talking about some time ago, I got almost the "final solution" but I am missing the very last step to reach it.
%I mentioned few days ago in physicsforums that I did some progress thanks to the psuedo-inverse operator; however I will skip all the steps I made and I will just explain what is the problem, the formula I arrived to, and the last missing step.
%
%I have an orthogonal basis $B={bi : i=1..M}$ and a vector $v$. All these vectors are N-elements vectors expressed in canonical coordinates.
%Note that the matrix $B$ is not square: it is instead a $NxM$ matrix.
%I have another basis which I call W, and it is defined in the following way:
%
%\begin{equation*}
%W = DB
%\end{equation*}
%
%where $D$ is simply a diagonal $NxN$ matrix.  In other words the new basis is given by a diagonal matrix multiplied by the the old one.
%According to my (hopefully correct) calculations, one would have:
%
%\begin{equation*}
%G(W) v2 = W'v
%\end{equation*}
%
%where:
%
%$G(W)$    is the metric tensor of W
%
%$v2$    is the vector v expressed in the new basis W
%
%$W'$    is the transpose of the matrix W 
%
%Now, all I need is a formula to "extract" the i-th coordinate of v2.
%Unfortunately I cannot yet figure out how to get the final formula without computing the inverse of the matrix $G(W)$. The correct resulting formula which I am supposed to get is the formula (4.9) at pag.56 of the Ph.D. thesis I sent you some time ago, but I want to know the last step to arrive at it.
%
%I was wondering if you could give me an hint in this.
%I dont know if this problem might be interesting for you, but perhaps you already got what's all this about. Basically if the basis B are complex sinusoids of different frequencies, and if D is the identity matrix, what you get is the Fourier transform of a discrete signal v. If you instead multiply the same weight-function by each complex sinusoid you get "weighted sinusoids" (like Gabor filters) which are not anymore orthogonal; however using somehow the information in $G(W)$, one should be able to compensate the non-orthogonality and compute the correct coefficients.
%In an analogue fashion, it is possible also to assign another weight-function to the data vector v. The result would be a generalization of convolution in which you are allowed to specify weights for the kernel function and for the data too, without scrambling the result.
%
%\section{ }

Let
\begin{align*}
b_i &= b_{ij} e_j \\
w_i &= w_{ij} e_j \\
w_{ij} &= \sigma_j b_{ij}
\end{align*}

Given

\begin{align*}
x = x^i b_i
\end{align*}

compute

\begin{align*}
x = u^i w_i
\end{align*}

\begin{align*}
x^i b_i &= u^j w_j \\
x^i b_{ik} e_k &= u^j \sigma_c b_{jc} e_c \\
x^i b_{ik} e_k \cdot e_d &= u^j \sigma_c b_{jc} e_c \cdot e_d \\
\end{align*}

This leaves us with $N$ equations (one for each $e_d$), for $M$ unknowns $u^j$

\begin{align*}
x^i b_{id} &= u^j \sigma_d b_{jd} \\
\end{align*}

You know there is a unique solution for this provided the matrix $\sigma_d$ is not degenerate (ie: no zeros), so I don't see any choice but to do the transpose multiplication and invert for $u^j$

%%\bibliographystyle{plain}
%\bibliographystyle{plainnat} % supposed to allow for \url use.
%\bibliography{myrefs}      % expects file "myrefs.bib"

\end{document}               % End of document.
