%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

% 
% 
\chapter{Some NFCM exercise solutions and notes}
\label{chap:nfcmCh2}
%\date{Nov 27, 2008.  nfcmCh2.tex}

\section{Chapter 2}

I recall that some of the problems from this chapter of
\citep{hestenes1999nfc}
were fairly tricky.  Did I end up doing them all?  I intended to
revisit these and make sure I understood it all.  As I do so, write up
solutions, starting with $1.3$, a question on the Geometric Algebra group.

Another thing I recall from the text is that I was fairly confused about
all the mass of identities by the time I got through it, and it was not clear
to me which were the fundamental ones.
Eventually I figured out that it is
really grade selection that is the fundamental operation, and
found better presentations of axiomatic treatment in \citep{doran2003gap}.

For reference the GA axioms are

\begin{itemize}
\item vector product is linear

\begin{align}
a ( \alpha b + \beta c) &= \alpha a b + \beta a c \\
( \alpha a + \beta b) c &= \alpha a c + \beta b c
\end{align}

\item distribution of vector product

\begin{align}
(a b) c = a (b c) = a b c
\end{align}

\item vector contraction

\begin{align}\label{eqn:nfcm_ch2:contractionAxiom}
a^2 \in \mathbb{R}
\end{align}

For a Euclidean space, this provides the length $a^2 = \Abs{a}^2$, but for relativity and conformal geometry this specific meaning is not required.

\end{itemize}

The definition of the generalized dot between two blades is

\begin{align}\label{eqn:nfcm_ch2:generalDot}
A_r \cdot B_s = \gpgrade{A B}{{\Abs{r -s}}}
\end{align}

and the generalized wedge product definition for two blades is 

\begin{align}\label{eqn:nfcm_ch2:generalWedge}
A_r \wedge B_s = \gpgrade{A B}{r + s}.
\end{align}

With these definitions and the GA axioms everything else should logically follow.

I personally found it was really easy to go around in circles attempting the various proofs, and intended to revisit all of these
and prove them all for myself making sure I did not invoke any circular arguments and used only things already proven.

\subsection{Exercise 1.3}

Solve for $x$

\begin{align*}
\alpha x + a x \cdot b = c
\end{align*}

where $\alpha$ is a scalar and all the rest are vectors.

\subsubsection{Solution}

Can dot or wedge the entire equation with the constant vectors.  In particular

\begin{align*}
c \cdot b &= (\alpha x + a x \cdot b) \cdot b \\ 
&= (\alpha + a \cdot b) x \cdot b 
\end{align*}
\begin{align*}
\implies
x \cdot b &= \frac{c \cdot b}{\alpha + a \cdot b} \\
\end{align*}

and
\begin{align*}
c \wedge a &= (\alpha x + a x \cdot b) \wedge a \\ 
&= \alpha (x \wedge a) + \underbrace{(a \wedge a)}_{=0} (x \cdot b) \wedge a \\
\end{align*}
\begin{align*}
\implies
x \wedge a &= \inv{\alpha} (c \wedge a) \\
\end{align*}

This last can be reduced by dotting with $b$, and then substitute the 
result for $x \cdot b$ from above

\begin{align*}
(x \wedge a) \cdot b
&= x (a \cdot b) - (x \cdot b) a \\
&= x (a \cdot b) - \frac{c \cdot b}{\alpha + a \cdot b} a \\
\end{align*}

Thus the final solution is

\begin{align*}
x = \inv{a \cdot b}\left(
\frac{c \cdot b}{\alpha + a \cdot b} a 
+ \inv{\alpha} (c \wedge a) \cdot b
\right)
\end{align*}

Question: was there a geometric or physical motivation for this question.  I can not recall one?

\section{Sequential proofs of required identities}

\subsection{Split of symmetric and antisymmetric parts of the vector product}

NFCM defines the vector dot and wedge products in terms of the symmetric and antisymmetric parts, and not in terms of grade
selection.

The symmetric and antisymmetric split of a vector product takes the form

\begin{align*}
a b &= \inv{2}(a b + b a) + \inv{2}(a b - b a)
\end{align*}

Observe that if the two vectors are colinear, say $b = \alpha a$, then this is

\begin{align*}
a b &= \frac{\alpha}{2} (a^2 + a^2) + \frac{\alpha}{2}(a^2 - a^2 )
\end{align*}

The antisymmetric part is zero for any colinear vectors, while the symmetric part is a scalar by the contraction axiom \ref{eqn:nfcm_ch2:contractionAxiom}.

Now, suppose that one splits the vector $b$ into a part that is explicit
colinear with $a$, as in $b = \alpha a + c$.

Here one can observe that none of the colinear component of this vector
contributes to the antisymmetric part of the split

\begin{align*}
\inv{2}(a b - b a) &= \inv{2}(a (\alpha a + c) - (\alpha a + c) a) \\
&= \inv{2}(a c - c a) 
\end{align*}

So, in a very loose fashion the symmetric part can be observed to be
due to only colinear parts of the vectors whereas colinear components of the 
vectors do not contribute at all to the antisymmetric part of the product split.
One can see that there is a notion of parallelism and perpendicularity built
into this construction.

What is of interest here is to show that this symmetric and antisymmetric split
also provides the scalar and bivector parts of the product, and thus matches the
definitions of generalized dot and wedge products.

While it has been observed that the symmetric product is a scalar for colinear vectors
it has not been
demonstrated that this is necessarily a scalar in the general case.

Consideration of the square of $a + b$ is enough to do so.

\begin{align*}
(a + b)^2 &= a^2 + b^2 + ab + ba \\
\implies \\
\end{align*}
\begin{align}\label{eqn:nfcm_ch2:pythagorus}
\inv{2}\left((a + b)^2 - a^2 - b^2\right) &= \inv{2}(ab + ba)
\end{align}

We have only scalar terms on the LHS, which demonstrates that the symmetric product is necessarily a scalar.
This is despite the fact that the exact definition of $a^2$ (ie: the metric for the space) has not been specified, nor even
a requirement that this vector square is even satisfies $a^2 >= 0$.  Such an omission is valuable since it allows
for a natural formulation of relativistic four-vector algebra where both signs are allowed for the vector square.

Observe that \ref{eqn:nfcm_ch2:pythagorus} provides a generalization of the Pythagorean theorem.  If one defines, as in
Euclidean space, that two vectors are perpendicular by

\begin{align*}
(a + b)^2 = a^2 + b^2
\end{align*}

Then one necessarily has

\begin{align*}
\inv{2}(ab + ba) = 0 
\end{align*}

So, that we have as a consequence of this perpendicularity definition a sign inversion on reversal
\begin{align*}
ba = -ab
\end{align*}

This equation contains the essence of the concept of grade.  The product of a pair of vectors is grade two
if reversal of the factors changes the sign, which in turn implies the two factors must be perpendicular.

Given a set of vectors that, according to the symmetric vector product (dot product) are all either mutually perpendicular or colinear, grouping by colinear sets determines the grade

\begin{align*}
a_1 a_2 a_3 ... a_m = (b_{j_1} b_{j_2} ... ) (b_{k_1} b_{k_2} ... ) ...  (b_{l_1} b_{l_2} ... )
\end{align*}

after grouping in pairs of colinear vectors (who's squares are scalars) the count of the remaining elements is the grade.  By  
example, suppose that ${e_i}$ is a normal basis for \R{N} $e_i \cdot e_j \propto \delta_{ij}$, and one wishes to determine the grade
of a product.  Permuting this product so that it is ordered by index leaves it in a form that the grade can be observed by inspection

\begin{align*}
e_3 e_7 e_1 e_2 e_1 e_7 e_6 e_7 
&= - e_3 e_1 e_7 e_2 e_1 e_7 e_6 e_7 \\
&= e_1 e_3 e_7 e_2 e_1 e_7 e_6 e_7 \\
&= ... \\
&\propto e_1 e_1 e_2 e_3 e_6 e_7 e_7 e_7 \\
&= (e_1 e_1) e_2 e_3 e_6 (e_7 e_7) e_7 \\
&\propto e_2 e_3 e_6 e_7 \\
\end{align*}

This is an example of a grade four product.  Given this implicit definition of grade, one can then see that the antisymmetric product of
two vectors is necessarily grade two.  An explicit enumeration of a vector product in terms of an explicit normal basis and associated 
coordinates is helpful here to demonstrate this.

Let

\begin{align*}
a &= \sum_i a_i e_i \\
b &= \sum_j b_j e_j
\end{align*}

now, form the product
\begin{align*}
a b
&= \sum_i \sum_j a_i b_j e_i e_j \\
&= 
 \sum_{i < j} a_i b_j e_i e_j 
+\sum_{i = j} a_i b_j e_i e_j 
+\sum_{i > j} a_i b_j e_i e_j \\
&= 
 \sum_{i < j} a_i b_j e_i e_j 
+\sum_{i = j} a_i b_j e_i e_j 
+\sum_{j > i} a_j b_i e_j e_i \\
&= 
 \sum_{i < j} a_i b_j e_i e_j 
+\sum_{i = j} a_i b_j e_i e_j 
-\sum_{i < j} a_j b_i e_i e_j \\
&= \sum_{i} a_i b_i (e_i)^2 
+ \sum_{i < j} (a_i b_j - a_j b_i) e_i e_j  \\
\end{align*}

similarly

\begin{align*}
b a &= \sum_{i} a_i b_i (e_i)^2 - \sum_{i < j} (a_i b_j - a_j b_i) e_i e_j  \\
\end{align*}

Thus the symmetric and antisymmetric products are respectively

\begin{align*}
\inv{2}(a b + b a) &= \sum_{i} a_i b_i (e_i)^2 \\
\inv{2}(a b - b a) &= \sum_{i < j} (a_i b_j - a_j b_i) e_i e_j  \\
\end{align*}

The first part as shown above with non-coordinate arguments is a scalar.  Each term in the antisymmetric product has a grade two term, which
as a product of perpendicular vectors cannot be reduced any further, so it is therefore grade two in its entirety.

following the definitions of equation \ref{eqn:nfcm_ch2:generalDot} and \ref{eqn:nfcm_ch2:generalWedge} respectively, one can then write

\begin{align}
a \cdot b &= \inv{2}(a b + b a) \\
a \wedge b &= \inv{2}(a b - b a)
\end{align}

These can therefore be seen to be a consequence of the definitions and axioms rather than a required a-priori definition in their own right.  Establishing
these as derived results is important to avoid confusion when one moves on to general higher grade products.  The vector dot and wedge products are
not sufficient by themselves if taken as a fundamental definition to establish the required results for such higher grade products (in particular the useful
formulas for vector times blade dot and wedge products should be observed to be derived results as opposed to definitions).

\subsection{bivector dot with vector reduction}

In the $1.3$ solution above the identity

\begin{align}
(a \wedge b) \cdot c &= a (b \cdot c) - (a \cdot c) b \\
\end{align}

was used.  Let us prove this.

\begin{align*}
(a \wedge b) \cdot c
&= \gpgradeone{(a \wedge b) c} \\
\implies \\
2 (a \wedge b) \cdot c
&= \gpgradeone{a b c - b a c} \\
&= \gpgradeone{a b c - b (- c a + 2 a \cdot c )} \\
&= \gpgradeone{a b c + b c a} - 2 b (a \cdot c ) \\
&= \gpgradeone{a (b \cdot c + b \wedge c) + (b \cdot c + b \wedge c) a} - 2 b (a \cdot c ) \\
&= 2 a (b \cdot c) + a \cdot (b \wedge c) + (b \wedge c) \cdot a - 2 b (a \cdot c ) \\
\end{align*}

To complete the proof we need $a \cdot B = -B \cdot a$, but once that is demonstrated, one is left with the desired identity after dividing through
by $2$.

\subsection{vector bivector dot product reversion}

Prove $a \cdot B = -B \cdot a$.
