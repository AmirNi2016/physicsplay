\documentclass{article}      % Specifies the document class

\input{../peeters_macros.tex}
\newcommand{\T}[0]{\text{T}}

%
% The real thing:
%

                             % The preamble begins here.
\title{ Oblique projection and reciprocal frame vectors. }
\author{Peeter Joot}         % Declares the author's name.
%\date{}        % Deleting this command produces today's date.

\begin{document}             % End of preamble and beginning of text.

\maketitle{}

\section{ Motivation. }

Followup on wikipedia projection article's description of an oblique
projection.  Calculate this myself.

\section{ Using GA.  Oblique projection onto a line. }

INSERT DIAGRAM.

Problem is to project a vector $\Bx$ onto a line with direction $\pcap$, along a direction vector $\dcap$.

Write:

\[
\Bx + \alpha \dcap = \beta \pcap
\]

and solve for $\Bp = \beta \pcap$.  Wedging with $\dcap$ provides the solution:

\[
\Bx \wedge \dcap + \alpha \underbrace{\dcap \wedge \dcap}_{=0} = \beta \pcap \wedge \dcap
\]
\[
\implies
\beta = \frac{\Bx \wedge \dcap}{\pcap \wedge \dcap}
\]

So the ``oblique'' projection onto this line (using direction $\dcap$) is:

\begin{equation}
\Proj_{\dcap \rightarrow \pcap}(\Bx) =
\frac{\Bx \wedge \dcap}{\pcap \wedge \dcap} \pcap
\end{equation}

This also shows that we do not need unit vectors for this sort of projection
operation, since we can scale these two vectors by any quantity since they are
in both the numerator and denominator.

Let $\BD$, and $\BP$ be vectors in the directions of $\dcap$, and $\pcap$ respectively.  Then the projection can also be written:

\begin{equation}\label{eqn:obliqueGAproj}
\Proj_{\BD \rightarrow \BP}(\Bx) =
\frac{\Bx \wedge \BD}{\BP \wedge \BD} \BP
\end{equation}

It's interesting to see projection expressed here without any sort of dot
product when all our previous projection calculations had intrinsic
requirements for a metric.

Now, let's compare this to the matrix forms of projection that we have become familiar with.  For the matrix result we need a metric, but because
this result is intrisically non-metric, we can introduce one if convienent and express this result with that too.  Such an expansion is:

\begin{align*}
\frac{\Bx \wedge \BD}{\BP \wedge \BD} \BP
&=
\Bx \wedge \BD
\frac{\BD \wedge \BP}{\BD \wedge \BP}
\inv{\BP \wedge \BD}
\BP \\
&=
(\Bx \wedge \BD) \cdot (\BD \wedge \BP)
\inv{\abs{\BP \wedge \BD}^2}
\BP \\
&=
((\Bx \wedge \BD) \cdot \BD) \cdot \BP
\inv{\abs{\BP \wedge \BD}^2}
\BP \\
&=
(
\Bx \BD^2 - \Bx \cdot \BD \BD
) \cdot \BP
\inv{\abs{\BP \wedge \BD}^2}
\BP \\
&=
\frac{\Bx \cdot \BP \BD^2 - \Bx \cdot \BD \BD \cdot \BP}
{\BP^2 \BD^2 - (\BP \cdot \BD)^2
%p ^ d . d ^ p = p ^ d . d . p = (p d^2 - d.p d) . p = p^2 d^2 - (d.p)^2
}
\BP \\
\end{align*}

This gives us the projection explicitly:

\begin{equation}\label{eqn:obliqueProjNearMatrixForm}
\Proj_{\BD \rightarrow \BP}(\Bx)
=
\left(\Bx \cdot \frac{\BP \BD^2 - \BD \BD \cdot \BP}{\BP^2 \BD^2 - (\BP \cdot \BD)^2}\right)
\BP
\end{equation}

It sure doesn't simplify things to expand things out, but we now have things prepared to express in matrix form.

Assuming a euclidian metrix, and a bit of playing shows that the denominator can be written more simply as:

\[
\BP^2 \BD^2 - (\BP \cdot \BD)^2 =
\begin{vmatrix}
U^\T U
\end{vmatrix}
\]

where:

\[
U =
\begin{bmatrix}
P & D
\end{bmatrix}
\]

Similarily the numerator can be written:

\[
\Bx \cdot \BP \BD^2 - \Bx \cdot \BD \BD \cdot \BP =
D^\T U
\begin{bmatrix}
0 & -1 \\
1 & 0 \\
\end{bmatrix}
U^\T \Bx.
\]

Combining these yields a projection matrix:

\begin{equation}\label{eqn:matrixprojfromwedge}
\Proj_{\BD \rightarrow \BP}(\Bx) =
\left(
\BP
\inv{
\begin{vmatrix}
U^\T U
\end{vmatrix}
}
\BD^\T U
\begin{bmatrix}
0 & -1 \\
1 & 0 \\
\end{bmatrix}
U^\T\right) \Bx.
\end{equation}

The alternation above suggests that this is related to the matrix inverse of something.  Let's try to calculate this directly instead.

\section{ Oblique projection onto a line using matrices. }

Let's start at the same place, except that we know we can discard the unit vectors and work with any vectors in the projection directions:

\[
\Bx + \alpha \BD = \beta \BP
\]

Assuming an inner product, we have two sets of results:

\begin{align*}
\innerprod{\BP}{\Bx} + \alpha \innerprod{\BP}{\BD} &= \beta \innerprod{\BP}{\BP} \\
\innerprod{\BD}{\Bx} + \alpha \innerprod{\BD}{\BD} &= \beta \innerprod{\BD}{\BP} \\
\end{align*}

and can solve this for $\alpha$, and $\beta$.

\begin{equation}\label{eqn:matrixtosolve}
\begin{bmatrix}
\innerprod{\BP}{\BD} & \innerprod{\BP}{\BP} \\
\innerprod{\BD}{\BD} & \innerprod{\BD}{\BP} \\
\end{bmatrix}
\begin{bmatrix}
-\alpha \\
\beta \\
\end{bmatrix}
=
\begin{bmatrix}
\innerprod{\BP}{\Bx} \\
\innerprod{\BD}{\Bx} \\
\end{bmatrix}
\end{equation}

%This can be solved with matrix inversion, but we are only

If our inner product is defined by $\innerprod{\Bu}{\Bv} = \Bu^* A \Bv$, we have:

\begin{align*}
\begin{bmatrix}
\innerprod{\BP}{\BD} & \innerprod{\BP}{\BP} \\
\innerprod{\BD}{\BD} & \innerprod{\BD}{\BP} \\
\end{bmatrix}
&=
\begin{bmatrix}
{\BP}^* A {\BD} & {\BP}^* A {\BP} \\
{\BD}^* A {\BD} & {\BD}^* A {\BP} \\
\end{bmatrix} \\
&=
{
\begin{bmatrix}
\BP & \BD \\
\end{bmatrix}
}^*
A
\begin{bmatrix}
{\BD} & {\BP} \\
\end{bmatrix} \\
\end{align*}

Thus the solution to equation \ref{eqn:matrixtosolve} is

\begin{equation}
\begin{bmatrix}
-\alpha \\
\beta \\
\end{bmatrix}
=
\left(
\inv{
{
\begin{bmatrix}
\BP & \BD \\
\end{bmatrix}
}^*
A
\begin{bmatrix}
{\BD} & {\BP} \\
\end{bmatrix}
}
{
\begin{bmatrix}
\BP & \BD \\
\end{bmatrix}
}^*
A
\right)
\Bx
\end{equation}

Again writing $U = 
\begin{bmatrix}
P & D \\
\end{bmatrix}
$, this is:

\begin{align*}
\begin{bmatrix}
-\alpha \\
\beta \\
\end{bmatrix}
&=
\left(
\inv{U^* A U 
\begin{bmatrix}
0 & 1 \\
1 & 0 \\
\end{bmatrix}
}
U^*
A
\right)
\Bx \\
&=
\left(
\begin{bmatrix}
0 & 1 \\
1 & 0 \\
\end{bmatrix}
\inv{U^* A U 
}
U^*
A
\right)
\Bx \\
\end{align*}

Since we only care about solution for $\beta$ to find the projection, we have to discard half the inversion work, and just select
that part of the solution (suggests that a Cramer's rule method is more efficient than matrix inversion in this case) :

\[
\beta = 
\begin{bmatrix}
0 & 1 \\
\end{bmatrix}
\begin{bmatrix}
-\alpha \\
\beta \\
\end{bmatrix}
\]

Thus the solution of this oblique projection problem in terms of matrixes is:

\begin{align*}
\Proj_{\BD \rightarrow \BP}(\Bx) 
&= 
\left(
\BP
\begin{bmatrix}
0 & 1 \\
\end{bmatrix}
\begin{bmatrix}
0 & 1 \\
1 & 0 \\
\end{bmatrix}
\inv{U^* A U 
}
U^*
A
\right)
\Bx
\end{align*}

Which is:

\begin{equation}
\Proj_{\BD \rightarrow \BP}(\Bx) = 
\left(
\BP
\begin{bmatrix}
1 & 0 \\
\end{bmatrix}
\inv{U^* A U 
}
U^*
A
\right)
\Bx
\end{equation}

Explicit expansion can be done easily enough to show that this is identical to equation \ref{eqn:obliqueProjNearMatrixForm}, so
the question of what we were implicitly inverting in equation \ref{eqn:matrixprojfromwedge} is answered.

\end{document}               % End of document.
