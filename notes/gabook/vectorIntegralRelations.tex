\documentclass{article}

\input{../peeters_macros.tex}
\newcommand{\grad}[0]{\nabla}
\newcommand{\PD}[2]{\frac{\partial {#2}}{\partial {#1}}}
\newcommand{\Abs}[1]{\left\lvert{#1}\right\rvert}
\newcommand{\gpgrade}[2] {{\left\langle{{#1}}\right\rangle}_{#2}}
\newcommand{\gpgradezero}[1] {\gpgrade{#1}{0}}

% mathmode version of \R{} macro:
\newcommand{\Rm}[1]{\mathbb{R}^{#1}}

\usepackage{color,cite,graphicx}
   % use colour in the document, put your citations as [1-4]
   % rather than [1,2,3,4] (it looks nicer, and the extended LaTeX2e
   % graphics package. 
\usepackage{latexsym,amssymb,epsf} % don't remember if these are
   % needed, but their inclusion can't do any damage

% ointclockwise, ointctrclockwise
\usepackage{esint}
% apparently also in txfonts/pxfonts

\usepackage[bookmarks=true]{hyperref}

\title{ Reconciling vector integral relations. }
\author{Peeter Joot}
\date{ Sept. 18, 2008.  Last Revision: $Date: 2008/09/20 18:34:43 $ }

\begin{document}

\maketitle{}

\tableofcontents

\section{ A hodge podge of relations. }

%I was never satisfied with how vector integral relationships were presented
%to me in my Calculus classes.  Some of these were presented as equations to
%memorize instead of with proof.  

The aim of these notes is to work through proofs of the following 
integral equations

\begin{itemize}

\item Gradient line integral. 

\begin{equation}\label{eqn:lineintegral}
\int_C (\grad f) \cdot d\Br = f \vert_{\partial C}
\end{equation}

\item Jacobian area determinants. 

Change of variables for a double integral

\begin{equation}
dA = dx dy =
\begin{vmatrix}
\PD{u}{x} & \PD{u}{y} \\
\PD{v}{x} & \PD{v}{y} \\
\end{vmatrix}
du dv
= \Abs{ \PD{(u,v)}{(x,y)} } du dv
\end{equation}

In Salus and Hille this is proved using Green's theorem, despite it 
being seeming like the more basic operation.  The greater than two
dimensional cases are not proved at all.

\item Green's theorem. 

\begin{equation}\label{eqn:greens}
\int\int \left(\PD{x}{Q} - \PD{y}{P}\right) dx dy = \ointctrclockwise P dx + Q dy
\end{equation}

\item Stokes theorem. 

\begin{equation}\label{eqn:stokes}
\int\int (\grad \cross \Bf) \cdot \ncap\, dx dy = \ointctrclockwise \Bf \cdot d\Br
\end{equation}

\item Divergence theorem. 

\begin{equation}\label{eqn:divergenceplane}
\int\int \grad \cdot \Bf\, dx dy = \oint \Bf \cdot \ncap\, ds
\end{equation}
FIXME: orientation of integral?

\begin{equation}\label{eqn:divergencevolume}
\int\int\int_V \grad \cdot \Bf\, dx dy dz = \int\int_S \Bf \cdot \ncap\, dA
\end{equation}

\begin{equation}\label{eqn:divergencegrad}
\int\int\int_V \grad \phi\, dV \int\int_S \ncap \phi\, dA
\end{equation}

\begin{equation}\label{eqn:divergencegradcross}
\int\int\int_V \grad \cross \Bf\, dV \int\int_S \Bf \cross \ncap\, dA
\end{equation}


\end{itemize}

In particular I'd like to relate these to the geometrical concepts
of Clifford algebra now that I know how to work with that in a 
differential and algebraic fashion for many sorts of problems.  I am hoping
that working through proofs of these basic identities 
will be enough that I can go on to the more general approaches in 
differential forms and the geometric calculus of Hestenes.

John Denker's 
\href{ http://www.av8n.com/physics/straight-wire.pdf }{ article on the
magnetic field of a straight wire }
gives a simple looking high level description of vector form of Stokes'
theorem in it's Clifford formulation

\begin{equation}\label{eqn:stokesGA}
\int_S \grad \wedge F = \int_{\partial S} F
\end{equation}

This is simple enough looking, but there are some important details left
out.  In particular the grades do not match, so there must be some sort of
implied projection or dot product operations too.

I'd say this suffers from some of the things that I had trouble with in
attempting to study differential forms.

The basic ideas of how to formulate
the curve, surface, volume, ... of integration is not specified.  How to do
that in greater than three dimensions is not trivial seeming to me since
none of the traditional methods of dotting with a normal will not work.

Knowing now about how subspaces can be expressed using blades is likely the
key.  The Clifford algebra ideas seem particularly suited to this as many
of these ideas can be formulated independent of the calculus applications.
One can learn the geometric and algebraic concepts first and then move on
to the Calculus.

\section{ Gradient line integral. }

This is the easiest of the identities to prove.  Introduction of a reciprocal frame $\gamma^{\mu} \cdot \gamma_{\nu} = {\delta^{\mu}}_{\nu}$
also means that we can do in full generalitity with a possibly
non-orthonormal basis of any dimension, and an arbitrary metric.

Write the gradient as normal

\begin{equation*}
\grad = \sum \gamma^{\mu} \PD{x^{\mu}}{} = \gamma^{\mu} \partial_{\mu}
\end{equation*}

Here summation convention with implied sum over mixed upper and lower indexes is employed.

Express the position vector along the curve as
a parameterized path $\Br = \Br(\lambda) = \gamma_{\mu} x^{\mu}$, and use
this to form the element of vector length along the path
%This can be used to form the line integral element that we also need
%the differential element of vector length.  

\begin{equation*}
d\Br = \gamma_{\mu} \frac{d x^{\mu}}{d\lambda} d\lambda
\end{equation*}

Dotting the gradient and the path element we have
\begin{align*}
\grad f \cdot d\Br 
&= \left(\gamma^{\mu} \partial_{\mu} f\right) \cdot \left(\gamma_{\nu} \frac{d x^{\nu}}{d\lambda} \right) d\lambda \\
&= {\delta^{\mu}}_{\nu} \PD{x^{\mu}}{f} \frac{d x^{\nu}}{d\lambda} d\lambda \\
&= \sum \PD{x^{\mu}}{f} \frac{d x^{\mu}}{d\lambda} d\lambda \\
&= \frac{d f}{d \lambda} d\lambda
\end{align*}

Equation \ref{eqn:lineintegral} follows immediately, which we see to be really not much more than the chain rule.

Additionally this can be put into correspondance with equation \ref{eqn:stokesGA}, with the observation that one can write the gradient of a scalar function as a wedge product by the fundamental definition of wedge in terms of grade selection.  For blades $A$ and $B$ with grades $a$ and $b$ respectively, the wedge is

\begin{align*}
A \wedge B = \gpgrade{AB}{a+b}
\end{align*}

Therefore for a scalar function $f$

\begin{align*}
\grad \wedge f = \gpgrade{\grad f}{1+0} = \grad f
\end{align*}

Putting this back together one has the desired result

\begin{equation}\label{eqn:lineintegralwedge}
\int_C (\grad \wedge f) \cdot d\Br = f \vert_{\partial C}
\end{equation}

\subsection{ Motivating the non-orthonormal form of the gradient. }

An additional note about the derivation of this line integral result.  Having done this with the gradient expressed for possibly non-orthonormal frames, 
shows that if played backwards, it provides a nice motivation for the general form of the gradient, in terms
of a such a non-orthonormal basis.  That's a lot more obvious a way to get at this result than my previous way of observing that the Euler-Lagrange
equations when summed in vector form imply that this is the required form of the gradient.

\section{ Jacobian area determinants. }

Next in ease of proof is the Jacobian determinant.  This actually comes largely for free since we can utilize the wedge product to
express areas.

\begin{figure}[htp]
\centering
\includegraphics[totalheight=0.4\textheight]{planeParameterization}
\caption{Plane parameterization}\label{fig:planeParameterization}
\end{figure}

Introduce a two vector parameterization of the area as in figure \ref{fig:planeParameterization}

\begin{equation*}
\Br = \gamma_{i} \phi^i(u,v)
\end{equation*}

Provided that the partials are not colinear at the point of interest, we can compute the area of the parallogram spanned by these

\begin{align*}
d\BA 
&= \left(\PD{u}{\Br} du\right) \wedge \left(\PD{v}{\Br} dv\right) \\
&= \left(\gamma_{i} \PD{u}{\phi^i}\right) \wedge \left(\gamma_{j} \PD{v}{\phi^j} \right) du dv \\
&= \gamma_{i} \wedge \gamma_{j} \PD{u}{\phi^i} \PD{v}{\phi^j} du dv \\
&= \sum_{i<j} \gamma_{i} \wedge \gamma_{j} \left( \PD{u}{\phi^i} \PD{v}{\phi^j} - \PD{u}{\phi^i} \PD{v}{\phi^i} \right) du dv \\
&= \sum_{i<j} \gamma_{i} \wedge \gamma_{j} \PD{(u,v)}{(\phi^i,\phi^j)} du dv \\
\end{align*}

Here $d\BA$ is a bivector area element, so in the purely two dimensional case, where this is constrained to a plane, the scalar area element
is recovered by dividing by the plane unit pseudoscalar having the same orientation as this bivector.

One can also see how the same idea will be of use later in the Stokes' generalization of Green's theorem (considering a surface element small enough to be considered planar).

For now, considering just the 2D case we have, to divide through by the plane unit pseudoscalar $i = \Be_1\Be_2$ produced by the product of two orthonormal vectors we want to calculate the product:

\begin{align*}
\inv{i} \gamma_{1} \wedge \gamma_{2} 
&= (\Be_2 \wedge \Be_1) \cdot (\gamma_{1} \wedge \gamma_{2}) \\
&= \Be_2 \cdot (\Be_1 \cdot (\gamma_{1} \wedge \gamma_{2})) \\
&= \Be_2 \cdot ( (\Be_1 \cdot \gamma_{1}) \gamma_{2} -(\Be_1 \cdot \gamma_{2}) \gamma_{1} ) \\
&= (\Be_1 \cdot \gamma_{1}) (\Be_2 \cdot \gamma_{2}) -(\Be_1 \cdot \gamma_{2}) (\Be_2 \cdot \gamma_{1}) \\
&=
\begin{vmatrix}
\Be_1 \cdot \gamma_{1} & \Be_1 \cdot \gamma_{2} \\
\Be_2 \cdot \gamma_{1} & \Be_2 \cdot \gamma_{2}
\end{vmatrix}
\end{align*}

Thus the (scalar) area element is

\begin{align}\label{eqn:jacobianframe}
dA =
\begin{vmatrix}
\Be_1 \cdot \gamma_{1} & \Be_1 \cdot \gamma_{2} \\
\Be_2 \cdot \gamma_{1} & \Be_2 \cdot \gamma_{2}
\end{vmatrix}
\PD{(u,v)}{(\phi^1,\phi^2)} du dv
\end{align}

This is a slightly more general form than we are used to seeing since the position vector parameterization was allowed to be expresed in terms
of an arbitrary (possibly non-orthonormal) basis.  Also observe that the coefficients in the determinant preceding the Jacobian are exactly those of the matrix of the linear transformation between the two sets of basis vectors.

\subsection{ Orthonormal parameterization. } 

For the special (and usual) case of an orthonormal parameterization

\begin{align*}
\Br = x(u,v) \Be_1 + y(u,v) \Be_2
\end{align*}

the product of determinants in \ref{eqn:jacobianframe} takes the usual form

\begin{align}\label{eqn:jacobianarea}
dx dy = \PD{(u,v)}{(x,y)} du dv.
\end{align}

Now the danger of an expression like \ref{eqn:jacobianarea} is that the differential notation for the determinant makes it seem almost
obvious.  Now, if you understand the wedge product origin you can state
that obviousness after a little bit of algebra.  However, in a book like Salus and Hille (used for Calculus I-III in UofT Engineering) they
can't even derive this two dimensional case til close to the end of the book, since they required Green's theorem to do so.  I'd say that in that case it is not really so obvious.  The geometrical background just isn't there.

Note that there are degrees of freedom to alter the sign given an arbitrary pseudoscalar.  This illustrates why the absolute value of the Jacobian determinant is used in some circumstances.  Less dodgy is to say the positive area element after change of variables in a specific region is produced by dividing out the pseudoscalar with the same orientation as the area element bivector.

It is also not too hard to see that this idea will also work for change of variables for volume and higher
dimensional volume elements, after wedging N partials.  We just have to divide by the spatial (or higher dimensional) pseudoscalar of the
same orientation associated with the parameterization.

\subsection{ Surface area in higher dimensions. }

As well as being able to use these ideas to express scalar area and volume, or higher dimensional generalizations, this can be used to calculate surface area in any number of dimensions.  For a two parameter vector parameterization of a surface $\Br(u,v)$ we can write

\begin{equation}\label{eqn:surfacearea}
A = \int\int \inv{I_2(u,v)} \left(\PD{u}{\Br} \wedge \PD{v}{\Br}\right) du dv
\end{equation}

Here $I_2(u,v)$ is the unit pseudoscalar for the tangent space of the surface at the point of interest with the orientation of the bivector 
$d\BA = \PD{u}{\Br} \wedge \PD{v}{\Br}$.

This is in fact equivalent to the familiar normal form in 3D expressed in terms
of a cross product

\begin{equation}
A = \int\int \left(\PD{u}{\Br} \cross \PD{v}{\Br}\right) \cdot \ncap(u,v) du dv
\end{equation}

but the expression of equation \ref{eqn:surfacearea}, holds for any number of dimensions $N \ge 2$.  As with the wedge product form, we have a requirement that the parameterization is not degenerate at any point, so the 3D de-generalization of our requirement that
$\PD{u}{\Br} \wedge \PD{v}{\Br} \ne 0$
on the region of the surface of interest means that for 3D we simply require
$\PD{u}{\Br} \cross \PD{v}{\Br} \ne 0$.

A consequence of non-degeneracy for the region of the surface area being integrated means that the sign of the bivector cannot change sign, so we have equivalance with the concept of outwards normal to the surface by picking the tangent space unit pseudoscalar to have the same orientation as the bivector area element.

\section{ Green's theorem. }

\subsection{ Attempt to arrive at a more natural vector form for Green's theorem. }

It is pretty clear glancing at equation \ref{eqn:greens}, that the left
hand side can likely be expressed as the curl of a vector.  By curl here
is meant the more natural bivector "curl", where we form the operator $\grad \wedge$.

To get a feel for this operation, here is a dumb expansion of such a product,
where an orthonormal basis for the plane is assumed.  Introduce a vector

\begin{equation*}
\Bf = P \Be_1 + Q \Be_2
\end{equation*}

then compute
\begin{align*}
\grad \wedge \Bf
&= \left( \Be_1 \partial_1 + \Be_2 \partial_2 \right) \wedge \left( \Be_1 P + \Be_2 Q \right) \\
&= (\Be_{1} \wedge \Be_2) \left( \partial_1 Q - \partial_2 P \right) \\
&= i \left( \partial_1 Q - \partial_2 P \right) \\
\end{align*}

This allows for writing the scalar alternating form as a vector relation

\begin{equation}\label{eqn:altpartial}
\partial_1 Q - \partial_2 P = - i(\grad \wedge \Bf).
\end{equation}

Let's continue to put the Green's theorem area integral in complete vector form.
Since the area element can be expressed in vector form, introduce a vector parameterization $\Br = x \Be_1 + y \Be_2$.  The element
of area expressed in terms of this parameterization is

\begin{equation*}
dA = \inv{i}\left( \PD{u}{\Br} \wedge \PD{v}{\Br} \right) du dv
\end{equation*}

Re-assembling the scalar alternating equation \ref{eqn:altpartial}, we can put the area integral
completely in vector form

\begin{equation}\label{eqn:greenlikeLHS}
\int\int - i(\grad \wedge \Bf) \inv{i}\left( \PD{u}{\Br} \wedge \PD{v}{\Br} \right) du dv
= -\int\int (\grad \wedge \Bf) \left( \PD{u}{\Br} \wedge \PD{v}{\Br} \right) du dv
\end{equation}

Considering the total differential of the position vector, it makes sense to introduce vector differential elements to
express this

\begin{equation*}
d\Br = \PD{u}{\Br} du + \PD{v}{\Br} dv = d\Bu + d\Bv
\end{equation*}

We can then rewrite equation \ref{eqn:greenlikeLHS}
once more in a slightly cleaner form, independent of the specific parameterization

\begin{equation}\label{eqn:greenlikeLHSFinal}
-\int\int (\grad \wedge \Bf) \cdot (d\Bu \wedge d\Bv) = -\int\int (\grad \wedge \Bf) \cdot d\BA
\end{equation}

Here we see that it becomes natural to work with the oriented bivector area element $d\BA = d\Bu \wedge d\Bv$.

Having arrived at what is likely the most natural vector form \ref{eqn:greenlikeLHSFinal} for the area
integral.

We should be able to 
integrate this in it's most general form, dropping references to the original $x$, and $y$ coordinates.
If this is the correct form, we should end up with a vector line integral around a path after doing so, and thus prove
Green's theorem.

FIXME: thought this, but am having trouble.  Will try from the loop integral instead.

\subsection{ Expanding the area integral in terms of an arbitrary parameterization. }

The integral expression of equation \ref{eqn:greenlikeLHSFinal} is a form that can be examined independent of the original planar Green's theorem motivation.  Let's expand
this picking an arbitrary parameterization for both the area element and the vector.  There will also be no need for now to work with the original 2D vectors.

Given a two parameter vector parameterization of a surface, and a reciprocal frame representation of our curled vector:

\begin{align*}
\Br(u,v) &= \gamma_i {x^i}(u,v) \\
\Bf &= \gamma^i {f_i}
\end{align*}

a bivector parallelogram surface element can be then be expressed as

\begin{align*}
d\BA 
&= \left(\PD{u}{\Br} du\right) \wedge \left(\PD{v}{\Br} dv\right) \\
&= \left(\gamma_i \wedge \gamma_j \right) \PD{u}{x^i} \PD{v}{x^j} du dv \\
\end{align*}

and our differential form is

\begin{align*}
\left(\grad \wedge \Bf\right) \cdot d\BA
&= \left( \gamma^i \wedge \gamma^j \right) \cdot \left(\gamma_k \wedge \gamma_m \right) \PD{x^{i}}{f_j} \PD{u}{x^k} \PD{v}{x^m} du dv \\
&= \left( {\delta^i}_m {\delta^j}_k -{\delta^i}_k {\delta^j}_m \right) \PD{x^{i}}{f_j} \PD{u}{x^k} \PD{v}{x^m} du dv \\
&= \PD{x^{i}}{f_j} \left( \PD{u}{x^j} \PD{v}{x^i} -\PD{u}{x^i} \PD{v}{x^j} \right) du dv \\
&= -\PD{x^{i}}{f_j} \PD{(u,v)}{(x^i, x^j)} du dv \\
&= -\sum_{i<j} \left( \PD{x^{i}}{f_j} -\PD{x^{j}}{f_i} \right) \PD{(u,v)}{(x^i, x^j)} du dv \\
\end{align*}

The trailing differential form here is just the Jacobian form for change of variables, so we have

\begin{align}\label{eqn:areaintegral}
-\left(\grad \wedge \Bf\right) \cdot d\BA
&= \sum_{i<j} \left( \PD{x^{i}}{f_j} -\PD{x^{j}}{f_i} \right) \PD{(u,v)}{(x^i, x^j)} du dv \\
&= \sum_{i<j} \left( \PD{x^{i}}{f_j} -\PD{x^{j}}{f_i} \right) dx^i dx^j
\end{align}

A result that is independent of dimension or any particular parameterization of the area.

\subsection{ Calculating the line integral. }

The expectation is that calculation of the line integral

\begin{equation}
I = \ointctrclockwise \Bf \cdot d\Br,
\end{equation}

around any loop in a plane will match equation \ref{eqn:areaintegral}.  This can
be verified with direct calculation.

FIXME: insert picture.

Again parameterizing the points around the loop with a vector $\Br = \Br(u,v)$ the integral can be split into four parts

\begin{align*}
I_1 &=  \int_{u=u_0}^{u_1} \Bf(\Br(u,v_0)) \cdot \PD{u}{\Br(u,v_0)} du \\
I_2 &=  \int_{v=v_0}^{v_1} \Bf(\Br(u_1,v)) \cdot \PD{v}{\Br(u_1,v)} dv \\
I_3 &= -\int_{u=u_0}^{u_1} \Bf(\Br(u,v_1)) \cdot \PD{u}{\Br(u,v_1)} du \\
I_4 &= -\int_{v=v_0}^{v_1} \Bf(\Br(u_0,v)) \cdot \PD{v}{\Br(u_0,v)} dv \\
\end{align*}

Summing these we have
\begin{align*}
I
&= I_1 + I_3 + I_2 + I_4  \\
&=
\int_{u=u_0}^{u_1} du \left(
\Bf(\Br(u,v_0)) \cdot \PD{u}{\Br(u,v_0)} 
-\Bf(\Br(u,v_1)) \cdot \PD{u}{\Br(u,v_1)} 
\right) \\
&+\int_{v=v_0}^{v_1} dv
\left(
\Bf(\Br(u_1,v)) \cdot \PD{v}{\Br(u_1,v)} 
-\Bf(\Br(u_0,v)) \cdot \PD{v}{\Br(u_0,v)}
\right)
\end{align*}

Writing out the vectors in components, utilizing reciprocal frames as in the area integral,
we have $\Bf = \gamma^i f_i$, and $\Br = \gamma_i x^i$ the dot products can be expanded and the sums
pulled out of the integral

\begin{align*}
I
&=
\sum
\int_{u=u_0}^{u_1} du \left(
f_i(\Br(u,v_0)) \PD{u}{x^i(u,v_0)} 
-f_i(\Br(u,v_1)) \PD{u}{x^i(u,v_1)} 
\right) \\
&+\sum \int_{v=v_0}^{v_1} dv
\left(
f_i(\Br(u_1,v)) \PD{v}{x^i(u_1,v)} 
-f_i(\Br(u_0,v)) \PD{v}{x^i(u_0,v)}
\right) \\
\end{align*}

The difference of functions here can be written as the integral of partials over the
$[u_0,u_1]$ or $[v_0,v_1]$ ranges.  This can be more obvious if one temporarily
introduces helper functions of one variable describing the difference (FIXME: do so like on paper notes).

Such an integration gives

\begin{align*}
I
&=
\sum
\int_{u=u_0}^{u_1} du \left(
f_i(x^j(u,v_0)) \PD{u}{x^i(u,v_0)} 
-f_i(x^j(u,v_1)) \PD{u}{x^i(u,v_1)} 
\right) \\
&+\sum \int_{v=v_0}^{v_1} dv
\left(
f_i(x^j(u_1,v)) \PD{v}{x^i(u_1,v)} 
-f_i(x^j(u_0,v)) \PD{v}{x^i(u_0,v)}
\right) \\
&=
\sum
-\int_{u=u_0}^{u_1} du 
\int_{v=v_0}^{v_1} dv \PD{v}{} \left(f_i(x^j(u,v)) \PD{u}{x^i(u,v)} \right)
+\sum 
\int_{v=v_0}^{v_1} dv
\int_{u=u_0}^{u_1} du \PD{u}{} \left(f_i(x^j(u,v)) \PD{v}{x^i(u,v)} \right) \\
&=
\sum \int\int \left(
\PD{u}{} \left(f_i \PD{v}{x^i} \right) 
-\PD{v}{} \left(f_i \PD{u}{x^i} \right) 
\right) du dv \\
&=
\sum \int\int \left(
\PD{u}{f_i} \PD{v}{x^i}
+f_i \PD{u}{} \PD{v}{x^i}
-\PD{v}{f_i} \PD{u}{x^i}
-f_i \PD{v}{} \PD{u}{x^i}
\right) 
du dv \\
&=
\sum \int\int \left(
\PD{u}{f_i} \PD{v}{x^i}
-\PD{v}{f_i} \PD{u}{x^i}
\right) 
du dv \\
\end{align*}

Sufficient continuity in the coordinates $x^i$ has been assumed here for mixed partial equality.  Expanding out
the partials with respect to $u$ and $v$ in terms of the coordinates one has

\begin{align*}
I
&=
\sum \int\int 
\PD{x^j}{f_i} 
\left(
\PD{u}{x^j}
\PD{v}{x^i}
-
\PD{v}{x^j}
\PD{u}{x^i}
\right) 
du dv \\
&= -\sum \int\int \PD{x^j}{f_i} \PD{(u,v)}{(x^i,x^j)} du dv \\
\end{align*}

Summing over $i<j$ and $j>i$, with a switch of variables we have
\begin{equation}
I
= 
\sum_{i<j} \int\int 
\left(
\PD{x^i}{f_j}
-\PD{x^j}{f_i}
\right)
\PD{(u,v)}{(x^i,x^j)} du dv 
\end{equation}

which equals the area integral of equation \ref{eqn:areaintegral}.  We have therefore proved a hybrid Green's-like
and Stokes-like theorem

\begin{equation}\label{eqn:stokesplane}
\int\int \left(\grad \wedge f\right) \cdot d\BA = \ointclockwise \Bf \cdot d\Br
\end{equation}

Like the \R{2} Green's result this applies to a looping path integral in a plane, but this
form is valid for $\Bf \in \Rm{N}$ as well.  In particular, like Stokes' law this this applies to \R{3}.

I set out only to prove
Green's theorem, but basically got the general proof without much extra work (using $i,j$ instead of $1,2$)
once the area integral was expressed as in terms of the wedge curl.

Note carefully that there is a
difference in the direction of the path integral compared to the cross product form of Stokes' law since
the squared bivector on the LHS introduces a negation.

As far as generalizing this to a non-planar surface.
The usual additional arguments to express a general 
surface as a triangularized set of differential plane elements, with summation cancelling opposing interior
contributions, is required to complete the proof.  The interesting (to me) part is the
plane to line integral Stokes law equation has been expressed in its \R{N} generality, and without
omission of the important loop orientation, and area sense.

\subsection{ Application to formulate Stokes law for a plane loop. }

We can obtain the \R{3} cross product form of Stokes law (assuming the triangularization generalization has been
done) with some basic algebraic manipulations.

Let $\ncap d\BA = i dA$, where $i = \Be_1\Be_2\Be_3$ is the \R{3} pseudoscalar.  Inserting back into 
the differential form of the area integral of \ref{eqn:stokesplane} we have

\begin{align*}
\left(\grad \wedge \Bf\right) \cdot d\BA
&= \gpgradezero{ (\grad \wedge \Bf) \ncap i dA} \\
&= \gpgradezero{ i (\grad \cross \Bf) \ncap i dA} \\
&= -\gpgradezero{ (\grad \cross \Bf) \ncap } dA \\
&= - (\grad \cross \Bf) \cdot \ncap dA \\
\end{align*}

This recovers the cross product form of Stokes law

\begin{equation}
\int\int (\grad \cross \Bf) \cdot \ncap dA = - \ointclockwise \Bf \cdot d\Br = \ointctrclockwise \Bf \cdot d\Br.
\end{equation}

Note that the surface here does not have to have any notion of outwards facing normal (this makes no sense for a plane for example), as is usually used
in the description of the \R{3} vector form of Stokes' law.
That means some care is required in the definition of the unit normal $\ncap$.
There is however an orientation for this vector, and that is fixed by the
pseudoscalar.  Supposing that one picks $\ncap$ such that $\ncap d\BA \inv{i} = dA > 0$.  With such a selection, and
$d\BA = \ucap \vcap dA$, the triplet of vectors is oriented such that $\ncap \ucap \vcap = i$.  There
is no notion of handedness required, which is a very \R{3} concept, despite having a notion of
explicitly oriented vectors.

\section{ Divergence theorem. }

This part is left for another day (will have to do some of this on paper first since I don't know where I'm going
yet.)

\end{document}               % End of document.
