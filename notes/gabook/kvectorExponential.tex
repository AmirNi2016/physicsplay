\documentclass{article}      % Specifies the document class

\input{../peeters_macros.tex}

\DeclareMathOperator{\Exp}{e}
\DeclareMathOperator{\Rej}{Rej}
\newcommand{\Bcap}[0]{\hat{\BB}}
\newcommand{\Babs}[0]{\abs{\BB}}
\newcommand{\gpgrade}[2] {{\left\langle{{#1}}\right\rangle}_{#2}}
\newcommand{\gpgradezero}[1] {\gpgrade{#1}{0}}
\newcommand{\gpgradetwo}[1] {\gpgrade{#1}{2}}
\newcommand{\gpgradefour}[1] {\gpgrade{#1}{4}}

\newcommand{\ddu}[1] {\frac {d{#1}} {du}}

%
% The real thing:
%

                             % The preamble begins here.
\title{} % Declares the document's title.
\author{Peeter Joot}         % Declares the author's name.
%\date{}        % Deleting this command produces today's date.

\begin{document}             % End of preamble and beginning of text.

\maketitle{}

\section{ Motivation }

Exponentials of bivectors and complex numbers are useful as generators of rotations, and expontials of
square matrices can be used in linear differential equation solution.

How about exponentials of vectors?

Because any power of a vector can be calculated it should be perfectly well defined to use the expontial infinite series with k-vector parameters.  An 
exponential function of this form will be expanded explicitly and compared to the real number result.  The first
derivitive will also be calculated to examine it's form.

\section{ Vector Exponential }

The infinite series representation of the exponential defines a function for any $x$ that can be repeatedly multiplied
with it self.

\begin{equation}
\Exp^x = \sum_{k=0}^{\infty} \frac{x^k}{k!}
\end{equation}

Depending on the type of the parameter $x$ this may or may not have properties consistent with
the real number exponential function.
For a vector $\Bx = \xcap\abs{\Bx}$, after splitting the sum into even and odd terms this infinite series takes the
following form:

\begin{equation*}
\Exp^{\pm\Bx}
= 
\sum_{k=0}^{\infty} \frac{\Bx^{2k}}{(2k)!}
\pm
\sum_{k=0}^{\infty} \frac{\abs{\Bx}^{2k}\abs{\Bx}\xcap}{(2k+1)!} 
\end{equation*}

\begin{equation}
\implies
\Exp^{\pm\Bx}
= 
\cosh\abs{\Bx}
\pm
\xcap \sinh\abs{\Bx}
\end{equation}

One can also employ symmetric and antisymmetric sums to write the hyperbolic functions in terms of the
vector exponentials:

\[
\cosh\abs{\Bx} = \frac{\Exp^\Bx + \Exp^{-\Bx}}{2}
\]
\[
\sinh\abs{\Bx} = \frac{\Exp^\Bx - \Exp^{-\Bx}}{2\xcap}
\]

\subsection{ Vector Exponential derivative }
One of the defining properties of the exponential is that it's derivitive is related to itself

\[
\ddu{\Exp^{x}} = \ddu{x}\Exp^{x} = \Exp^{x} \ddu{x}
\]

For a vector parameter $\Bx$ one shouldn't generally expect that.  Let's expand this to see the form of this
derivative:

\begin{align*}
\ddu{\Exp^{\Bx}} 
&= \ddu{}( \cosh\abs{\Bx} + \xcap \sinh\abs{\Bx} ) \\
&= ( \sinh\abs{\Bx} + \xcap \cosh\abs{\Bx} ) \ddu{\abs{\Bx}} + \ddu{\xcap} \sinh\abs{\Bx} \\
\end{align*}

Can calculate $\ddu{\abs{\Bx}}$ with the usual trick:

\[
\ddu{\abs{\Bx}^2} = 2\abs{\Bx}\ddu{\abs{\Bx}} = \ddu{\Bx}\Bx + \Bx\ddu{\Bx} = 2 \ddu{\Bx} \cdot \Bx
\]

\[
\implies
\ddu{\abs{\Bx}} = \ddu{\Bx} \cdot \xcap
\]

Calculation of $\ddu{\xcap}$ uses this result:

\begin{align*}
\ddu{\xcap}
&= \ddu{}\frac{\Bx}{\abs\Bx}  \\
&= \ddu{\Bx}\inv{\abs\Bx} - \frac{\Bx}{\abs{\Bx}^2}\ddu{\abs{\Bx}} \\
&= \ddu{\Bx}\inv{\abs\Bx} - \frac{\Bx}{\abs{\Bx}^2} \ddu{\Bx} \cdot \xcap \\
&= \inv{\abs\Bx}\left( \ddu{\Bx} - \xcap \left(\ddu{\Bx} \cdot \xcap\right) \right) \\
&= \frac{\xcap}{\abs\Bx} \left(\xcap \wedge \ddu{\Bx} \right) \\
&= \inv{\abs\Bx} {\Rej_{\xcap}\left(\ddu{\Bx}\right)} \\
\end{align*}

Putting these together one write the derivative in a few ways:

\begin{align*}
\ddu{\Exp^{\Bx}} 
&= 
\left(\ddu{\Bx} \cdot \xcap\right) \xcap
( \xcap \sinh\abs{\Bx} + \cosh\abs{\Bx} ) 
 + \frac{\xcap}{\abs\Bx} \left(\xcap \wedge \ddu{\Bx} \right) \sinh\abs{\Bx} \\
&= 
\xcap \left(\ddu{\Bx} \cdot \xcap\right)\Exp^{\Bx}
 + \frac{\xcap}{\abs\Bx} \left(\xcap \wedge \ddu{\Bx} \right) \sinh\abs{\Bx} \\
&= 
\Proj_{\xcap}\left(\ddu{\Bx}\right) \Exp^{\Bx}
 + \inv{\abs\Bx} \Rej_{\xcap}\left(\ddu{\Bx}\right) \sinh\abs{\Bx} \\
\end{align*}

This is considerably different from the real number case.  Only when the vector $\Bx$ and all its variation
$\ddu{\Bx}$ are colinear does $\ddu{\Bx} = \Proj_{\xcap}\left(\ddu{\Bx}\right)$ for the real number like result:

\begin{equation}
\ddu{\Exp^{\Bx}} = \ddu{\Bx} \Exp^{\Bx} = \Exp^{\Bx} \ddu{\Bx} 
\end{equation}

Note that the $\sinh$ term can be explicitly removed

\begin{align*}
\ddu{\Exp^{\Bx}} 
=
\left(\xcap \left(\ddu{\Bx} \cdot \xcap\right) - \inv{2\abs\Bx}\left(\xcap \wedge \ddu{\Bx} \right) \right) \Exp^{\Bx}
 - \inv{2\abs\Bx}\left(\xcap \wedge \ddu{\Bx} \right) \Exp^{-\Bx} \\
\end{align*}

, but without a $\Rej_{\xcap}\left(\ddu{\Bx}\right) = 0$
constraint, there will always be a term that is not proportional to $\Exp^{\Bx}$.

\section{ Bivector Exponential. }

The bivector expontial can be expanded utilizing its complex number equivalence:

\begin{align*}
\Exp^{\BB}
&= \Exp^{\Bcap\Babs} \\
&= \cos{\Babs} + \Bcap\sin{\Babs} \\
\end{align*}

So, taking the derivitive we have

\begin{align*}
(\Exp^{\BB})'
&= \left(-\sin\Babs + \Bcap\cos\Babs\right)\Babs' + \Bcap' \sin\Babs \\
&= \Bcap \left(\Bcap\sin\Babs + \cos\Babs\right)\Babs' + \Bcap' \sin\Babs \\
&= \Bcap \Exp^{\BB} \Babs' + \Bcap' \sin\Babs \\
&= \Exp^{\BB} \Bcap \Babs' + \Bcap' \sin\Babs \\
\end{align*}

\subsection{ bivector magnitude derivative }

As with the vector case we've got a couple helper derivatives required.  Here's the first:

\begin{align*}
({\Babs^2})' &= 2\Babs\Babs' = -(\BB\BB' + \BB'\BB) \\
\implies \\
{\Babs}' &= -\frac{\Bcap\BB' + \BB'\Bcap}{2} \\
\end{align*}

Unlike the vector case this last expression is not a bivector dot product $= -\Bcap\cdot \BB'$ since there could be a
$\gpgradefour{}$ term that this symmetric sum would also include.
That wedge term would be zero for example if $\BB = \Bx \wedge \Bk$ for a constant vector $\Bk$.

\subsection{ Unit bivector derivative }

Now calculate $\Bcap'$:

\begin{align*}
\Bcap'
&= \frac{\BB'}{\Babs} - \frac{\BB}{\Babs^2}\Babs' \\
&= \inv{\Babs}\left( \BB' + {\Bcap}\frac{\Bcap\BB' + \BB'\Bcap}{2} \right) \\
&= \inv{2\Babs}\left( \BB' + \Bcap\BB'\Bcap \right) \\
&= \frac{\Bcap}{\Babs}\frac{-\Bcap\BB' + \BB'\Bcap}{2} \\
\end{align*}

Thus, the derivative is a scaled bivector rejection:
\begin{equation}
\Bcap' = \inv{\BB}\gpgradetwo{\Bcap\BB'}
\end{equation}

Although this appears different from a unit vector derivative, a slight adjustment highlights the
similarities:

\begin{align*}
\rcap' 
&= \frac{\rcap}{\abs\Br}\rcap \wedge \Br' \\
&= \inv{\Br}\gpgradetwo{\rcap\Br'} \\
\end{align*}

Note however the sign inversion that is built into the bivector inversion.

\subsection{ combining results. }

Putting the individual results back together we have:

\begin{equation}
(\Exp^{\BB})'
= \inv{\Bcap}\frac{\Bcap\BB' + \BB'\Bcap}{2} \Exp^{\BB} + \inv{\BB}\gpgradetwo{\Bcap\BB'} \sin\Babs 
\end{equation}

In general with bivectors we can have two sorts of perpendicularity.  The first is perpendicular but intersecting (generated by the grade 2 term of the product), and perpendicular with no common line (generated by the grade 4 term).
In \R{3} we have only the first sort.

With a restriction that the derivative only changes the bivector enough to introduce the first term, this
exponential deriviative is reduced to:

\begin{align*}
(\Exp^{\BB})'
&= \inv{\Bcap}\Bcap \cdot \BB' \Exp^{\BB} + \inv{\BB}\gpgradetwo{\Bcap\BB'} \sin\Babs \\
&= \Proj_{\Bcap}(\BB') \Exp^{\BB} + \inv{\Babs}{\Rej_{\Bcap}(\BB')} \sin\Babs \\
\end{align*}

Only if the bivector variation is in the same plane as the bivector itself can the $\gpgradetwo{}$ term be dropped
in which case, since the derivative will equal it's projection one has:

\begin{equation}
(\Exp^{\BB})' = \BB' \Exp^{\BB} = \Exp^{\BB} \BB' 
\end{equation}

\end{document}               % End of document.
