\documentclass{article}

\input{../peeters_macros.tex}
\input{../peeters_macros2.tex}
\newcommand{\EE}[0]{\boldsymbol{\mathcal{E}}}
\newcommand{\HH}[0]{\boldsymbol{\mathcal{H}}}
%\newcommand{\PDSq}[2]{\frac{\partial^2 {#2}}{\partial {#1}^2}}

\usepackage[bookmarks=true]{hyperref}

\usepackage{color,cite,graphicx}
   % use colour in the document, put your citations as [1-4]
   % rather than [1,2,3,4] (it looks nicer, and the extended LaTeX2e
   % graphics package. 
\usepackage{latexsym,amssymb,epsf} % don't remember if these are
   % needed, but their inclusion can't do any damage


\title{ Fourier series Vacuum Maxwell's equations. }
\author{Peeter Joot}
\date{ Feb 03, 2009.  Last Revision: $Date: 2009/02/05 04:51:34 $ }

\begin{document}

\maketitle{}

\tableofcontents

\section{ Motivation. }

In \cite{bohm1989qt}, 
after finding a formulation of Maxwell's equations that he likes, his next
step is to assume the electric and magnetic fields can be expressed in 
a 3D Fourier series form, with periodicity in some repeated volume 
of space, and then procedes to evaluate the energy of the 
field.

\section{ Setup. }

Let's try this.  Instead of using the sine and cosine fourier series
which looks more complex than it ought to be, use of a complex exponential
ought to be cleaner.

\subsection{ 3D Fourier series in complex exponential form. }

For a multivector function $f(\Bx, t)$, periodic in some rectangular spatial volume, let's assume that we have a
3D Fourier series representation.

Define the element of volume for our fundamental wavelengths to be the region bounded by three intervals in the $x^1, x^2, x^3$ directions respectively

\begin{align*}
I_1 &= [ a^1, a^1 + \lambda_1 ] \\
I_2 &= [ a^2, a^2 + \lambda_2 ] \\
I_3 &= [ a^3, a^3 + \lambda_3 ] \\
\end{align*}

Our assumed Fourier representation is then

\begin{align*}
f(\Bx, t) &= \sum_{\Bk} \hat{f}_{\Bk}(t) \exp\left( - \sum_j \frac{2 \pi i k_j x^j}{\lambda_j} \right)
\end{align*}

Here $\hat{f}_{\Bk} = \hat{f}_{\{k_1, k_2, k_3\}}$ is indexed over a triplet of integer values, and the $k_1, k_2, k_3$ indexes take on all integer values in the $[-\infty, \infty]$ range.

Note that we also wish to allow $i$ to not just be a generic complex number, but allow for the use of either the Euclidian or Minkowski pseudoscalar

\begin{align*}
i = \gamma_0 \gamma_1 \gamma_2 \gamma_3 = \sigma_1 \sigma_2 \sigma_3
\end{align*}

Because of this we should not assume that we can commute $i$, or our exponentials with the functions $f(\Bx,t)$, or $\hat{f}_{\Bk}(t)$.

\begin{align*}
\int_{x^1 = \partial I_1} &\int_{x^2 = \partial I_2} \int_{x^3 = \partial I_3} f(\Bx, t) 
e^{ 2 \pi i m_j x^j/\lambda_j}
dx^1 dx^2 dx^3 \\
&= \sum_{\Bk} \hat{f}_{\Bk}(t) \int_{x^1 = \partial I_1} \int_{x^2 = \partial I_2} \int_{x^3 = \partial I_3} dx^1 dx^2 dx^3 e^{ 2 \pi i (m_j - k_j) x^j/\lambda_j} dx^1 dx^2 dx^3
\end{align*}

But each of these integrals is just $\delta_{\Bk,\Bm} \lambda_1 \lambda_2 \lambda_3$, giving us

\begin{align*}
\hat{f}_{\Bk}(t)
&= \inv{\lambda_1 \lambda_2 \lambda_3 } \int_{x^1 = \partial I_1} \int_{x^2 = \partial I_2} \int_{x^3 = \partial I_3} f(\Bx, t) \exp\left( \sum_j \frac{2 \pi i k_j x^j}{\lambda_j} \right) dx^1 dx^2 dx^3 \\
\end{align*}

For short lets write this as

\begin{align}
f(\Bx, t) &= \sum_{\Bk} \hat{f}_{\Bk}(t) \exp\left( - \frac{2 \pi i k_j x^j }{\lambda_j} \right) \\
\hat{f}_{\Bk}( t) &= \inv{V} \int f(\Bx, t) \exp\left( \frac{2 \pi i k_j x^j}{\lambda_j} \right) d^3 x
\end{align}

\subsection{ Vacuum equation. }

Now that we have a desirable seeming Fourier series representation, we 
want to apply this to Maxwell's equation for the vacuum.  We will use the 
STA formulation of Maxwell's equation, but use the unit convention of Bohm's
book.

In \cite{PJrayleighJeans} the STA equivalent to Bohm's notation 
for Maxwell's equations was found to be

\begin{align}\label{eqn:maxwell}
F &= \EE + i\HH \\
J &= (\rho + \Bj) \gamma_0 \\
\grad F &= 4 \pi J
\end{align}

This is the cgs form of Maxwell's equation, but with the old style $\HH$ for $c\BB$, and $\EE$ for $\BE$.  In more recent texts $\EE$ is reserved for electromotive flux.  In this set of notes I use Bohm's notation, since the aim is to clarify for myself aspects of his treatment.

For the vacuum equation, we make an explicit spacetime split by premultiplying with $\gamma_0$

\begin{align*}
\gamma_0 \grad 
&= \gamma_0 (\gamma^0 \partial_0 + \gamma^k \partial_k) \\
&= \partial_0 - \gamma^k \gamma_0 \partial_k \\
&= \partial_0 + \gamma_k \gamma_0 \partial_k \\
&= \partial_0 + \sigma_k \partial_k \\
&= \partial_0 + \spacegrad \\
\end{align*}

So our vacuum equation is just

\begin{align}\label{eqn:vacuumMaxwell}
(\partial_0 + \spacegrad) F = 0
\end{align}

\section{ First order vacuum solution with Fourier series. }

Now that a notation for the 3D Fourier series has been established, we
can assume a series solution for our field of the form

\begin{align}\label{eqn:assumed}
F(\Bx,t) = \sum_{\Bk} \hat{F}_{\Bk}(t) e^{-2\pi i k_j x^j/\lambda_j}
\end{align}

can now apply this to the vacuum Maxwell equation \ref{eqn:vacuumMaxwell}.
This gives us

\begin{align*}
\sum_{\Bk} \left(\partial_t \hat{F}_{\Bk}(t) \right) e^{-2\pi i k_j x^j/\lambda_j}
&= -c \sum_{\Bk, m} \sigma^m \hat{F}_{\Bk}(t) \PD{x^m}{} e^{-2\pi i k_j x^j/\lambda_j} \\
&= -c \sum_{\Bk, m} \sigma^m \hat{F}_{\Bk}(t) \left(-2 \pi \frac{k_m}{\lambda_m}\right) e^{-2\pi i k_j x^j/\lambda_j} \\
&= 2 \pi c \sum_{\Bk} \sum_m \frac{\sigma^m k_m}{\lambda_m} \hat{F}_{\Bk}(t) i e^{-2\pi i k_j x^j/\lambda_j} \\
\end{align*}

Now lets invent (perhaps abuse) some notation to tidy things up.  As a subscript on our Fourier coefficients we've used $\Bk$ as an index.  Let's also use it as a vector, and write

\begin{align*}
\Bk = 2 \pi \sum_m \frac{\sigma^m k_m}{\lambda_m}
\end{align*}

It was also previously implied that we had

\begin{align*}
\Bx = \sum_m \sigma_m x^m
\end{align*}

Also noting that $i$ commutes with $\Bk$ and since $F$ is also an STA bivector $i$ commutes with $F$.  Putting all this together we have

\begin{align*}
\sum_{\Bk} \left(\partial_t \hat{F}_{\Bk}(t) \right) e^{-i \Bk \cdot \Bx }
&= i c \sum_{\Bk} \Bk \hat{F}_{\Bk}(t) e^{- i \Bk \cdot \Bx } \\
\end{align*}

Term by term we now have a (big ass, triple infinite) set of very simple first order differential equations, one for each $\Bk$ triplet of indexes.  Specifically this is

\begin{align*}
\hat{F}_{\Bk}' &= i c \Bk \hat{F}_{\Bk}
\end{align*}

With solutions

\begin{align*}
\hat{F}_{0} &= C_{0} \\
\hat{F}_{\Bk} &= \exp\left(i c \Bk t \right) C_{\Bk} \\
\end{align*}

Here $C_{\Bk}$ is an undetermined STA bivector.  Note that we have to keep this undetermined coefficient on the right hand side of the exponential since we cannot assume it commutes with a factor of the form $\exp(i\Bk\phi)$.  Substitution back into our assumed solution sum we have a solution to Maxwell's equation, in terms of a set of as yet undetermined (bivector) coefficients

\begin{align}\label{eqn:undetermined}
F(\Bx,t) = C_0 + \sum_{\Bk \ne 0} \exp\left(i c \Bk t \right) C_{\Bk} \exp(-i \Bk \cdot \Bx )
\end{align}

Now, observe the form of this sum for $t=0$.  This is

\begin{align*}
F(\Bx,0) 
&= C_0 + \sum_{\Bk \ne 0} C_{\Bk} \exp(-i \Bk \cdot \Bx ) \\
&= \sum_{\Bk} C_{\Bk} \exp(-i \Bk \cdot \Bx ) \\
\end{align*}

So, the $C_k$ coefficients are precisely the Fourier coefficients of $F(\Bx,0)$.  This is to be expected having repeatedly seen similar results in the Fourier transform treatments of 
\cite{PJfourierMaxwellSecondOrder}, \cite{PJfirstOrderMaxwell}, and \cite{PJ4dFourier}.
If we write 
$
C_{\Bk}
=
{\left.\hat{F}_{\Bk}\right\vert}_{t=0}
$, we then have an equation for the complete time evolution of any spatially periodic electrodynamic field in terms of the field value at all points in the region at some initial time.  That is

\begin{align}
F(\Bx,t) &= \sum_{\Bk} \exp\left(i c \Bk t \right) {\left.\hat{F}_{\Bk}\right\vert}_{t=0} \exp(-i \Bk \cdot \Bx) \\
{\left.\hat{F}_{\Bk}\right\vert}_{t=0} &= \inv{V} \int F(\Bx', 0) \exp\left( i\Bk \cdot \Bx' \right) d^3 x'
\end{align}

Regrouping slightly, taking advantage that we can commute our complex exponential to the left (cannot do so for the $i\Bk$ exponential)
we can also write this as a convolution with a Fourier kernel (a Green's function).  That is

\begin{align}
F(\Bx,t) &= \inv{V} \int \sum_k e^{ - i (\Bk \cdot (\Bx' - \Bx) - \Bk c t) } F(\Bx', 0) d^3 x'
\end{align}

Or
\begin{align}\label{eqn:bivectorSolution}
F(\Bx,t) &= \int G(\Bx' - \Bx, t) F(\Bx', 0) d^3 x' \\
G(\Bx,t) &= \inv{V} \sum_k e^{ - i (\Bk \cdot \Bx - \Bk c t) }
\end{align}

Okay, that's cool.  We've now got the basic periodicity result directly from Maxwell's equation in one shot.  No need to drop down to
potentials, or even the separate electric or magnetic components of our field $F = \EE + i \HH$.

\subsection{ Electric and magnetic field components. }

Given $F$ we can compute the electric and magnetic field components using a spacetime observer split

\begin{align*}
\EE &= \inv{2}(F - \gamma_0 F \gamma_0 ) \\
\HH &= \inv{2i}(F + \gamma_0 F \gamma_0 ) \\
\end{align*}

An alternative is a split by components, which also implicitly utilizes
a specific observer time basis vector.  That would be
\begin{align*}
F = E^m \sigma_m + i H^m \sigma_m
\end{align*}

This provides the electric and magnetic field components:
\begin{align*}
E^m &= F \cdot \sigma_m \\
H^m &= (-i F) \cdot \sigma_m
\end{align*}

We are used to separate electric and magnetic fields, as measurable and experiencable quantities.  So reexpressing the previous results 
in terms of separate fields should take some of the abstraction out of the picture.  Additionally, in the Fourier components we expect, or at least ought to be able to show, a $\Bk$ dependence between $\EE$ and $\HH$.  Let's try this

FIXME:TODO...

\subsection{ Separate electric and magnetic fields with the boundary conditions unspecified. }

Fixing the boundary value in terms of the initial field at $t=0$ is not the only option.  We see similar things in classical mechanics in constant acceleration problems where one can use an initial position and velocity, or positions at two different times, and so forth.  Bohm leaves his equivalents to the integration constants $C_{\Bk}$ unspecified.  If we do so too we have equation \ref{eqn:undetermined}.  How does that look with separate fields?

FIXME:TODO:...  

\section{ Second order treatment with potentials. }

\subsection{ With the Lorentz gauge. }

Now, it appears that Bohm's use of potentials allows a nice comparison with the harmonic oscillator.  Let's also try a Fourier solution of the 
potential equations.  Again, use STA instead of the traditional vector equations, writing $A = (\phi + \Ba \gamma_0)$, and employing the Lorentz gauge
$\grad \cdot A = 0$ we have for $F = \grad \wedge A$ in csg units

\begin{align*}
\grad^2 A = 4 \pi J
\end{align*}

Again with a spacetime split of the gradient

\begin{align*}
\grad = \gamma^0(\partial_0 + \spacegrad) = (\partial_0 - \spacegrad) \gamma_0
\end{align*}

our four Laplacian can be written

\begin{align*}
(\partial_0 - \spacegrad) \gamma_0 \gamma^0(\partial_0 + \spacegrad) 
&= (\partial_0 - \spacegrad) (\partial_0 + \spacegrad) \\
&= \partial_{00} - \spacegrad^2
\end{align*}

Our vacuum field equation for the potential is thus
\begin{align}
\partial_{tt} A = c^2 \spacegrad^2 A
\end{align}

Now, as before assume a Fourier solution and see what follows.  That is

\begin{align}\label{eqn:assumedPotential}
A(\Bx, t) &= \sum_{\Bk} \hat{A}_{\Bk}(t) e^{ -i \Bk \cdot \Bx}
\end{align}

Applied to each component this gives us
\begin{align*}
\hat{A}_{\Bk}'' e^{ -i \Bk \cdot \Bx} 
&= c^2 \hat{A}_{\Bk}(t) \sum_m \PDsq{x^m}{} e^{ - 2 \pi i \sum_j k_j x^j /\lambda_j} \\
&= c^2 \hat{A}_{\Bk}(t) \sum_m (- 2 \pi i k_m/\lambda_m)^2 e^{ - i \Bk \cdot \Bx } \\
&= -c^2 \Bk^2 \hat{A}_{\Bk} e^{ - i \Bk \cdot \Bx }
\end{align*}

So we are left with another big ass set of simplest equations to solve

\begin{align*}
\hat{A}_{\Bk}'' &= -c^2 \Bk^2 \hat{A}_{\Bk}
\end{align*}

Note that again the origin point $\Bk = (0,0,0)$ is a special case.  Also of note this time is that $\hat{A}_{\Bk}$ has vector and trivector parts, unlike $\hat{F}_{\Bk}$ which being derived from dual and non-dual components of a bivector was still a bivector.

It appears that solutions can be found with either left or right handed
vector valued integration constants

\begin{align*}
\hat{A}_{\Bk}(t) &= \exp(\pm i c \Bk t) C_{\Bk} \\
                 &= D_{\Bk} \exp(\pm i c \Bk t)
\end{align*}

Since these are equal at $t=0$, it appears to imply that these commute with the
complex exponentials as was the case for the bivector field.

For the $\Bk = 0$ special case we have solutions
\begin{align*}
\hat{A}_{\Bk}(t) &= D_0 t + C_0
\end{align*}

It doesn't seem unreasonable to require $D_0 = 0$.  Otherwise this time dependent DC Fourier component will blow up at large and small values, while periodic
solutions are sought.

Putting things back together we have 

\begin{align}
A(\Bx, t) &= \sum_{\Bk} 
%\hat{A}_{\Bk}(t) &= 
\exp(\pm i c \Bk t) C_{\Bk} e^{ -i \Bk \cdot \Bx}
\end{align}

Here again for $t=0$, our integration constants are found to be determined completely by the initial conditions

\begin{align}
A(\Bx, 0) &= \sum_{\Bk} C_{\Bk} e^{ -i \Bk \cdot \Bx}
\end{align}

So we can write

\begin{align*}
C_{\Bk} = \inv{V} \int A(\Bx', 0) e^{ i \Bk \cdot \Bx'} d^3 x'
\end{align*}

In integral kernel form this is

%\sum_{\Bk} \inv{V} \int A(\Bx', 0) e^{ i \Bk \cdot (\Bx - \Bx') \mp i c \Bk t } d^3 x'
\begin{align}
A(\Bx, t) &= \int A(\Bx', 0) G_A(\Bx - \Bx', t) d^3 x' \\
G_A(\Bx, t) &= \inv{V} \sum_{\Bk} e^{ i (\Bk \cdot \Bx \mp c \Bk t) }
\end{align}

Rather suprisingly, this is almost exactly what we had for the bivector field in equation \ref{eqn:bivectorSolution}!  The only difference that the second order differential equation seems to contribute to the kernel is an allowable plus or minus variation in the $ct$ term.

\subsection{ Comparing the first and second order solutions }

Since we are working in the Lorentz gauge, we should have

\begin{align*}
F 
&= \grad \wedge A \\
&= \grad A \\
&= \int A(\Bx', 0) \left(\grad G_A(\Bx - \Bx', t) \right) d^3 x' \\
\end{align*}

Or with the opposite convolution
\begin{align*}
F &= \grad \int A(\Bx - \Bx', 0) G_A(\Bx', t) d^3 x' \\
\end{align*}

FIXME: expand these and see what falls out.  

\section{ Field Energy and momentum. }

\subsection{ Get the units right with these cgs equations. }

We'll want to calculate the equivalent of 

\begin{align*}
U = \frac{\epsilon_0}{2} (\BE^2 + c^2 \BB^2)
\end{align*}

but are faced with the alternate units of Bohm's text.  Let's repeat the
derivation of the electric field energy from \cite{PJelectricFieldEnergy}
in the cgs units directly from equation \ref{eqn:maxwell} to get it right.

To start with we our spacetime split of \ref{eqn:maxwell} is

\begin{align*}
( \partial_0 + \spacegrad ) (\EE + \HH) = 4 \pi (\rho - \Bj)
\end{align*}

The scalar part gives us Coulomb's law

\begin{align}
\spacegrad \cdot \EE = 4 \pi \rho 
\end{align}

Gauss's theorem applied to a spherical constant density charge distribution
gives us
\begin{align*}
\int \spacegrad \cdot \EE dV &= 4 \pi \int \rho dV \\
\implies \\
\int {\EE} \cdot \ncap dA &= 4 \pi Q \\
\implies \\
\Abs{\EE} 4 \pi r^2 &= 4 \pi Q \\
\end{align*}

so we have the expected ``unitless'' Coloumb law force equation

\begin{align*}
{\BF} = q\EE = \frac{q Q }{r^2} \rcap
\end{align*}

So far so good.  Next introduction of a potential.  For statics we don't care
about the four vectors and stick with the old fashion definition of the potential $\phi$ indirectly in terms of $\EE$.  That is

\begin{align*}
\EE = -\spacegrad \phi
\end{align*}

A line integral of this gives us $\phi$ in terms of $\EE$
\begin{align*}
-\int \EE \cdot \Br 
&= \int \spacegrad \phi \cdot d\Br \\
&= \phi - \phi_0 \\
\end{align*}

With $\phi_0 = 0$ this is

\begin{align*}
\phi 
&= -\int \EE \cdot d\Br  \\
&= -\int \frac{Q}{r^2} \rcap \cdot d\Br  \\
&= -\int \frac{Q}{r^2} dr  \\
&= \frac{Q}{r} \\
%&= -\int \frac{\rho dV}{r^2} dr 
\end{align*}

Okay.  Now onto the electrostatic energy.  The work done to move one charge from infinite to some separation $d$ of another like sign charge 
is

\begin{align*}
\int F \cdot d\Br 
&= \int_{r= \infty}^d \frac{q Q}{r^2} \rcap \cdot (-d\Br)  \\
&= -\int_{r= \infty}^d \frac{qQ}{r^2} dr  \\
&= \frac{qQ}{d} \\
&= q\phi \\
\end{align*}

For a distribution of discrete charges we have to sum over all pairs

\begin{align*}
W 
&= \sum_{i \ne j} \frac{q_i q_j}{d_{ij}} \\
&= \sum_{i,j} \inv{2} \frac{q_i q_j}{d_{ij}} \\
\end{align*}

In a similar fashion we can do a continuous variation, employing a double summation over all space

%\begin{align*}
%W &= \inv{2} \int \frac{\rho_1 \rho_2}{r_{12}} dV_1 dV_2 \\
%\end{align*}

\begin{align*}
W
&= \int \rho' dV' \phi \\
&= \inv{2} \int_{r_{12}= \infty}^d \frac{\int \rho(\Br) dV \int \rho(\Br') dV' }{(r_{12})^2} \rcap_{12} \cdot (-d\Br_{12})  \\
&= \inv{2} \int_{r_{12}= \infty}^d \frac{\int \rho(\Br) dV \int \rho(\Br') dV' }{(r_{12})^2} \rcap_{12} \cdot (-d\Br_{12})  \\
&= \inv{2} \int_{r_{12}= \infty}^d \frac{\int \rho(\Br) dV \int \rho(\Br') dV' }{(r_{12})^2} -dr_{12}  \\
%&= \inv{2} \int \rho(\Br) dV \rho(\Br') dV' \inv{(r_{12})^2} \rcap_{12} \cdot (-d\Br_{12})  \\
%&= \inv{2} \int \rho(\Br) dV \rho(\Br') dV' \inv{r_{12}} 
\end{align*}

\subsection{ }

Given that we have the same structure for our four vector potential solutions as the complete bivector field, it doesn't appear that there is much
reason to work in the second order quantities.  For the energy momentum analysis, let's go back to the original bivector field solutions.

% FIXME:TODO:
%Next in the sequence of understanding
%Bohm's Rayleigh-Jeans result will be to consider the energy and momentum density of the field, but that's a job for a different day.

\bibliographystyle{plainnat}
\bibliography{myrefs}

\end{document}
