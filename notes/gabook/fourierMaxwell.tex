\documentclass{article}

\input{../peeters_macros.tex}
\input{../peeters_macros2.tex}
\newcommand{\PDSq}[2]{\frac{\partial^2 {#2}}{\partial {#1}^2}}
\DeclareMathOperator{\sinc}{sinc}
\DeclareMathOperator{\PV}{PV}
\newcommand{\FF}[0]{\mathcal{F}}
\newcommand{\IIinf}[0]{ \int_{-\infty}^\infty }

\usepackage[bookmarks=true]{hyperref}

\usepackage{color,cite,graphicx}
   % use colour in the document, put your citations as [1-4]
   % rather than [1,2,3,4] (it looks nicer, and the extended LaTeX2e
   % graphics package.
\usepackage{latexsym,amssymb,epsf} % don't remember if these are
   % needed, but their inclusion can't do any damage


\title{ Fourier transform solutions to Maxwell's equation. }
\author{Peeter Joot}
\date{ Jan 29, 2009.  Last Revision: $Date: 2009/01/30 05:34:38 $ }

\begin{document}

\maketitle{}

\tableofcontents
\section{ Motivation. }

In \cite{PJwaveFourier} a Green's function solution to the homogeneous
wave equation

\begin{align}\label{eqn:wave}
\left(\inv{v^2} \partial_{tt} -\partial_{xx} -\partial_{yy} -\partial_{zz} \right)\psi = 0
\end{align}

was found to be

\begin{align}\label{eqn:greensSolution3d}
{\psi}(x,y,z,t) &= \IIinf \phi(u,w,r) G( x-u, y-w, z-r, t) du dw dr \\
G(x,y,z,t) &= \inv{({2\pi})^3} \IIinf \exp\left( i k x + i m y + i n z \pm i \sqrt{k^2 + m^2 + n^2} v t \right) dk dm dn
\end{align}

The aim of this set of notes is to explore the same ideas to the forced wave
equations for the four vector potentials of the Lorentz gauge Maxwell equation.

Such solutions can be used to find the Faraday bivector or its associated
tensor components.

Additionally, we can likely apply the same ideas to solve for the Faraday
bivector directly from Maxwell's equation without having to solve the
associated second order equations.

Note that the specific form of the Fourier transform used in these notes continues to be

\begin{align}
%\hat{f}(\Bk) &= \inv{(\sqrt{2\pi})^n} \IIinf f(\Bx) \exp\left( -i k_j x^j \right) d^n x \\
%{f}(\Bx) &= \inv{(\sqrt{2\pi})^n} \IIinf \hat{f}(\Bk) \exp\left( i k_j x^j \right) d^n k
\hat{f}(\Bk) &= \inv{(\sqrt{2\pi})^n} \IIinf f(\Bx) \exp\left( -i \Bk \cdot \Bx \right) d^n x \\
{f}(\Bx) &= \inv{(\sqrt{2\pi})^n} \IIinf \hat{f}(\Bk) \exp\left( i \Bk \cdot \Bx \right) d^n k
\end{align}

\section{ Forced wave equation. }

\subsection{ One dimensional case. }

A good starting point is the reduced complexity one dimensional forced
wave equation

\begin{align}
\left( \inv{v^2} \partial_{tt} -\partial_{xx} \right)\psi = \rho
\end{align}

Fourier transforming to to the wave number domain, with application of integration by parts twice (each toggling the sign of the spatial
derivative term) we have

\begin{align}
\inv{v^2}\hat{\psi}_{tt} - (-i k)^2 \hat{\psi} = \hat{\rho}
\end{align}

This leaves us with a linear differential equation of the following form to solve

\begin{align}\label{eqn:waveNumEquationToSolve}
f'' + \alpha^2 f = g
\end{align}

Out of line solution of this can be found below in equation \ref{eqn:solutionToWaveNumberDomainEquation}, where we have
$f = \hat{\psi}$, $\alpha = k v$, and $g = \hat{\rho} v^2$.  Our solution for the wave function in the wave number domain is now completely
specified

\begin{align*}
\hat{\psi}(k, t) = \frac{v}{k} \int_{u=t_0(k)}^t \hat{\rho}(u) \sin( k v (t-u) ) du
\end{align*}

Here because of the partial differentiation we have the flexibility to make the initial time a function of the wave number $k$, but it is probably
more natural to just set $t_0 = -\infty$

\begin{align*}
\hat{\psi}(k, t) = \frac{v}{k} \int_{u = -\infty}^t \hat{\rho}(k, u) \sin( k v (t-u) ) du
\end{align*}

But seeing the integral in this form suggests a change of variables $w = t-u$, which gives us our final wave function in the wave number domain with all the time
dependency removed from the integration limits

\begin{align*}
\hat{\psi}(k, t) = \frac{v}{k} \int_{w = 0}^\infty \hat{\rho}(k, t-w) \sin( k v w ) dw
\end{align*}

With this our wave function is

\begin{align*}
{\psi}(x, t)
&=
\inv{\sqrt{2\pi}} \IIinf
\left(
\frac{v}{k} \int_{w = 0}^\infty \hat{\rho}(k, t-w) \sin( k v w ) dw
%\frac{v}{k} \int_{u = -\infty}^t \hat{\rho}(u) \sin( k v (t-u) ) du
\right) \exp( i k x ) dk \\
\end{align*}


But we also have

\begin{align*}
\hat{\rho}(k,t) &= \inv{\sqrt{2\pi}} \int_{-\infty}^\infty {\rho}(x, t) \exp( -i k x ) dx
\end{align*}

Reassembling we have

%\begin{align*}
%{\psi}(x, t)
%&=
%\inv{\sqrt{2\pi}} \IIinf
%\left( \frac{v}{k} \int_{u = -\infty}^t
%\left(
%\inv{\sqrt{2\pi}} \int_{-\infty}^\infty {\rho}(x) \exp( -i u x ) dx
%\right)
%\sin( k v (t-u) ) du \right) \exp( i k x ) dk \\
%\end{align*}

\begin{align*}
{\psi}(x, t)
&=
\inv{\sqrt{2\pi}}
\int_{k = -\infty}^\infty
\left(
\frac{v}{k}
\int_{w = 0}^\infty
\left(
\inv{\sqrt{2\pi}} \int_{y=-\infty}^\infty {\rho}(y, t-w) \exp( -i k y ) dy
\right)
\sin( k v w ) dw
\right) \exp( i k x ) dk
\end{align*}

Rearranging a bit we have

\begin{align}
{\psi}(x, t)
&=
%\int_{y=-\infty}^\infty
%\int_{w = 0}^\infty
%{\rho}(y, t-w) G(x -y, t) dy dw \\
%
% x-y=z
% y=x-z
% dy = -dz
% \int_y -> -\int_z
%
\int_{z=-\infty}^\infty
\int_{w = 0}^\infty
{\rho}(x-z, t-w) G(z, t) dz dw \\
G(x, w) &=
\int_{k = -\infty}^\infty
\frac{v}{2\pi k}
\sin( k v w )
\exp( i k x )
dk
%\\
\end{align}

We see that our charge density summed over all space contributes to the wave function, but it is the charge density at that spatial location as it existed at a specific previous time.
Exactly what that previous time is is a rather complex looking function of our integral kernel.

%This is
%\begin{align*}
%{\psi}(x, t)
%&=
%\IIinf {\rho}(x) G( x, t ) dx \\
%G(x, t) &=
%\int_{k=-\infty}^\infty
%\int_{u = -\infty}^t
%\frac{v}{2 k \pi}
%\sin( k v (t-u) )
%\exp( i (k-u) x )
%dk
%du
%\\
%\end{align*}

%or
%\begin{align*}
%% t-u = w
%% u = t-w
%% w(u=t) = 0
%% w(u=-\infty) = \infty
%G(x, t) &=
%\int_{k=-\infty}^\infty
%\int_{w = 0}^{\infty}
%\frac{v}{2 k \pi}
%\sin( k v w )
%\exp( i (k+w-t) x )
%dk
%dw
%\\
%\end{align*}

\subsection{ Three dimensional case. }

Now, lets move on to the 3D case that's of particular interest for electrodynamics.  Our wave equation is now of the form

\begin{align}
\left( \inv{v^2} \PDSq{t}{} -\sum_j \PDSq{x^j}{} \right)\psi = \rho
\end{align}

and our Fourier transformation produces almost the same result, but we have a wave number contribution from each of the three dimensions

\begin{align}
\inv{v^2}\hat{\psi}_{tt} + \Bk^2 \hat{\psi} = \hat{\rho}
\end{align}

Our wave number domain solution is therefore
\begin{align*}
\hat{\psi}(\Bk, t) = \frac{v}{\Abs{\Bk}} \int_{w = 0}^\infty \hat{\rho}(\Bk, t-w) \sin( \Abs{\Bk} v w ) dw
\end{align*}

But our wave number domain charge density is

\begin{align*}
\hat{\rho}(\Bk, t) &= \inv{(\sqrt{2\pi})^3} \IIinf \rho(\Bx, t) \exp\left( -i \Bk \cdot \Bx \right) d^3 x \\
\end{align*}

Our wave number domain result in terms of the charge density is therefore

%\hat{\rho}(\Bk, t-w) &= \inv{(\sqrt{2\pi})^3} \IIinf \rho(\Br, t-w) \exp\left( -i \Bk \cdot \Br \right) d^3 r \\
\begin{align*}
\hat{\psi}(\Bk, t) = 
\frac{v}{\Abs{\Bk}} \int_{w = 0}^\infty 
%\hat{\rho}(\Bk, t-w) &= 
\left(
\inv{(\sqrt{2\pi})^3} \IIinf \rho(\Br, t-w) \exp\left( -i \Bk \cdot \Br \right) d^3 r 
\right)
\sin( \Abs{\Bk} v w ) dw
\end{align*}

And finally inverse transforming back to the spatial domain we have a complete solution for the inhomogeneous wave equation in terms of the spatial and temporal charge density distribution

\begin{align}
{\psi}(\Bx, t) 
%&= \IIinf \int_{w = 0}^\infty \rho(\Br, t-w) G(\Bx -\Br) d^3 r dw \\
% y_j = x_j - r_j
% r_j = x_j - y_j
% dr_j = -dy_j
% III dr_1 dr_2 dr_3 = (-1)^3 III d^3 y
&= \IIinf \int_{w = 0}^\infty \rho(\Bx -\By, t-w) G(\By, w) d^3 y dw \\
G(\By, w) 
&= \IIinf
\frac{v}{(2\pi)^3 \Abs{\Bk}} 
\sin( \Abs{\Bk} v w ) 
\exp\left( i \Bk \cdot \By \right) 
d^3 k
\end{align}

Very cool to see a closed form expression for this.
One can also see the elements of the traditional retarded time expressions for the potential hiding in there, but making that final next step to show this is actually
the case looks like it is
still a job for a different day.

\section{ Appendix.  Mechanical details. }

\subsection{ Solving the wave number domain differential equation. }

We wish to solve equation the inhomogeneous equation \ref{eqn:waveNumEquationToSolve}.  Writing this in terms of a linear operator equation this is

\begin{align*}
L(y) &= y'' + \alpha^2 y \\
L(y) &= g
\end{align*}

The solutions of this equation will be formed from linear combinations of the homogeneous problem plus a specific solution of the inhomogeneous problem

By inspection the homogeneous problem has solutions in $\Span \{ e^{ i \alpha x }, e^{ -i \alpha x }\}$.
We can find a solution to the inhomogeneous problem using the variation of parameters method, assuming a solution of the form

\begin{align*}
y  = u e^{ i \alpha x } + v e^{ -i \alpha x }
\end{align*}

Taking derivatives we have
\begin{align*}
y' = u' e^{ i \alpha x } + v' e^{ -i \alpha x } + i \alpha (u e^{ i \alpha x } - v e^{ -i \alpha x })
\end{align*}

The trick to solving this is to employ the freedom to set the $u'$, and $v'$ terms above to zero

\begin{align}\label{eqn:firstConstraint}
u' e^{ i \alpha x } + v' e^{ -i \alpha x } = 0
\end{align}

Given this choice we then have
\begin{align*}
y' &= i \alpha (u e^{ i \alpha x } - v e^{ -i \alpha x }) \\
y'' &=
(i \alpha)^2 (u e^{ i \alpha x } + v e^{ -i \alpha x })
i \alpha (u' e^{ i \alpha x } - v' e^{ -i \alpha x })
\end{align*}

So we have
\begin{align*}
L(y)
&=
(i \alpha)^2 (u e^{ i \alpha x } + v e^{ -i \alpha x })  \\
&+i \alpha (u' e^{ i \alpha x } - v' e^{ -i \alpha x })
+ (\alpha)^2 (u e^{ i \alpha x } + v e^{ -i \alpha x })  \\
&=
i \alpha (u' e^{ i \alpha x } - v' e^{ -i \alpha x })
\end{align*}

With this and \ref{eqn:firstConstraint} we have a set of simultaneous first order linear differential equations to solve

\begin{align*}
\begin{bmatrix}
u' \\
v' \\
\end{bmatrix}
&=
{\begin{bmatrix}
 e^{ i \alpha x } &- e^{ -i \alpha x } \\
 e^{ i \alpha x } &  e^{ -i \alpha x } \\
\end{bmatrix}}^{-1}
\begin{bmatrix}
{g}/{i \alpha} \\
0 \\
\end{bmatrix} \\
&=
\inv{2}
{\begin{bmatrix}
 e^{ -i \alpha x } & e^{ -i \alpha x } \\
 -e^{ i \alpha x } &  e^{ i \alpha x } \\
\end{bmatrix}}
\begin{bmatrix}
{g}/{i \alpha} \\
0 \\
\end{bmatrix} \\
&=
\frac{g}{2 i \alpha}
{\begin{bmatrix}
 e^{ -i \alpha x } \\
 -e^{ i \alpha x } \\
\end{bmatrix}}
\end{align*}

Substituting back into the assumed solution we have
\begin{align*}
y
&= \frac{1}{2 i \alpha} \left(
  e^{ i \alpha x } \int g e^{ -i \alpha x }
- e^{ -i \alpha x } \int g e^{ i \alpha x }
\right) \\
&= \frac{1}{2 i \alpha} \int_{u=x_0}^x g(u) \left( e^{ -i \alpha (u-x) } -e^{ i \alpha (u-x) } \right) du \\
\end{align*}

So our solution appears to be

\begin{align}\label{eqn:solutionToWaveNumberDomainEquation}
y &= \frac{1}{\alpha} \int_{u=x_0}^x g(u) \sin( \alpha(x-u) ) du
\end{align}

A check to see if this is correct is in order to verify this.  Differentiating using \ref{eqn:diffInt} we have

\begin{align*}
y'
&=
{\left.
\frac{1}{\alpha}
g(u) \sin( \alpha(x-u) ) \right\vert}_{u=x}
+\frac{1}{\alpha} \int_{u=x_0}^x \PD{x}{} g(u) \sin( \alpha(x-u) ) du \\
&= \int_{u=x_0}^x g(u) \cos( \alpha(x-u) ) du \\
\end{align*}

and for the second derivative we have

\begin{align*}
y''
&=
{\left. g(u) \cos( \alpha(x-u) ) \right\vert}_{u=x}
- \alpha \int_{u=x_0}^x g(u) \sin( \alpha(x-u) ) du \\
&= g(x) - \alpha^2 y(x)
\end{align*}

Excellent, we have $y'' + \alpha^2 y = g$ as desired.

\subsection{ Differentiation under the integral sign. }

Given an function that is both a function of the integral limits and the integrals kernel

\begin{align*}
f(x) = \int_{u = a(x)}^{b(x)} G(x,u) du,
\end{align*}

lets recall how to differentiate the beastie.  First let $G(x,u) = \PDi{u}{F(x,u)}$ so we have

\begin{align*}
f(x) = F(x,b(x)) - F(x,a(x))
\end{align*}

and our derivative is
\begin{align*}
f'(x)
&=
\PD{x}{F}(x,b(x))
\PD{u}{F}(x,b(x)) b'
-\PD{x}{F}(x,a(x))
-\PD{u}{F}(x,a(x)) a' \\
&=
G(x,b(x)) b'
-G(x,a(x)) a'
+\PD{x}{F}(x,b(x))
-\PD{x}{F}(x,a(x))
\\
\end{align*}

Intuition (or recollection?) says that these last two terms are

\begin{align*}
\PD{x}{F}(x,b(x))
-\PD{x}{F}(x,a(x))
&=
\int_{a}^b \PD{x}{G}(x,u) du
\end{align*}

FIXME: Does this make sense?   Justify this... feels handwavyish.

Assuming that is right we then have
\begin{align}\label{eqn:diffInt}
\frac{d}{dx} \int_{u = a(x)}^{b(x)} G(x,u) du
&=
G(x,b(x)) b'
-G(x,a(x)) a'
+ \int_{a(x)}^{b(x)} \PD{x}{G}(x,u) du
\end{align}

\bibliographystyle{plainnat}
\bibliography{myrefs}

\end{document}
