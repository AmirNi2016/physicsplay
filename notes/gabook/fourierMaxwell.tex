\documentclass{article}

\input{../peeters_macros.tex}
\input{../peeters_macros2.tex}
\newcommand{\PDSq}[2]{\frac{\partial^2 {#2}}{\partial {#1}^2}}
\DeclareMathOperator{\sinc}{sinc}
\DeclareMathOperator{\PV}{PV}
\newcommand{\FF}[0]{\mathcal{F}}
\newcommand{\IIinf}[0]{ \int_{-\infty}^\infty }

\usepackage[bookmarks=true]{hyperref}

\usepackage{color,cite,graphicx}
   % use colour in the document, put your citations as [1-4]
   % rather than [1,2,3,4] (it looks nicer, and the extended LaTeX2e
   % graphics package. 
\usepackage{latexsym,amssymb,epsf} % don't remember if these are
   % needed, but their inclusion can't do any damage


\title{ Fourier transform solutions to Maxwell's equation. }
\author{Peeter Joot}
\date{ Jan 29, 2009.  Last Revision: $Date: 2009/01/30 04:17:19 $ }

\begin{document}

\maketitle{}

\tableofcontents
\section{ Motivation. }

In \cite{PJwaveFourier} a Green's function solution to the homogeneous 
wave equation

\begin{align}\label{eqn:wave}
\left(\inv{v^2} \partial_{tt} -\partial_{xx} -\partial_{yy} -\partial_{zz} \right)\psi = 0 
\end{align}

was found to be

\begin{align}\label{eqn:greensSolution3d}
{\psi}(x,y,z,t) &= \IIinf \phi(u,w,r) G( x-u, y-w, z-r, t) du dw dr \\
G(x,y,z,t) &= \inv{({2\pi})^3} \IIinf \exp\left( i k x + i m y + i n z \pm i \sqrt{k^2 + m^2 + n^2} v t \right) dk dm dn
\end{align}

The aim of this set of notes is to explore the same ideas to the forced wave
equations for the four vector potentials of the Lorentz gauge Maxwell equation.

Such solutions can be used to find the Faraday bivector or its associated
tensor components.

Additionally, we can likely apply the same ideas to solve for the Faraday
bivector directly from Maxwell's equation without having to solve the 
associated second order equations.

Note that the specific form of the Fourier transform used in these notes continues to be

\begin{align}
\hat{f}(\Bk) &= \inv{(\sqrt{2\pi})^n} \IIinf f(\Bx) \exp\left( -i k_j x^j \right) d^n x \\
{f}(\Bx) &= \inv{(\sqrt{2\pi})^n} \IIinf \hat{f}(\Bk) \exp\left( i k_j x^j \right) d^n k
\end{align}

\section{ One dimensional forced wave equation. }

A good starting point is the reduced complexity one dimensional forced
wave equation

\begin{align}
\left( \inv{v^2} \partial_{tt} -\partial_{xx} \right)\psi = \rho
\end{align}

Fourier transforming to to the wave number domain, with application of integration by parts twice (each toggling the sign of the spatial 
derivative term) we have

\begin{align*}
\inv{v^2}\hat{\psi}_{tt} - (-i k)^2 \hat{\psi} = \hat{\rho}
\end{align*}

This leaves us with a linear differential equation of the following form to solve

\begin{align}\label{eqn:waveNumEquationToSolve}
f'' + \alpha^2 f = g
\end{align}

Out of line solution of this can be found below in equation \ref{eqn:solutionToWaveNumberDomainEquation}, where we have
$f = \hat{\psi}$, $\alpha = k v$, and $g = \hat{\rho} v^2$.  Our solution for the wave function in the wave number domain is now completely
specified

\begin{align*}
\hat{\psi}(k, t) = \frac{v}{k} \int_{u=t_0(k)}^t \hat{\rho}(u) \sin( k v (t-u) ) du
\end{align*}

Here because of the partial differentiation we have the flexibility to make the initial time a function of the wave number $k$, but it is probably
more natural to just set $t_0 = -\infty$.  Doing so, our wave function is

\begin{align*}
{\psi}(x, t) 
&= 
\inv{\sqrt{2\pi}} \IIinf
\left( \frac{v}{k} \int_{u = -\infty}^t \hat{\rho}(u) \sin( k v (t-u) ) du \right) \exp( i k x ) dk \\
\end{align*}

But we also have

\begin{align*}
\hat{\rho}(k) &= \inv{\sqrt{2\pi}} \int_{-\infty}^\infty {\rho}(x) \exp( -i k x ) dx
\end{align*}

Reassembling we have

\begin{align*}
{\psi}(x, t) 
&= 
\inv{\sqrt{2\pi}} \IIinf
\left( \frac{v}{k} \int_{u = -\infty}^t 
\left(
\inv{\sqrt{2\pi}} \int_{-\infty}^\infty {\rho}(x) \exp( -i u x ) dx
\right)
\sin( k v (t-u) ) du \right) \exp( i k x ) dk \\
\end{align*}

This is
\begin{align*}
{\psi}(x, t) 
&= 
\IIinf {\rho}(x) G( x, t ) dx \\
G(x, t) &=
\int_{k=-\infty}^\infty
\int_{u = -\infty}^t 
\frac{v}{2 k \pi}
\sin( k v (t-u) ) 
\exp( i (k-u) x ) 
dk 
du 
\\
\end{align*}

or
\begin{align*}
% t-u = w
% u = t-w
% w(u=t) = 0
% w(u=-\infty) = \infty
G(x, t) &=
\int_{k=-\infty}^\infty
\int_{w = 0}^{\infty}
\frac{v}{2 k \pi}
\sin( k v w ) 
\exp( i (k+w-t) x ) 
dk 
dw 
\\
\end{align*}

\section{ Tedious details. }

\subsection{ Solving the wave number domain differential equation. }

We wish to solve equation the inhomogeneous equation \ref{eqn:waveNumEquationToSolve}.  Writing this in terms of a linear operator equation this is

\begin{align*}
L(y) &= y'' + \alpha^2 y \\
L(y) &= g
\end{align*}

The solutions of this equation will be formed from linear combinations of the homogeneous problem plus a specific solution of the inhomogeneous problem

By inspection the homogeneous problem has solutions in $\Span \{ e^{ i \alpha x }, e^{ -i \alpha x }\}$.
We can find a solution to the inhomogeneous problem using the variation of parameters method, assuming a solution of the form

\begin{align*}
y  = u e^{ i \alpha x } + v e^{ -i \alpha x } 
\end{align*}

Taking derivatives we have
\begin{align*}
y' = u' e^{ i \alpha x } + v' e^{ -i \alpha x } + i \alpha (u e^{ i \alpha x } - v e^{ -i \alpha x })
\end{align*}

The trick to solving this is to employ the freedom to set the $u'$, and $v'$ terms above to zero

\begin{align}\label{eqn:firstConstraint}
u' e^{ i \alpha x } + v' e^{ -i \alpha x } = 0 
\end{align}

Given this choice we then have
\begin{align*}
y' &= i \alpha (u e^{ i \alpha x } - v e^{ -i \alpha x }) \\
y'' &= 
(i \alpha)^2 (u e^{ i \alpha x } + v e^{ -i \alpha x }) 
i \alpha (u' e^{ i \alpha x } - v' e^{ -i \alpha x }) 
\end{align*}

So we have
\begin{align*}
L(y) 
&=
(i \alpha)^2 (u e^{ i \alpha x } + v e^{ -i \alpha x })  \\
&+i \alpha (u' e^{ i \alpha x } - v' e^{ -i \alpha x }) 
+ (\alpha)^2 (u e^{ i \alpha x } + v e^{ -i \alpha x })  \\
&=
i \alpha (u' e^{ i \alpha x } - v' e^{ -i \alpha x }) 
\end{align*}

With this and \ref{eqn:firstConstraint} we have a set of simultaneous first order linear differential equations to solve

\begin{align*}
\begin{bmatrix}
u' \\
v' \\
\end{bmatrix}
&=
{\begin{bmatrix}
 e^{ i \alpha x } &- e^{ -i \alpha x } \\
 e^{ i \alpha x } &  e^{ -i \alpha x } \\
\end{bmatrix}}^{-1}
\begin{bmatrix}
{g}/{i \alpha} \\
0 \\
\end{bmatrix} \\
&=
\inv{2}
{\begin{bmatrix}
 e^{ -i \alpha x } & e^{ -i \alpha x } \\
 -e^{ i \alpha x } &  e^{ i \alpha x } \\
\end{bmatrix}}
\begin{bmatrix}
{g}/{i \alpha} \\
0 \\
\end{bmatrix} \\
&=
\frac{g}{2 i \alpha} 
{\begin{bmatrix}
 e^{ -i \alpha x } \\
 -e^{ i \alpha x } \\
\end{bmatrix}}
\end{align*}

Substituting back into the assumed solution we have
\begin{align*}
y 
&= \frac{1}{2 i \alpha} \left(
  e^{ i \alpha x } \int g e^{ -i \alpha x } 
- e^{ -i \alpha x } \int g e^{ i \alpha x } 
\right) \\
&= \frac{1}{2 i \alpha} \int_{u=x_0}^x g(u) \left( e^{ -i \alpha (u-x) } -e^{ i \alpha (u-x) } \right) du \\
\end{align*}

So our solution appears to be

\begin{align}\label{eqn:solutionToWaveNumberDomainEquation}
y &= \frac{1}{\alpha} \int_{u=x_0}^x g(u) \sin( \alpha(x-u) ) du
\end{align}

A check to see if this is correct is in order to verify this.  Differentiating using \ref{eqn:diffInt} we have

\begin{align*}
y' 
&= 
{\left. 
\frac{1}{\alpha} 
g(u) \sin( \alpha(x-u) ) \right\vert}_{u=x}
+\frac{1}{\alpha} \int_{u=x_0}^x \PD{x}{} g(u) \sin( \alpha(x-u) ) du \\
&= \int_{u=x_0}^x g(u) \cos( \alpha(x-u) ) du \\
\end{align*}

and for the second derivative we have

\begin{align*}
y''
&= 
{\left. g(u) \cos( \alpha(x-u) ) \right\vert}_{u=x}
- \alpha \int_{u=x_0}^x g(u) \sin( \alpha(x-u) ) du \\
&= g(x) - \alpha^2 y(x)
\end{align*}

Excellent, we have $y'' + \alpha^2 y = g$ as desired.

\subsection{ Differentiation under the integral sign. }

Given an function that is both a function of the integral limits and the integrals kernel

\begin{align*}
f(x) = \int_{u = a(x)}^{b(x)} G(x,u) du,
\end{align*}

lets recall how to differentiate the beastie.  First let $G(x,u) = \PDi{u}{F(x,u)}$ so we have

\begin{align*}
f(x) = F(x,b(x)) - F(x,a(x))
\end{align*}

and our derivative is
\begin{align*}
f'(x) 
&= 
\PD{x}{F}(x,b(x)) 
\PD{u}{F}(x,b(x)) b'
-\PD{x}{F}(x,a(x)) 
-\PD{u}{F}(x,a(x)) a' \\
&= 
G(x,b(x)) b'
-G(x,a(x)) a'
+\PD{x}{F}(x,b(x)) 
-\PD{x}{F}(x,a(x))  
\\
\end{align*}

Intuition (or recollection?) says that these last two terms are

\begin{align*}
\PD{x}{F}(x,b(x)) 
-\PD{x}{F}(x,a(x))  
&=
\int_{a}^b \PD{x}{G}(x,u) du
\end{align*}

FIXME: Does this make sense?   Justify this... feels handwavyish.

Assuming that is right we then have
\begin{align}\label{eqn:diffInt}
\frac{d}{dx} \int_{u = a(x)}^{b(x)} G(x,u) du  
&= 
G(x,b(x)) b'
-G(x,a(x)) a'
+ \int_{a(x)}^{b(x)} \PD{x}{G}(x,u) du
\end{align}

\bibliographystyle{plainnat}
\bibliography{myrefs}

\end{document}
