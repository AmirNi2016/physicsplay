\documentclass{article}

\input{../peeters_macros.tex}
\newcommand{\gpgrade}[2] {{\left\langle{{#1}}\right\rangle}_{#2}}
\newcommand{\gpgradezero}[1] {\gpgrade{#1}{0}}
\newcommand{\gpgradetwo}[1] {\gpgrade{#1}{2}}
\newcommand{\gpgradefour}[1] {\gpgrade{#1}{4}}
\newcommand{\grad}[0]{\nabla}
\newcommand{\spacegrad}[0]{\boldsymbol{\nabla}}
% == \partial_{#1} {#2}
\newcommand{\PD}[2]{\frac{\partial {#2}}{\partial {#1}}}
\newcommand{\PDD}[3]{\frac{\partial^2 {#3}}{\partial {#1}\partial {#2}}}
\newcommand{\PDsq}[2]{\frac{\partial^2 {#2}}{\partial^2 {#1}}}

\title{ Metric signature dependencies for electromagnetic equations. }
\author{Peeter Joot}
\date{ Sept 5, 2008.  Last Revision: $Date: 2008/09/07 04:55:12 $ }

\begin{document}

\maketitle{}

\section{ Motivation. }

Doran/Lasenby use a $+,-,-,-$ signature, and I had gotten used to that.  On first seeing the alternate signature used by John Denker's excellent
explainatory paper:

http://www.av8n.com/physics/maxwell-ga.pdf

I found myself disoriented.  How many of the identities that I was used to were metric dependent?   Here are some notes that explore some of the
metric dependencies of STA, in particular observing which identities are metric dependent and which aren't.

\section{}

\subsection{ Spatial basis. }

Our spatial (bivector) basis:

\begin{equation*}
\sigma_i = \gamma_i \wedge \gamma_0 = \gamma_{i0},
\end{equation*}

that behaves like Euclidean vectors (positive square) still behave as desired, regardless of the signature:

\begin{align*}
\sigma_i \cdot \sigma_j
&= \gpgradezero{\gamma_{i0j0}}  \\
&= - \gpgradezero{\gamma_{ij}} (\gamma_{0})^2  \\
&= -\delta_{ij} (\gamma_i)^2 (\gamma_{0})^2
\end{align*}

Regardless of the signature the pair of products $(\gamma_i)^2 (\gamma_{0})^2 = -1$, so our spatial bivectors are metric invariant.

\subsection{ How about commutation? }

Commutation with
\begin{equation*}
i \gamma_{\mu} = \gamma_{0123\mu} = \gamma_{\mu0123}
\end{equation*}

$\mu$ has to "pass" three indexes regardless of metric, so anticommutes for any $\mu$.

\begin{equation*}
\sigma_k \gamma_{\mu} = \gamma_{k0\mu}
\end{equation*}

If $k = \mu$, or $0 = \mu$, then we get a sign inversion, and otherwise commute (pass two indexes).  This is also metric invariant.

\subsection{ Spatial and time component selection. }

With a postive time metric (Doran/Lasenby) selection of the $x^0$ component of a vector $x$ requires a dot product:

\begin{equation*}
x = x^0 \gamma_0 + x^i \gamma_i
\end{equation*}

\begin{equation*}
x \cdot \gamma_0 = x^0 (\gamma_0)^2
\end{equation*}

Obviously this is a metric dependent operation.  To generalize it appropriately, we need to dot with $\gamma^0$ instead:

\begin{equation*}
x \cdot \gamma^0 = x^0
\end{equation*}

Now, what do we get when wedging with this upper index quantity instead.

\begin{align*}
x \wedge \gamma^0 
&= \left(x^0 \gamma_0 + x^i \gamma_i\right) \wedge \gamma^0 \\
&= x^i \gamma_i \wedge \gamma^0 \\
&= x^i \gamma_{i0} (\gamma^0)^2 \\
&= x^i \sigma_i (\gamma^0)^2 \\
&= \Bx \left(\gamma^0\right)^2
\end{align*}

Not quite the usual expression we are used to, but it still behaves as a euclidan vector (positive square), regardless of the metric:

\begin{equation*}
(x \wedge \gamma^0)^2 = \left(\pm \Bx\right)^2 = \Bx^2
\end{equation*}

This suggests that we should define our spatial projection vector as $x \wedge \gamma^0$ instead of $x \wedge \gamma_0$ as done in 
Doran/Lasenby (where a positive time metric is used).

\subsubsection{ Velocity. }

Variation of a event path with some parameter we have:

\begin{align*}
\frac{ d x }{ d \lambda } 
&= \frac{ d x^{\mu} }{ d \lambda } \gamma_{\mu} = c \frac{dt}{d\lambda} \gamma_0 + \frac{d x^i }{d\lambda} \gamma_i \\
&= \frac{d t}{d \lambda} \left( c \gamma_0 + \frac{d x^i }{dt} \gamma_i \right)
\end{align*}

The square of this is:
%becomes metric dependent:
\begin{align*}
\inv{c^2} \left(\frac{ d x }{ d \lambda } \right)^2
&= \left(\frac{dt }{d\lambda}\right)^2 (\gamma_0)^2 \left( 1 + \inv{c^2}\left(\frac{d x^i }{dt}\right)^2 (\gamma_i)^2 (\gamma_0)^2 \right) \\
&= \left(\frac{d t}{d \lambda}\right)^2 (\gamma_0)^2 \left( 1 - (\Bv/c)^2 \right) \\
\frac{ (\gamma_0)^2 }{c^2} \left(\frac{ d x }{ d \lambda } \right)^2 &= \left(\frac{d t}{d \lambda}\right)^2 \left( 1 - (\Bv/c)^2 \right) \\
\end{align*}

We define the proper time $\tau$ as that particular parameterization $c \tau = \lambda$ such that the LHS equals 1.  This is implicitly defined
via the integral

\begin{equation*}
\tau = \int \sqrt{ 1 - (\Bv/c)^2 } dt = \int \sqrt{ 1 - \left(\inv{c} \frac{dx^i }{d \alpha} \right)^2 } d\alpha
\end{equation*}

Regardless of this parameterization $\alpha = \alpha(t)$, this velocity scaled 4D arc length is the same.  This is a bit of a digression from the
ideas of metric dependence investigation.  There is however a metric dependence in the first steps arriving at this result.

with proper velocity defined in terms of proper time $v = dx/d\tau$, we also have:

\begin{equation}\label{eqn:gamma}
\gamma = \frac{dt}{d\tau} = \inv{ \sqrt{ 1 - (\Bv/c)^2 } }
\end{equation}
\begin{equation}
v = \gamma \left(c \gamma_0 + \frac{d x^i }{d t} \gamma_i \right)
\end{equation}

Therefore we can select this quantity $\gamma$, and our spatial velocity components, from our proper velocity:

\begin{equation*}
c \gamma = v \cdot \gamma^0
\end{equation*}

In equation \ref{eqn:gamma} we didn't define $\Bv$, only implictly requiring that it's square was $\sum (dx^i/dt)^2$, as we require for correspondence with Euclidean meaning.  This can be made more exact by
taking wedge products to weed out the time component:

\begin{equation*}
v \wedge \gamma^0 = \gamma \frac{d x^i }{d t} \gamma_i \wedge \gamma^0 
\end{equation*}

With a definition of $\Bv = \frac{d x^i }{d t} \gamma_i \wedge \gamma^0$ (which has the desired positive square), we therefore have:

\begin{align*}
\Bv
&= \frac{v \wedge \gamma^0 }{\gamma} \\
&= \frac{v \wedge \gamma^0 }{ v/c \cdot \gamma^0 } \\
\end{align*}

Or,
\begin{equation}
\Bv/c = \frac{v/c \wedge \gamma^0 }{ v/c \cdot \gamma^0 }
\end{equation}

All the lead up to this allows for expression of the spatial component of the proper velocity in a metric independent fashion.

\subsection{ Reciprocal Vectors. }

By reciprocal frame we mean the set of vectors $\{u^{\alpha}\}$ associated with a basis
for some linear subspace $\{u_{\alpha}\}$ such that:

\begin{equation*}
u_{\alpha} \cdot u^{\beta} = \delta_{\alpha}^\beta
\end{equation*}

In the special case of orthonormal vectors $u_{\alpha} \cdot u_{\beta} = \pm \delta_{\alpha\beta}$ the reciprocal frame vectors
are just the inverses (literally reciprocals), which can be verified by taking dot products:

\begin{align*}
\inv{u_{\alpha}} \cdot {u_{\alpha}}
&= \gpgradezero{ \inv{u_{\alpha}} {u_{\alpha}} } \\
&= \gpgradezero{ \inv{u_{\alpha}} \frac{u_{\alpha}}{u_{\alpha}} {u_{\alpha}} } \\
&= \gpgradezero{ \frac{(u_{\alpha})^2}{(u_{\alpha})^2} } \\
&= 1
\end{align*}

Written out explicitly for our positive "orthonormal" time metric:

\begin{align*}
(\gamma_0)^2 &= 1 \\
(\gamma_i)^2 &= -1,
\end{align*}

we have the reciprocal vectors:
\begin{align*}
\gamma_0 &= \gamma^0 \\
\gamma_i &= -\gamma^i \\
\end{align*}

Note that this last statement is consistent with $(\gamma_i)^2 = -1$, since $(\gamma_i)^2 = \gamma_i (-\gamma^i) = -\delta_i^i = -1$

Contrast this with a positive spatial metric:

\begin{align*}
(\gamma_0)^2 &= -1 \\
(\gamma_i)^2 &= 1,
\end{align*}

with reciprocal vectors:
\begin{align*}
\gamma_0 &= -\gamma^0 \\
\gamma_i &= \gamma^i \\
\end{align*}

where we have the opposite.

\subsection{ Reciprocal Bivectors. }

Now, let's examine the bivector reciprocals.  Given our orthonormal vector basis, let's invert the bivector and verify that is what we want:

\begin{align*}
\inv{\gamma_{\mu\nu}}
&= \inv{\gamma_{\mu\nu}} \frac{ \gamma_{\nu\mu} }{ \gamma_{\nu\mu} } \\
&= \inv{\gamma_{\mu\nu}} \inv{ \gamma_{\nu\mu} }{ \gamma_{\nu\mu} } \\
&= \inv{\gamma_{\mu\nu\nu\mu} }{ \gamma_{\nu\mu}} \\
&= \inv{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 } { \gamma_{\nu\mu}} \\
\end{align*}

Multiplication with our vector we will get 1 if this has the required reciprocal relationship:
\begin{align*}
\inv{\gamma_{\mu\nu}} \gamma_{\mu\nu}
&= \inv{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 } { \gamma_{\nu\mu}} \gamma_{\mu\nu} \\
&= \frac{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 }{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 } \\
&= 1
\end{align*}

Observe that unlike our basis vectors the bivector reciprocals are metric independant.  Let's verify this explicitly:

\begin{align*}
\inv{\gamma_{i0}} &= \inv{ (\gamma_{i})^2 (\gamma_{0})^2 } { \gamma_{0i}} \\
\inv{\gamma_{ij}} &= \inv{ (\gamma_{i})^2 (\gamma_{j})^2 } { \gamma_{ji}} \\
\inv{\gamma_{0i}} &= \inv{ (\gamma_{0})^2 (\gamma_{i})^2 } { \gamma_{i0}} \\
\end{align*}

With a spacetime mix of indexes we have a $-1$ denominator for either metric.  With a spatial only mix ($B$ components) we have $1$ in the denominator $1^2 = (-1)^2$ for either metric.

Now, perhaps counter to intuition the reciprocal $\inv{\gamma_{\mu\nu}}$ of $\gamma_{\mu\nu}$ is not $\gamma^{\mu\nu}$, but instead $\gamma^{\nu\mu}$.  Here the shorthand can be deceptive and it is worth verifying this statement explicitly:

\begin{align*}
\gamma_{\mu\nu} \cdot \gamma^{\alpha\beta}
&= (\gamma_{\mu} \wedge \gamma_{\nu}) \cdot (\gamma^{\alpha} \wedge \gamma^{\beta}) \\
&= ((\gamma_{\mu} \wedge \gamma_{\nu}) \cdot \gamma^{\alpha}) \cdot \gamma^{\beta}) \\
&= ( \gamma_{\mu} (\gamma_{\nu} \cdot \gamma^{\alpha}) - \gamma_{\nu} (\gamma_{\mu} \cdot \gamma^{\alpha}) ) \cdot \gamma^{\beta}) \\
&= ( \gamma_{\mu} {\delta_{\nu}}^{\alpha} - \gamma_{\nu} {\delta_{\mu}}^{\alpha} ) \cdot \gamma^{\beta} \\
\end{align*}

Or,
\begin{equation}
\gamma_{\mu\nu} \cdot \gamma^{\alpha\beta} = {\delta_{\mu}}^{\beta} {\delta_{\nu}}^{\alpha} - {\delta_{\nu}}^{\beta} {\delta_{\mu}}^{\alpha}
\end{equation}

In particular for matched pairs of indexes we have:
\begin{equation*}
\gamma_{\mu\nu} \cdot \gamma^{\nu\mu} = {\delta_{\mu}}^{\mu} {\delta_{\nu}}^{\nu} - {\delta_{\nu}}^{\mu} {\delta_{\mu}}^{\nu} = 1
\end{equation*}

\subsection{ Pseudoscalar expresed with reciprocal frame vectors. }

With a positive time metric

\begin{equation*}
\gamma_{0123} = -\gamma^{0123}
\end{equation*}

(three inversions for each of the spatial quantities).  This is metric invariant too since it will match the single negation for the same operation
using a positive spatial metric.

\subsection{ Spatial bivector basis commutation with pseudoscalar. }

I have been used to writing:
\begin{equation*}
\sigma_j = \gamma_{j0}
\end{equation*}

as a spatial basis, and having this equivalent to the four-pseudoscalar, but this only works with a time positive metric:
\begin{equation*}
i_3 = \sigma_{123} = \gamma_{102030} = \gamma_{0123} (\gamma_0)^2
\end{equation*}

With the spatial positive spacetime metric we therefore have:

\begin{equation*}
i_3 = \sigma_{123} = \gamma_{102030} = -i_4
\end{equation*}

instead of $i_3 = i_4$ as is the case with a time positive spacetime metric.  We see that the metric choice can also be interpretted as a choice of handedness.

That choice allowed Doran/Lasenby to initially write the field as a vector plus trivector where $i$ is the spatial pseudoscalar:

\begin{equation}\label{eqn:field}
F = \BE + i c \BB,
\end{equation}

and then later switch the interpretation of $i$ to the four space pseudoscalar.  The freedom to do so is metric dependent freedom, but
equation \ref{eqn:field} works regardless of metric when $i$ is uniformly interpretted as the spacetime pseudoscalar.

Regardless of the metric the spacetime pseudoscalar commutes with $\sigma_j = \gamma_{j0}$, since it anticommutes twice to cross:

\begin{equation*}
\sigma_j i = \gamma_{j00123} = \gamma_{00123j} = \gamma_{0123j0} = i \sigma_j
\end{equation*}

\subsection{ Gradient and Laplacian. }

As seen by the Lagrangian based derivation of the (spacetime or spatial) gradient, the form is metric independant and valid even for non-orthonormal frames:

\begin{equation*}
\grad = \gamma^{\mu} \PD{x^{\mu}}{}
\end{equation*}

\subsubsection{ Vector derivative. }

A cute aside, as pointed out in John Denker's paper, for orthonormal frames, this can also be written as:

\begin{equation}\label{eqn:gradient}
\grad = \inv{\gamma_{\mu}} \PD{x^{\mu}}{}
\end{equation}

as a mnemonic for remembering where the signs go, since in that form the upper and lower indexes are nicely matched in summation convention fashion.

Now, $\gamma_{\mu}$ is a constant when we are not working in curvalinear coordinates, and for constants we are used to the freedom to pull them into our
derivatives as in:

\begin{equation*}
\inv{c} \PD{t}{} = \PD{(ct)}{}
\end{equation*}

Supposing that one had an orthogonal vector decomposition:

\begin{equation*}
\Bx = \sum \gamma_i x^i = \sum \Bx_i
\end{equation*}

then, we can abuse notation and do the same thing with our unit vectors, rewriting the gradient equation \ref{eqn:gradient} as:

\begin{equation}\label{eqn:gradvec}
\grad = \PD{(\gamma_{\mu} x^{\mu})}{} = \sum \PD{\Bx_i}{}
\end{equation}

Is there anything to this that isn't just abuse of notation?  I think so, and I'm guessing the notational freedom to do this is closely related to
what Hestenes calls geometric calculus.

Expanding out the gradient in the form of equation \ref{eqn:gradvec} as a limit statement this becomes, rather loosely:

\begin{equation*}
\grad = \sum_i \lim_{d\Bx_i \to 0} \inv{ d \Bx_i } \left(f( \Bx + d\Bx_i ) - f( \Bx )\right)
\end{equation*}

If nothing else this justifies the notation for the polar form gradient of a function that is only radially dependent, where the quantity:

\begin{equation*}
\spacegrad = \rcap\PD{r}{} = \inv{\rcap}\PD{r}{}
\end{equation*}

is sometimes written:

\begin{equation*}
\spacegrad = \PD{\Br}{}
\end{equation*}

Tong does this for example in his online dynamics paper, although there it appears to be not much more than a fancy shorthand for gradient.

\subsection{ Four-Laplacian. }

Now, although our gradient is metric invarient, it's square the four-Laplacian is not.  There we have:

\begin{align*}
\grad^2
&= \sum (\gamma^{\mu})^2 \PDsq{x^{\mu}}{} \\
&= (\gamma^0)^2 \left( \PDsq{x^0}{} + (\gamma^0)^2 (\gamma^i)^2 \PDsq{x^i}{} \right) \\
&= (\gamma^0)^2 \left( \PDsq{x^0}{} - \PDsq{x^i}{} \right)
\end{align*}

This makes the metric dependency explicit so that we have:

\begin{equation*}
\grad^2 = \inv{c^2} \PDsq{t}{} - \PDsq{x^i}{} \quad \mbox{if $(\gamma^0)^2 = 1$}
\end{equation*}
\begin{equation*}
\grad^2 = \PDsq{x^i}{} - \inv{c^2} \PDsq{t}{} \quad \mbox{if $(\gamma^0)^2 = -1$}
\end{equation*}


\subsection{ Electrodynamic tensor. }

John Denker's paper writes:

\begin{equation}
F = (\BE + ic\BB) \gamma_0
\end{equation}

with
\begin{align*}
\BE &= E^i \gamma_i \\
\BB &= B^i \gamma_i
\end{align*}

Since he uses the postive end of the metric for spatial indexes this works fine.  Contrast to Doran/Lasenby who write:

\begin{equation}
F = \BE + ic\BB
\end{equation}

with the following implied spatial bivector representation:
\begin{align*}
\BE &= E^i \sigma_i = E^i \gamma_{i0} \\
\BB &= B^i \sigma_i = B^i \gamma_{i0}.
\end{align*}

That implied representation wasn't obvious to me, but I eventually figured out what they meant.  They also use $c=1$, so I've added it back in here for clarity.

The end result in both cases is a pure "bivector" representation for the complete field:

\begin{equation*}
F = E^j \gamma_{j0} + ic B^j \gamma_{j0}
\end{equation*}

ASIDE: Is bivector the term used for a completely grade two multivector, but not neccessarily a wedge product?
This field multivector is not definitely not a blade a term reserved for something that can be created by wedging (simple element in grassman algebra terms).
Here the field multivector cannot be expressed as the wedge product of two vectors unless one of the electric or magnetic fields is entirely zero (essentially
reducing the dimension of the spanning basis to a 3D bivector).

Let's look at the $B^j$ basis bivectors a bit more closely:

\begin{equation*}
i\gamma_{j0}
= \gamma_{0123j0}
= -\gamma_{01230j}
= +\gamma_{00123j}
= (\gamma_0)^2 \gamma_{123j}
\end{equation*}

Where,
\begin{equation*}
\gamma_{123j} =
\left\{
\begin{array}{l l}
(\gamma_{j})^2 \gamma_{23} & \quad \mbox{if $j = 1$} \\
(\gamma_{j})^2 \gamma_{31} & \quad \mbox{if $j = 2$} \\
(\gamma_{j})^2 \gamma_{12} & \quad \mbox{if $j = 3$} \\
\end{array} \right.
\end{equation*}

Combining these results we have a $(\gamma_0)^2 (\gamma_{j})^2 = -1$ coefficient that is metric invariant, and can write:

\begin{equation*}
i \sigma_{j} =
i \gamma_{j0} =
\left\{
\begin{array}{l l}
\gamma_{32} & \quad \mbox{if $j = 1$} \\
\gamma_{13} & \quad \mbox{if $j = 2$} \\
\gamma_{21} & \quad \mbox{if $j = 3$} \\
\end{array} \right.
\end{equation*}

% -1:23
% -2:31
% -3:12

Or, more compactly:

\begin{equation*}
i \sigma_{a} =
i \gamma_{a0} =
-\epsilon_{abc} \gamma_{bc}
\end{equation*}

Putting things back together, our bivector field in index notation is:

\begin{equation}\label{eqn:Fcomp}
F = E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k}
\end{equation}

\subsection{ Tensor components }

Now, given a grade two multivector such as our field, how can we in general compute the components of that field given any arbitrary basis.  This can be done using the reciprocal bivector frame:

\begin{equation*}
F = \sum a_{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu})
\end{equation*}

To calculate the coordinates $a_{{\mu} {\nu}}$ we can dot with
$e^{\nu} \wedge e^{\mu}$:

\begin{align*}
F \cdot (e^{\nu} \wedge e^{\mu})
&= \sum a_{{\alpha} {\beta}} (e_{\alpha} \wedge e_{\beta}) \cdot (e^{\nu} \wedge e^{\mu}) \\
&= ( a_{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu}) + a_{{\nu} {\mu}} (e_{\nu} \wedge e_{\mu}) ) \cdot (e^{\nu} \wedge e^{\mu}) \\
&= a_{{\mu} {\nu}} - a_{{\nu} {\mu}} \\
&= 2 a_{{\mu} {\nu}}
\end{align*}

Therefore
\begin{equation*}
F = \inv{2} \sum (F \cdot (e^{\nu} \wedge e^{\mu})) (e_{\mu} \wedge e_{\nu}) = \sum_{{\mu}<{\nu}} (F \cdot (e^{\nu} \wedge e^{\mu})) (e_{\mu} \wedge e_{\nu})
\end{equation*}

Or, with $F^{{\mu} {\nu}} = F \cdot (e^{\nu} \wedge e^{\mu})$ and summation convention:

\begin{equation}
F = \inv{2} F^{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu})
\end{equation}

It is not hard to see that the representation with respect to the reciprocal frame, with
$F_{{\mu} {\nu}} = F \cdot (e_{\nu} \wedge e_{\mu})$ must be:

\begin{equation}
F = \inv{2} F_{{\mu} {\nu}} (e^{\mu} \wedge e^{\nu})
\end{equation}

Writing $F^{\mu\nu}$ or $F_{\mu\nu}$ leaves a lot unspecified.  You will get a different tensor for each choice of basis.  Using this form amounts to the equivalent of using the matrix of a linear transformation with respect to a specified basis.

\subsection{ Electromagnetic tensor components. }

Next, let's calculate these
$F_{{\mu} {\nu}}$, and $F^{{\mu} {\nu}}$ values and relate them to our electric and magnetic fields so we can work in or translate to and from all of the traditional vector, the tensor, and the clifford/geometric languages.

\begin{equation*}
F^{{\mu} {\nu}} = \left( E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k} \right) \cdot \gamma^{\nu\mu}
\end{equation*}

By inspection our electric field components we have:

\begin{equation*}
F^{i0} = E^i,
\end{equation*}

and for the magnetic field:

\begin{equation*}
F^{{i} {j}} = - \epsilon_{k i j} c B^k = - \epsilon_{i j k} c B^k.
\end{equation*}

Putting in sample numbers this is:

\begin{align*}
F^{{3} {2}} &= - \epsilon_{3 2 1} c B^1 = c B^1 \\
F^{{1} {3}} &= - \epsilon_{1 3 2} c B^2 = c B^2 \\
F^{{2} {1}} &= - \epsilon_{2 1 3} c B^3 = c B^3 \\
\end{align*}

This can be summarized in matrix form:

\begin{equation*}
F^{\mu\nu} =
\begin{bmatrix}
0   & -E^1 & -E^2 & -E^3 \\
E^1 &   0  & -c B^3 &  c B^2 \\
E^2 &  c B^3 &   0  & -c B^1 \\
E^3 & -c B^2 &  c B^1 &   0  \\
\end{bmatrix}
\end{equation*}

Observe that no specific reference to a metric was required to evaluate these components.

\subsection{ reciprocal tensor (name?) }

The reciprocal frame representation of equation \ref{eqn:Fcomp} is metric dependent when expressed

\begin{align*}
F
&= E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k} \\
&= -E^i \gamma^{i 0} - \epsilon_{i j k} c B^i \gamma^{j k}
\end{align*}

Calculation of the reciprocal representation of the field tensor $F_{{\mu} {\nu}} = F \cdot \gamma_{\nu\mu}$ is now possible, and by inspection, regardless
of the metric:

\begin{align*}
F_{i0} &= -E^a = -F^{i0} \\
F_{ij} &= - \epsilon_{i j k} c B^k \gamma^{i j} = F^{ij}
\end{align*}

So, all the electric field components in the tensor invert:
\begin{equation*}
F_{\mu\nu} =
\begin{bmatrix}
0   & E^1 & E^2 & E^3 \\
-E^1 &   0  & -c B^3 &  c B^2 \\
-E^2 &  c B^3 &   0  & -c B^1 \\
-E^3 & -c B^2 &  c B^1 &   0  \\
\end{bmatrix}
\end{equation*}

Again, this is metric independent with this bivector based definition of $F_{\mu\nu}$, and $F^{\mu\nu}$.  Suprising, since I thought I had read otherwise.

\subsection{ Lagrangian density. }

Doran/Lasenby write the Lagrangian density in terms of $\gpgradezero{F^2}$, whereas Denker writes it in terms of $\gpgradezero{F \tilde{F}}$.  Is their
alternate choice in metric responsible for this difference.

Reversing the field since it is a bivector, just inverts the sign:

\begin{align*}
F &= E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k} \\
\tilde{F} &= E^i \gamma_{0 i} - \epsilon_{i j k} c B^i \gamma_{k j} = -F
\end{align*}

So the choice of $\gpgradezero{F^2}$ vs. $\gpgradezero{F \tilde{F}}$ is just a sign choice, and does not have anything to do with the metric.

Let's evaluate one of these:

\begin{align*}
F^2
&=
(E^i \gamma_{i 0} - \epsilon_{i j k} c B^i \gamma_{j k}) (E^u \gamma_{u 0} - \epsilon_{u v w} c B^u \gamma_{v w})  \\
&=
E^i E^u \gamma_{i 0} \gamma_{u 0}
- \epsilon_{u v w} E^i c B^u \gamma_{v w} \gamma_{i 0}
- \epsilon_{i j k} E^u c B^i \gamma_{j k} \gamma_{u 0}
+ \epsilon_{i j k} \epsilon_{u v w} c^2 B^i B^u \gamma_{v w} \gamma_{j k}
\\
\end{align*}

That first term is:

\begin{align*}
E^i E^u \gamma_{i 0} \gamma_{u 0}
&= \BE^2 + \sum_{i \ne j} E^i E^j ( \sigma_i \sigma_j + \sigma_j \sigma_i ) \\
&= \BE^2 + \sum_{i \ne j} 2 E^i E^j \sigma_i \cdot \sigma_j \\
&= \BE^2
\end{align*}

Hmm.  This is messy.  Let's try with $F = \BE + i c \BB$ directly (with the Doran/Lasenby convention: $\BE = E^k \sigma_k$) :

\begin{align*}
F^2
&= (\BE + i c \BB) (\BE + i c \BB) \\
&= \BE^2 + c^2 (i \BB) (i \BB) + c (i \BB \BE + \BE i \BB) \\
&= \BE^2 + c^2 (\BB i) (i \BB) + i c (\BB \BE + \BE \BB) \\
&= \BE^2 - c^2 \BB^2 + 2 i c (\BB \cdot \BE) \\
\end{align*}

\subsubsection{ Compared to tensor form. }

Now lets compare to the tensor form, where the Lagrangian density is written in terms of the product of upper and lower index tensors:

\begin{align*}
F_{\mu\nu}F^{\mu\nu}
&= F_{i 0}F^{i 0} +F_{0 i}F^{0 i} +\sum_{i<j} F_{i j}F^{i j} +\sum_{j<i} F_{i j}F^{i j} \\
&= 2 F_{i 0}F^{i 0} + 2 \sum_{i<j} F_{i j}F^{i j} \\
&= 2 (-E^i)(E^i) + 2 \sum_{i<j} (F^{i j})^2 \\
&= -2 \BE^2 + 2 \sum_{i<j} ( -\epsilon_{ijk} c B^k )^2 \\
&= -( \BE^2 + c^2 \BB^2 )
\end{align*}

Summarizing with a comparision of the bivector and tensor forms we have:

\begin{equation}
\inv{2} F_{\mu\nu}F^{\mu\nu} = c^2 \BB^2 - \BE^2 = - \gpgradezero{F^2} = \gpgradezero{ F \tilde{F} }
\end{equation}

But to put this in context we need to figure out how to apply this in the Lagrangian.  That appears to require a potential formulation of the field equations, so that is the next step.

\subsubsection{ Potential and relation to electromagnetic tensor. }

Since the field is a bivector is it reasonable to assume that it may be possible to express as the curl of a vector

\begin{equation*}
F = \grad \wedge A.
\end{equation*}

Inserting this into the field equation we have:
\begin{align*}
\grad (\grad \wedge A)
&= \grad \cdot (\grad \wedge A) + \underbrace{\grad \wedge \grad}_{=0} \wedge A \\
&= \grad^2 A - \grad ( \grad \cdot A ) \\
&= \inv{\epsilon_0 c} J
\end{align*}

With application of the guage condition $\grad \cdot A = 0$, one is left with the four scalar equations:

\begin{equation}\label{eqn:potential}
\grad^2 A = \inv{\epsilon_0 c} J
\end{equation}

This can also be seen more directly since the guage condition implies:

\begin{equation*}
\grad \wedge A = \grad \wedge A + \grad \cdot A = \grad A
\end{equation*}

from which equation \ref{eqn:potential} follows directly.  Observe that although the field equation was not metric
dependent, the equivalent potential equation is.

This metric dependency also shows up if one calculates the em tensor in terms of potential.

\begin{align*}
\grad \wedge A
&= \gamma^{\mu} \wedge \underbrace{\gamma_{\nu}}_{\gamma^{\nu} \gamma_{\nu} \gamma_{\nu}} \partial_{\mu} A^{\nu} \\
&= (\gamma_{\nu})^2 \gamma^{\mu\nu} \partial_{\mu} A^{\nu} \\
\end{align*}

Calcualating the tensor in terms of the bivector we have:

\begin{align*}
F^{\mu\nu}
&= F \cdot \gamma_{\nu\mu} \\
&= (\gamma_{\beta})^2 \partial_{\alpha} A^{\beta} \gamma^{\alpha\beta} \cdot \gamma_{\nu\mu} \\
&= (\gamma_{\beta})^2 \partial_{\alpha} A^{\beta} ((\gamma^{\alpha} \wedge \gamma^{\beta}) \cdot \gamma_{\nu}) \cdot \gamma_{\mu} \\
&= (\gamma_{\beta})^2 \partial_{\alpha} A^{\beta} ( \gamma^{\alpha} \delta^{\beta}_{\nu} -\gamma^{\beta} \delta^{\alpha}_{\nu} ) \cdot \gamma_{\mu} \\
&= (\gamma_{\beta})^2 \partial_{\alpha} A^{\beta} ( \delta^{\alpha}_{\mu} \delta^{\beta}_{\nu} -\delta^{\beta}_{\mu} \delta^{\alpha}_{\nu} ) \\
&= \partial_{\mu} A^{\nu} (\gamma_{\nu})^2 - \partial_{\nu} A^{\mu} (\gamma_{\mu})^2 \\
\end{align*}

This also explains the inconsistency in comparision to the wikipedia em tensor page that says this tensor is metric dependent.  There the tensor is defined in terms of a different field quantity, say $B$ directly in terms of the partials of that field.  Writing $B^{\mu} = A^{\mu} (\gamma_{\mu})^2$, that definition is:

\begin{equation*}
F^{\mu\nu} = \partial_{\mu} B^{\nu} - \partial_{\nu} B^{\mu}.
\end{equation*}

In our bivector based definition of the em tensor we have these magic $(\gamma_{\mu})^2$ accompanying each $A^{\mu}$ terms, ``cancelling'' the
metric dependence on the field itself in the resulting tensor field equation.

\subsection{ Lagrangian density in terms of potential. }

\end{document}
