\documentclass{article}

\input{../peeters_macros.tex}
\newcommand{\gpgrade}[2] {{\left\langle{{#1}}\right\rangle}_{#2}}
\newcommand{\gpgradezero}[1] {\gpgrade{#1}{0}}
\newcommand{\gpgradetwo}[1] {\gpgrade{#1}{2}}
\newcommand{\gpgradefour}[1] {\gpgrade{#1}{4}}

\title{ Metric signature dependencies for electromagnetic equations. }
\author{Peeter Joot}
\date{ Last Revision: $Date: 2008/09/05 03:19:33 $ }

\begin{document}

\maketitle{}

\section{ Motivation. }

Doran/Lasenby use a $+,-,-,-$ signature, and I had gotten used to that.  On first seeing the alternate signature used by John Denker's excellent
explainatory paper:

http://www.av8n.com/physics/maxwell-ga.pdf

I found myself disoriented.  How many of the identities that I was used to were metric dependent?   Here are some notes that explore some of the
metric dependencies of STA, in particular observing which identities are metric dependent and which aren't.

\section{}

\subsection{ spatial basis }

Our spatial (bivector) basis:

\begin{equation*}
\sigma_i = \gamma_i \wedge \gamma_0 = \gamma_{i0},
\end{equation*}

that behaves like Euclidean vectors (positive square) still behave as desired, regardless of the signature:

\begin{align*}
\sigma_i \cdot \sigma_j
&= \gpgradezero{\gamma_{i0j0}}  \\
&= - \gpgradezero{\gamma_{ij}} (\gamma_{0})^2  \\
&= -\delta_{ij} (\gamma_i)^2 (\gamma_{0})^2
\end{align*}

Regardless of the signature the pair of products $(\gamma_i)^2 (\gamma_{0})^2 = -1$, so our spatial bivectors are metric invariant.

\subsection{ How about commutation? }

Commutation with
\begin{equation*}
i \gamma_{\mu} = \gamma_{0123\mu} = \gamma_{\mu0123}
\end{equation*}

$\mu$ has to "pass" three indexes regardless of metric, so anticommutes for any $\mu$.

\begin{equation*}
\sigma_k \gamma_{\mu} = \gamma_{k0\mu}
\end{equation*}

If $k = \mu$, or $0 = \mu$, then we get a sign inversion, and otherwise commute (pass two indexes).  This is also metric invariant.

\subsection{ Reciprocal Vectors. }

By reciprocal frame we mean the set of vectors $\{u^{\alpha}\}$ associated with a basis 
for some linear subspace $\{u_{\alpha}\}$ such that:

\begin{equation*}
u_{\alpha} \cdot u^{\beta} = \delta_{\alpha}^\beta
\end{equation*}

In the special case of orthonormal vectors $u_{\alpha} \cdot u_{\beta} = \pm \delta_{\alpha\beta}$ the reciprocal frame vectors
are just the inverses (literally reciprocals), which can be verified by taking dot products:

\begin{align*}
\inv{u_{\alpha}} \cdot {u_{\alpha}}
&= \gpgradezero{ \inv{u_{\alpha}} {u_{\alpha}} } \\
&= \gpgradezero{ \inv{u_{\alpha}} \frac{u_{\alpha}}{u_{\alpha}} {u_{\alpha}} } \\
&= \gpgradezero{ \frac{(u_{\alpha})^2}{(u_{\alpha})^2} } \\
&= 1
\end{align*}

Written out explicitly for our positive "orthonormal" time metric:

\begin{align*}
(\gamma_0)^2 &= 1 \\
(\gamma_i)^2 &= -1,
\end{align*}

we have the reciprocal vectors:
\begin{align*}
\gamma_0 &= \gamma^0 \\
\gamma_i &= -\gamma^i \\
\end{align*}

Note that this last statement is consistent with $(\gamma_i)^2 = -1$, since $(\gamma_i)^2 = \gamma_i (-\gamma^i) = -\delta_i^i = -1$

Contrast this with a positive spatial metric:

\begin{align*}
(\gamma_0)^2 &= -1 \\
(\gamma_i)^2 &= 1,
\end{align*}

with reciprocal vectors:
\begin{align*}
\gamma_0 &= -\gamma^0 \\
\gamma_i &= \gamma^i \\
\end{align*}

where we have the opposite.

\subsection{ Reciprocal Bivectors. }

Now, let's examine the bivector reciprocals.  Given our orthonormal vector basis, let's invert the bivector and verify that is what we want:

\begin{align*}
\inv{\gamma_{\mu\nu}}
&= \inv{\gamma_{\mu\nu}} \frac{ \gamma_{\nu\mu} }{ \gamma_{\nu\mu} } \\
&= \inv{\gamma_{\mu\nu}} \inv{ \gamma_{\nu\mu} }{ \gamma_{\nu\mu} } \\
&= \inv{\gamma_{\mu\nu\nu\mu} }{ \gamma_{\nu\mu}} \\
&= \inv{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 } { \gamma_{\nu\mu}} \\
\end{align*}

Multiplication with our vector we will get 1 if this has the required reciprocal relationship:
\begin{align*}
\inv{\gamma_{\mu\nu}} \gamma_{\mu\nu}
&= \inv{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 } { \gamma_{\nu\mu}} \gamma_{\mu\nu} \\
&= \frac{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 }{ (\gamma_{\mu})^2 (\gamma_{\nu})^2 } \\
&= 1
\end{align*}

Observe that unlike our basis vectors the bivector reciprocals are metric independant.  Let's verify this explicitly:

\begin{align*}
\inv{\gamma_{i0}} &= \inv{ (\gamma_{i})^2 (\gamma_{0})^2 } { \gamma_{0i}} \\
\inv{\gamma_{ij}} &= \inv{ (\gamma_{i})^2 (\gamma_{j})^2 } { \gamma_{ji}} \\
\inv{\gamma_{0i}} &= \inv{ (\gamma_{0})^2 (\gamma_{i})^2 } { \gamma_{i0}} \\
\end{align*}

With a spacetime mix of indexes we have a $-1$ denominator for either metric.  With a spatial only mix ($B$ components) we have $1$ in the denominator $1^2 = (-1)^2$ for either metric.

Now, perhaps counter to intuition the reciprocal $\inv{\gamma_{\mu\nu}}$ of $\gamma_{\mu\nu}$ is not $\gamma^{\mu\nu}$, but instead $\gamma^{\nu\mu}$.  Here the shorthand can be deceptive and it is worth verifying this statement explicitly:

\begin{align*}
\gamma_{\mu\nu} \cdot \gamma^{\alpha\beta}
&= (\gamma_{\mu} \wedge \gamma_{\nu}) \cdot (\gamma^{\alpha} \wedge \gamma^{\beta}) \\
&= ((\gamma_{\mu} \wedge \gamma_{\nu}) \cdot \gamma^{\alpha}) \cdot \gamma^{\beta}) \\
&= ( \gamma_{\mu} (\gamma_{\nu} \cdot \gamma^{\alpha}) - \gamma_{\nu} (\gamma_{\mu} \cdot \gamma^{\alpha}) ) \cdot \gamma^{\beta}) \\
&= ( \gamma_{\mu} {\delta_{\nu}}^{\alpha} - \gamma_{\nu} {\delta_{\mu}}^{\alpha} ) \cdot \gamma^{\beta} \\
\end{align*}

Or,
\begin{equation}
\gamma_{\mu\nu} \cdot \gamma^{\alpha\beta} = {\delta_{\mu}}^{\beta} {\delta_{\nu}}^{\alpha} - {\delta_{\nu}}^{\beta} {\delta_{\mu}}^{\alpha}
\end{equation}

In particular for matched pairs of indexes we have:
\begin{equation*}
\gamma_{\mu\nu} \cdot \gamma^{\nu\mu} = {\delta_{\mu}}^{\mu} {\delta_{\nu}}^{\nu} - {\delta_{\nu}}^{\mu} {\delta_{\mu}}^{\nu} = 1
\end{equation*}

\subsection{ Electrodynamic tensor. }

John Denker's paper writes:

\begin{equation}
F = (\BE + ic\BB) \gamma_0
\end{equation}

with
\begin{align*}
\BE &= E^i \gamma_i \\
\BB &= B^i \gamma_i
\end{align*}

Since he uses the postive end of the metric for spatial indexes this works fine.  Contrast to Doran/Lasenby who write:

\begin{equation}
F = \BE + ic\BB
\end{equation}

with the following implied spatial bivector representation:
\begin{align*}
\BE &= E^i \sigma_i = E^i \gamma_{i0} \\
\BB &= B^i \sigma_i = B^i \gamma_{i0}.
\end{align*}

That implied representation wasn't obvious to me, but I eventually figured out what they meant.  They also use $c=1$, so I've added it back in here for clarity.

The end result in both cases is a pure "bivector" representation for the complete field:

\begin{equation*}
F = E^j \gamma_{j0} + icB^j \gamma_{j0}
\end{equation*}

ASIDE: Note that bivector is an inaccurate label (depending on definition perhaps) since this grade two multivector cannot be formed by the wedge product of two vectors unless one of the electric or magnetic fields is entirely zero.

Let's look at the $B^j$ basis bivectors a bit more closely:

\begin{equation*}
i\gamma_{j0}
= \gamma_{0123j0}
= -\gamma_{01230j}
= +\gamma_{00123j}
= (\gamma_0)^2 \gamma_{123j}
\end{equation*}

Where,
\begin{equation*}
\gamma_{123j} =
\left\{
\begin{array}{l l}
(\gamma_{j})^2 \gamma_{23} & \quad \mbox{if $j = 1$} \\
(\gamma_{j})^2 \gamma_{31} & \quad \mbox{if $j = 2$} \\
(\gamma_{j})^2 \gamma_{12} & \quad \mbox{if $j = 3$} \\
\end{array} \right.
\end{equation*}

Combining these results we have a $(\gamma_0)^2 (\gamma_{j})^2 = -1$ coefficient that is metric invariant, and can write:

\begin{equation*}
i \sigma_{j} =
i \gamma_{j0} =
\left\{
\begin{array}{l l}
\gamma_{32} & \quad \mbox{if $j = 1$} \\
\gamma_{13} & \quad \mbox{if $j = 2$} \\
\gamma_{21} & \quad \mbox{if $j = 3$} \\
\end{array} \right.
\end{equation*}

% -1:23
% -2:31
% -3:12

Or, more compactly:

\begin{equation*}
i \sigma_{a} =
i \gamma_{a0} =
-\epsilon_{abc} \gamma_{bc}
\end{equation*}

Putting things back together, our bivector field in index notation is:

\begin{equation}\label{eqn:Fcomp}
F = E^a \gamma_{a0} - \epsilon_{abc} B^a \gamma_{bc}
\end{equation}

\subsection{ Tensor components }

Now, given a grade two multivector such as our field, how can we in general compute the components of that field given any arbitrary basis.  This can be done using the reciprocal bivector frame:

\begin{equation*}
F = \sum a_{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu})
\end{equation*}

To calculate the coordinates $a_{{\mu} {\nu}}$ we can dot with 
$e^{\nu} \wedge e^{\mu}$:

\begin{align*}
F \cdot (e^{\nu} \wedge e^{\mu})
&= \sum a_{{\alpha} {\beta}} (e_{\alpha} \wedge e_{\beta}) \cdot (e^{\nu} \wedge e^{\mu}) \\
&= ( a_{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu}) + a_{{\nu} {\mu}} (e_{\nu} \wedge e_{\mu}) ) \cdot (e^{\nu} \wedge e^{\mu}) \\
&= a_{{\mu} {\nu}} - a_{{\nu} {\mu}} \\
&= 2 a_{{\mu} {\nu}}
\end{align*}

Therefore 
\begin{equation*}
F = \inv{2} \sum (F \cdot (e^{\nu} \wedge e^{\mu})) (e_{\mu} \wedge e_{\nu}) = \sum_{{\mu}<{\nu}} (F \cdot (e^{\nu} \wedge e^{\mu})) (e_{\mu} \wedge e_{\nu})
\end{equation*}

Or, with $F^{{\mu} {\nu}} = F \cdot (e^{\nu} \wedge e^{\mu})$ and summation convention:

\begin{equation}
F = \inv{2} F^{{\mu} {\nu}} (e_{\mu} \wedge e_{\nu})
\end{equation}

It is not hard to see that the representation with respect to the reciprocal frame, with
$F_{{\mu} {\nu}} = F \cdot (e_{\nu} \wedge e_{\mu})$ must be:

\begin{equation}
F = \inv{2} F_{{\mu} {\nu}} (e^{\mu} \wedge e^{\nu})
\end{equation}

Next, let's calculate these 
$F_{{\mu} {\nu}}$, and $F^{{\mu} {\nu}}$ values and relate them to our electric and magnetic fields so we can work in or translate to and from all of the traditional vector, the tensor, and the clifford/geometric languages.

\end{document}
