%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

\chapter{Problem Set 3}
\label{chap:relElectroDynProblemSet3}
%\blogpage{http://sites.google.com/site/peeterjoot/math2011/relElectroDynProblemSet3.pdf}
%\date{Feb 15, 2011}

\section{Problem 1.  Fun with \texorpdfstring{$\epsilon_{\alpha\beta\gamma}$, $\epsilon^{ijkl}$, $F_{ij}$}{antisymmetric tensors}, and the duality of Maxwell's equations in vacuum}

\subsection{1. Statement.  rank 3 spatial antisymmetric tensor identities}

Prove that

\begin{equation}\label{eqn:relElectroDynProblemSet3:10}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\delta_{\alpha\mu} \delta_{\beta\nu}
-\delta_{\alpha\nu} \delta_{\beta\mu}
\end{equation}

and use it to find the familiar relation for

\begin{equation}\label{eqn:relElectroDynProblemSet3:30}
(\BA \cross \BB) \cdot (\BC \cross \BD)
\end{equation}

Also show that

\begin{equation}\label{eqn:relElectroDynProblemSet3:50}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
=
2 \delta_{\alpha\mu}.
\end{equation}

(Einstein summation implied all throughout this problem).

\subsection{1. Solution}

We can explicitly expand the (implied) sum over indices $\gamma$.  This is

\begin{equation}\label{eqn:relElectroDynProblemSet3:70}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\epsilon_{\alpha \beta 1} \epsilon_{\mu \nu 1}
+\epsilon_{\alpha \beta 2} \epsilon_{\mu \nu 2}
+\epsilon_{\alpha \beta 3} \epsilon_{\mu \nu 3}
\end{equation}

For any $\alpha \ne \beta$ only one term is non-zero.  For example with $\alpha,\beta = 2,3$, we have just a contribution from the $\gamma = 1$ part of the sum

\begin{equation}\label{eqn:relElectroDynProblemSet3:90}
\epsilon_{2 3 1} \epsilon_{\mu \nu 1}.
\end{equation}

The value of this for $(\mu,\nu) = (\alpha,\beta)$ is

\begin{equation}\label{eqn:relElectroDynProblemSet3:110}
(\epsilon_{2 3 1})^2
\end{equation}

whereas for $(\mu,\nu) = (\beta,\alpha)$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:130}
-(\epsilon_{2 3 1})^2
\end{equation}

Our sum has value one when $(\alpha, \beta)$ matches $(\mu, \nu)$, and value minus one for when $(\mu, \nu)$ are permuted.  We can summarize this, by saying that when $\alpha \ne \beta$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:150}
\myBoxed{
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\delta_{\alpha\mu} \delta_{\beta\nu}
-\delta_{\alpha\nu} \delta_{\beta\mu}.
}
\end{equation}

However, observe that when $\alpha = \beta$ the RHS is

\begin{equation}\label{eqn:relElectroDynProblemSet3:170}
\delta_{\alpha\mu} \delta_{\alpha\nu}
-\delta_{\alpha\nu} \delta_{\alpha\mu} = 0,
\end{equation}

as desired, so this form works in general without any $\alpha \ne \beta$ qualifier, completing this part of the problem.

\begin{align*}
(\BA \cross \BB) \cdot (\BC \cross \BD)
&=
(\epsilon_{\alpha \beta \gamma} \Be^\alpha A^\beta B^\gamma ) \cdot
(\epsilon_{\mu \nu \sigma} \Be^\mu C^\nu D^\sigma ) \\
&=
\epsilon_{\alpha \beta \gamma} A^\beta B^\gamma
\epsilon_{\alpha \nu \sigma} C^\nu D^\sigma \\
&=
(
\delta_{\beta \nu} \delta_{\gamma\sigma}
-\delta_{\beta \sigma} \delta_{\gamma\nu} )
A^\beta B^\gamma
C^\nu D^\sigma \\
&=
A^\nu B^\sigma
C^\nu D^\sigma
-A^\sigma B^\nu
C^\nu D^\sigma.
\end{align*}

This gives us
\begin{equation}\label{eqn:relElectroDynProblemSet3:190}
\myBoxed{
(\BA \cross \BB) \cdot (\BC \cross \BD)
=
(\BA \cdot \BC)
(\BB \cdot \BD)
-
(\BA \cdot \BD)
(\BB \cdot \BC).
}
\end{equation}

We have one more identity to deal with.

\begin{equation}\label{eqn:relElectroDynProblemSet3:210}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
\end{equation}

We can expand out this (implied) sum slow and dumb as well

\begin{align*}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
&=
\epsilon_{\alpha 1 2} \epsilon_{\mu 1 2}
+\epsilon_{\alpha 2 1} \epsilon_{\mu 2 1} \\
&+\epsilon_{\alpha 1 3} \epsilon_{\mu 1 3}
+\epsilon_{\alpha 3 1} \epsilon_{\mu 3 1} \\
&+\epsilon_{\alpha 2 3} \epsilon_{\mu 2 3}
+\epsilon_{\alpha 3 2} \epsilon_{\mu 3 2} \\
&=
2 \epsilon_{\alpha 1 2} \epsilon_{\mu 1 2}
+ 2 \epsilon_{\alpha 1 3} \epsilon_{\mu 1 3}
+ 2 \epsilon_{\alpha 2 3} \epsilon_{\mu 2 3}
\end{align*}

Now, observe that for any $\alpha \in (1,2,3)$ only one term of this sum is picked up.  For example, with no loss of generality, pick $\alpha = 1$.  We are left with only

\begin{equation}\label{eqn:relElectroDynProblemSet3:230}
2 \epsilon_{1 2 3} \epsilon_{\mu 2 3}
\end{equation}

This has the value
\begin{equation}\label{eqn:relElectroDynProblemSet3:250}
2 (\epsilon_{1 2 3})^2 = 2
\end{equation}

when $\mu = \alpha$ and is zero otherwise.  We can therefore summarize the evaluation of this sum as

\begin{equation}\label{eqn:relElectroDynProblemSet3:270}
\myBoxed{
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
=  2\delta_{\alpha\mu},
}
\end{equation}

completing this problem.

\subsection{2. Statement.  Determinant of three by three matrix}

Prove that for any $3 \times 3$ matrix $\Norm{A_{\alpha\beta}}$: $\epsilon_{\mu\nu\lambda} A_{\alpha \mu} A_{\beta\nu} A_{\gamma\lambda} = \epsilon_{\alpha \beta \gamma} \Det A$ and that $\epsilon_{\alpha\beta\gamma} \epsilon_{\mu\nu\lambda} A_{\alpha \mu} A_{\beta\nu} A_{\gamma\lambda} = 6 \Det A$.

\subsection{2. Solution}

In class Simon showed us how the first identity can be arrived at using the triple product $\Ba \cdot (\Bb \cross \Bc) = \Det(\Ba \Bb \Bc)$.  It occurred to me later that I had seen the identity to be proven in the context of Geometric Algebra, but hhad not recognized it in this tensor form.  Basically, a wedge product can be expanded in sums of determinants, and when the dimension of the space is the same as the vector, we have a pseudoscalar times the determinant of the components.

For example, in \R{2}, let us take the wedge product of a pair of vectors.  As preparation for the relativistic \R{4} case We will not require an orthonormal basis, but express the vector in terms of a reciprocal frame and the associated components

\begin{equation}\label{eqn:relElectroDynProblemSet3:290}
a = a^i e_i = a_j e^j
\end{equation}

where
\begin{equation}\label{eqn:relElectroDynProblemSet3:310}
e^i \cdot e_j = {\delta^i}_j.
\end{equation}

When we get to the relativistic case, we can pick (but do not have to) the standard basis

\begin{align}\label{eqn:relElectroDynProblemSet3:330}
e_0 &= (1, 0, 0, 0) \\
e_1 &= (0, 1, 0, 0) \\
e_2 &= (0, 0, 1, 0) \\
e_3 &= (0, 0, 0, 1),
\end{align}

for which our reciprocal frame is implicitly defined by the metric
\begin{align}\label{eqn:relElectroDynProblemSet3:350}
e^0 &= (1, 0, 0, 0) \\
e^1 &= (0, -1, 0, 0) \\
e^2 &= (0, 0, -1, 0) \\
e^3 &= (0, 0, 0, -1).
\end{align}

Anyways.  Back to the problem.  Let us examine the \R{2} case.  Our wedge product in coordinates is

\begin{equation}\label{eqn:relElectroDynProblemSet3:370}
a \wedge b
=
a^i b^j (e_i \wedge e_j)
\end{equation}

Since there are only two basis vectors we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:390}
a \wedge b
=
(a^1 b^2 - a^2 b^1) e_1 \wedge e_2 = \Det \Norm{a^i b^j} (e_1 \wedge e_2).
\end{equation}

Our wedge product is a product of the determinant of the vector coordinates, times the \R{2} pseudoscalar $e_1 \wedge e_2$.

This does not look quite like the \R{3} relation that we want to prove, which had an antisymmetric tensor factor for the determinant.  Observe that we get the determinant by picking off the $e_1 \wedge e_2$ component of the bivector result (the only component in this case), and we can do that by dotting with $e^2 \cdot e^1$.  To get an antisymmetric tensor times the determinant, we have only to dot with a different pseudoscalar (one that differs by a possible sign due to permutation of the indices).  That is

\begin{align*}
(e^t \wedge e^s) \cdot (a \wedge b)
&=
a^i b^j (e^t \wedge e^s) \cdot (e_i \wedge e_j) \\
&=
a^i b^j
\left( {\delta^{s}}_i {\delta^{t}}_j
-{\delta^{t}}_i {\delta^{s}}_j  \right) \\
&=
a^i b^j
{\delta^{[t}}_j {\delta^{s]}}_i \\
&=
a^i b^j
{\delta^{t}}_{[j} {\delta^{s}}_{i]} \\
&=
a^{[i} b^{j]}
{\delta^{t}}_{j} {\delta^{s}}_{i} \\
&=
a^{[s} b^{t]}
\end{align*}

Now, if we write $a^i = A^{1 i}$ and $b^j = A^{2 j}$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:410}
(e^t \wedge e^s) \cdot (a \wedge b)
=
A^{1 s} A^{2 t} -A^{1 t} A^{2 s}
\end{equation}

We can write this in two different ways.  One of which is

\begin{equation}\label{eqn:relElectroDynProblemSet3:430}
A^{1 s} A^{2 t} -A^{1 t} A^{2 s} =
\epsilon^{s t} \Det \Norm{A^{ij}}
\end{equation}

and the other of which is by introducing free indices for $1$ and $2$, and summing antisymmetrically over these.  That is

\begin{equation}\label{eqn:relElectroDynProblemSet3:450}
A^{1 s} A^{2 t} -A^{1 t} A^{2 s}
=
A^{a s} A^{b t} \epsilon_{a b}
\end{equation}

So, we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:470}
\myBoxed{
A^{a s} A^{b t} \epsilon_{a b} =
A^{1 i} A^{2 j} {\delta^{[t}}_j {\delta^{s]}}_i =
\epsilon^{s t} \Det \Norm{A^{ij}},
}
\end{equation}

This result hold regardless of the metric for the space, and does not require that we were using an orthonormal basis.  When the metric is Euclidean and we have an orthonormal basis, then all the indices can be dropped.

The \R{3} and \R{4} cases follow in exactly the same way, we just need more vectors in the wedge products.

For the \R{3} case we have

\begin{align*}
(e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c)
&=
a^i b^j c^k
(e^u \wedge e^t \wedge e^s) \cdot (e_i \wedge e_j \wedge e_k) \\
&=
a^i b^j c^k
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i \\
&=
a^{[s} b^t c^{u]}
\end{align*}

Again, with $a^i = A^{1 i}$ and $b^j = A^{2 j}$, and $c^k = A^{3 k}$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:490}
(e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c)
=
A^{1 i} A^{2 j} A^{3 k}
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i
\end{equation}

and we can choose to write this in either form, resulting in the identity

\begin{equation}\label{eqn:relElectroDynProblemSet3:510}
\myBoxed{
\epsilon^{s t u} \Det \Norm{A^{ij}}
=
A^{1 i} A^{2 j} A^{3 k}
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i
=
\epsilon_{a b c} A^{a s} A^{b t} A^{c u}.
}
\end{equation}

The \R{4} case follows exactly the same way, and we have

\begin{align*}
(e^v \wedge e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c \wedge d)
&=
a^i b^j c^k d^l
(e^v \wedge e^u \wedge e^t \wedge e^s) \cdot (e_i \wedge e_j \wedge e_k \wedge e_l) \\
&=
a^i b^j c^k d^l
{\delta^{[v}}_l
{\delta^{u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i \\
&=
a^{[s} b^t c^{u} d^{v]}.
\end{align*}

This time with $a^i = A^{0 i}$ and $b^j = A^{1 j}$, and $c^k = A^{2 k}$, and $d^l = A^{3 l}$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:530}
\myBoxed{
\epsilon^{s t u v} \Det \Norm{A^{ij}}
=
A^{0 i} A^{1 j} A^{2 k} A^{3 l}
{\delta^{[v}}_l
{\delta^{u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i
=
\epsilon_{a b c d} A^{a s} A^{b t} A^{c u} A^{d v}.
}
\end{equation}

This one is almost the identity to be established later in problem 1.4.  We have only to raise and lower some indices to get that one.  Note that in the Minkowski standard basis above, because $s, t, u, v$ must be a permutation of $0,1,2,3$ for a non-zero result, we must have

\begin{equation}\label{eqn:relElectroDynProblemSet3:550}
\epsilon^{s t u v} = (-1)^3 (+1) \epsilon_{s t u v}.
\end{equation}

So raising and lowering the identity above gives us

\begin{equation}\label{eqn:relElectroDynProblemSet3:570}
-\epsilon_{s t u v} \Det \Norm{A_{ij}}
=
\epsilon^{a b c d} A_{a s} A_{b t} A_{c u} A_{d u}.
\end{equation}

No sign changes were required for the indices $a, b, c, d$, since they are paired.

Until we did the raising and lowering operations here, there was no specific metric required, so our first result \eqnref{eqn:relElectroDynProblemSet3:530} is the more general one.

There is one more part to this problem, doing the antisymmetric sums over the indices $s, t, \cdots$.  For the \R{2} case we have

\begin{align*}
\epsilon_{s t} \epsilon_{a b} A^{a s} A^{b t}
&=
\epsilon_{s t} \epsilon^{s t} \Det \Norm{A^{ij}} \\
&=
\left( 
\epsilon_{1 2} \epsilon^{1 2} 
+\epsilon_{2 1} \epsilon^{2 1} 
\right)
\Det \Norm{A^{ij}} \\
&=
\left( 
1^2 + (-1)^2
\right)
\Det \Norm{A^{ij}}
\end{align*}

We conclude that

\begin{equation}\label{eqn:relElectroDynProblemSet3:600}
\myBoxed{
\epsilon_{s t} \epsilon_{a b} A^{a s} A^{b t} = 2! \Det \Norm{A^{ij}}.
}
\end{equation}

For the \R{3} case we have the same operation

\begin{align*}
\epsilon_{s t u} \epsilon_{a b c} A^{a s} A^{b t} A^{c u}
&=
\epsilon_{s t u} \epsilon^{s t u} \Det \Norm{A^{ij}} \\
&=
\left( 
\epsilon_{1 2 3} \epsilon^{1 2 3} 
+\epsilon_{1 3 2} \epsilon^{1 3 2} 
+ \cdots
\right)
\Det \Norm{A^{ij}} \\
&=
(\pm 1)^2 (3!)
\Det \Norm{A^{ij}}.
\end{align*}

So we conclude
\begin{equation}\label{eqn:relElectroDynProblemSet3:620}
\myBoxed{
\epsilon_{s t u} \epsilon_{a b c} A^{a s} A^{b t} A^{c u}= 3! \Det \Norm{A^{ij}}.
}
\end{equation}

It is clear what the pattern is, and if we evaluate the sum of the antisymmetric tensor squares in \R{4} we have

\begin{align*}
\epsilon_{s t u v} \epsilon_{s t u v}
&=
\epsilon_{0 1 2 3} \epsilon_{0 1 2 3}
+
\epsilon_{0 1 3 2} \epsilon_{0 1 3 2}
+
\epsilon_{0 2 1 3} \epsilon_{0 2 1 3}
+ \cdots \\
&= (\pm 1)^2 (4!),
\end{align*}

So, for our SR case we have
\begin{equation}\label{eqn:relElectroDynProblemSet3:640}
\myBoxed{
\epsilon_{s t u v} \epsilon_{a b c d} A^{a s} A^{b t} A^{c u} A^{d v}= 4! \Det \Norm{A^{ij}}.
}
\end{equation}

This was part of question 1.4, albeit in lower index form.  Here since all indices are matched, we have the same result without major change

\begin{equation}\label{eqn:relElectroDynProblemSet3:660}
\myBoxed{
\epsilon^{s t u v} \epsilon^{a b c d} A_{a s} A_{b t} A_{c u} A_{d v}= 4! \Det \Norm{A_{ij}}.
}
\end{equation}

The main difference is that we are now taking the determinant of a lower index tensor.

\subsection{3. Statement.  Rotational invariance of 3D antisymmetric tensor}

Use the previous results to show that $\epsilon_{\mu\nu\lambda}$ is invariant under rotations.

\subsection{3. Solution}

We apply transformations to coordinates (and thus indices) of the form

\begin{equation}\label{eqn:relElectroDynProblemSet3:680}
x_\mu \rightarrow O_{\mu\nu} x_\nu
\end{equation}

With our tensor transforming as its indices, we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:700}
\epsilon_{\mu\nu\lambda} \rightarrow \epsilon_{\alpha\beta\sigma} O_{\mu\alpha} O_{\nu\beta} O_{\lambda\sigma}.
\end{equation}

We have got \eqnref{eqn:relElectroDynProblemSet3:510}, which after dropping indices, because we are in a Euclidean space, we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:510b}
\epsilon_{\mu \nu \lambda} \Det \Norm{A_{ij}} = \epsilon_{\alpha \beta \sigma} A_{\alpha \mu} A_{\beta \nu} A_{\sigma \lambda}.
\end{equation}

Let $A_{i j} = O_{j i}$, which gives us

\begin{equation}\label{eqn:relElectroDynProblemSet3:720}
\epsilon_{\mu\nu\lambda} \rightarrow \epsilon_{\mu\nu\lambda} \Det A^\T
\end{equation}

but since $\Det O = \Det O^\T$, we have shown that $\epsilon_{\mu\nu\lambda}$ is invariant under rotation.

\subsection{4. Statement.  Rotational invariance of 4D antisymmetric tensor}

Use the previous results to show that $\epsilon_{i j k l}$ is invariant under Lorentz transformations.

\subsection{4. Solution}

This follows the same way.  We assume a transformation of coordinates of the following form

\begin{align}\label{eqn:relElectroDynProblemSet3:740}
(x')^i &= {O^i}_j x^j \\
(x')_i &= {O_i}^j x_j,
\end{align}

where the determinant of ${O^i}_j = 1$ (sanity check of sign: ${O^i}_j = {\delta^i}_j$).

Our antisymmetric tensor transforms as its coordinates individually

\begin{align*}
\epsilon_{i j k l} 
&\rightarrow \epsilon_{a b c d} 
{O_i}^a
{O_j}^b
{O_k}^c
{O_l}^d \\
&= \epsilon^{a b c d} 
O_{i a}
O_{j b}
O_{k c}
O_{l d} \\
\end{align*}

Let $P_{ij} = O_{ji}$, and raise and lower all the indices in \eqnref{eqn:relElectroDynProblemSet3:530b} for
\begin{equation}\label{eqn:relElectroDynProblemSet3:530b}
-\epsilon_{s t u v} \Det \Norm{P_{ij}}
=
\epsilon^{a b c d} P_{a s} P_{b t} P_{c u} P_{d v}.
\end{equation}

We have
\begin{align*}
\epsilon_{i j k l} 
&= \epsilon^{a b c d} 
P_{a i}
P_{a j}
P_{a k}
P_{a l} \\
&=
-\epsilon_{i j k l} \Det \Norm{P_{ij}} \\
&=
-\epsilon_{i j k l} \Det \Norm{O_{ij}} \\
&=
-\epsilon_{i j k l} \Det \Norm{g_{im} {O^m}_j } \\
&=
-\epsilon_{i j k l} (-1)(1) \\
&=
\epsilon_{i j k l}
\end{align*}

Since $\epsilon_{i j k l} = -\epsilon^{i j k l}$ both are therefore invariant under Lorentz transformation.

\subsection{5. Statement.  Sum of contracting symmetric and antisymmetric rank 2 tensors}

Show that $A^{ij} B_{ij} = 0$ if $A$ is symmetric and $B$ is antisymmetric.

\subsection{5. Solution}

We swap indices in $B$, switch dummy indices, then swap indices in $A$

\begin{align*}
A^{i j} B_{i j} 
&= 
-A^{i j} B_{j i} \\
&= 
-A^{j i} B_{i j} \\
&= 
-A^{i j} B_{i j} \\
\end{align*}

Our result is the negative of itself, so must be zero.

\subsection{6. Statement.  Characteristic equation for the electromagnetic strength tensor}

Show that $P(\lambda) = \Det \Norm{F_{i j} - \lambda g_{i j}}$ is invariant under Lorentz transformations.  Consider the polynomial of $P(\lambda)$, also called the characteristic polynomial of the matrix $\Norm{F_{i j}}$.  Find the coefficients of the expansion of $P(\lambda)$ in powers of $\lambda$ in terms of the components of $\Norm{F_{i j}}$.  Use the result to argue that $\BE \cdot \BB$ and $\BE^2 - \BB^2$ are Lorentz invariant.

\subsection{6. Solution}

\subsubsection{The invariance of the determinant}

Let us consider how any lower index rank 2 tensor transforms.  Given a transformation of coordinates

\begin{align}\label{eqn:relElectroDynProblemSet3:800}
(x^i)' &= {O^i}_j x^j \\
(x_i)' &= {O_i}^j x^j ,
\end{align}

where $\Det \Norm{ {O^i}_j } = 1$, and ${O_i}^j = {O^m}_n g_{i m} g^{j n}$.  Let us reflect briefly on why this determinant is unit valued.  We have

\begin{equation}\label{eqn:relElectroDynProblemSet3:820}
(x^i)' (x_i)'
= {O_i}^a x^a {O^i}_b x^b = x^b x_b,
\end{equation}

which implies that the transformation product is
\begin{equation}\label{eqn:relElectroDynProblemSet3:840}
{O_i}^a {O^i}_b = {\delta^a}_b,
\end{equation}

the identity matrix.  The identity matrix has unit determinant, so we must have

\begin{equation}\label{eqn:relElectroDynProblemSet3:860}
1 = (\Det \hat{G})^2 (\Det \Norm{ {O^i}_j })^2.
\end{equation}

Since $\Det \hat{G} = -1$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:880}
\Det \Norm{ {O^i}_j } = \pm 1,
\end{equation}

which is all that we can say about the determinant of this class of transformations by considering just invariance.  If we restrict the transformations of coordinates to those of the same determinant sign as the identity matrix, we rule out reflections in time or space.  This seems to be the essence of the $SO(1,3)$ labeling.

Why dwell on this?  Well, I wanted to be clear on the conventions I had chosen, since parts of the course notes used $\hat{O} = \Norm{O^{i j}}$, and $X' = \hat{O} X$, and gave that matrix unit determinant.  That $O^{i j}$ looks like it is equivalent to my ${O^i}_j$, except that the one in the course notes is loose when it comes to lower and upper indices since it gives $(x')^i = O^{i j} x^j$.

I will write

\begin{equation}\label{eqn:relElectroDynProblemSet3:900}
\hat{O} = \Norm{{O^i}_j},
\end{equation}

and require this (not $\Norm{O^{i j}}$) to be the matrix with unit determinant.  Having cleared the index upper and lower confusion I had trying to reconcile the class notes with the rules for index manipulation, let us now consider the Lorentz transformation of a lower index rank 2 tensor (not necessarily antisymmetric or symmetric)

We have, transforming in the same fashion as a lower index coordinate four vector (but twice, once for each index)

\begin{equation}\label{eqn:relElectroDynProblemSet3:920}
A_{i j} \rightarrow 
A_{k m} 
{O_i}^k
{O_j}^m.
\end{equation}

The determinant of the transformation tensor ${O_i}^j$ is

\begin{equation}\label{eqn:relElectroDynProblemSet3:940}
\Det \Norm{ {O_i}^j } = 
\Det \Norm{ g^{i m} {O^m}_n g^{n j} } = (\Det \hat{G}) (1) (\Det \hat{G} ) = (-1)^2 (1) = 1.
\end{equation}

We see that the determinant of a lower index rank 2 tensor is invariant under Lorentz transformation.  This would include our characteristic polynomial $P(\lambda)$.

\subsubsection{Expanding the determinant}

Utilizing \eqnref{eqn:relElectroDynProblemSet3:660} we can now calculate the characteristic polynomial.  This is

\begin{align*}
\Det \Norm{F_{ij} - \lambda g_{ij} }
&= 
\inv{4!}
\epsilon^{s t u v} \epsilon^{a b c d} 
(F_{ a s } - \lambda g_{a s}) (F_{ b t } - \lambda g_{b t}) (F_{ c u } - \lambda g_{c u}) (F_{ d v } - \lambda g_{d v}) \\
&=
\inv{24}
\epsilon^{s t u v} \epsilon_{a b c d} 
({F^a}_s - \lambda {g^a}_s) ({F^b}_t - \lambda {g^b}_t) ({F^c}_u - \lambda {g^c}_u) ({F^d}_v - \lambda {g^d}_v) \\
\end{align*}

However, ${g^a}_b = g_{b c} g^{a c}$, or $\Norm{{g^a}_b} = \hat{G}^2 = I$.  This means we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:960}
{g^a}_b = {\delta^a}_b,
\end{equation}

and our determinant is reduced to

\begin{equation}\label{eqn:relElectroDynProblemSet3:961}
\begin{aligned}
P(\lambda) 
&=
\inv{24}
\epsilon^{s t u v} \epsilon_{a b c d} 
\Bigl({F^a}_s {F^b}_t - \lambda( {\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) + \lambda^2 {\delta^a}_s {\delta^b}_t \Bigr) \\
&\times \qquad \qquad \Bigl({F^c}_u {F^d}_v - \lambda( {\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u ) + \lambda^2 {\delta^c}_u {\delta^d}_v \Bigr) 
\end{aligned}
\end{equation}

If we expand this out we have our powers of $\lambda$ coefficients are

\begin{align*}
\lambda^0 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} 
{F^a}_s {F^b}_t {F^c}_u {F^d}_v 
\\
\lambda^1 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} 
\Bigl(
- ({\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u ) {F^a}_s {F^b}_t 
- ({\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) {F^c}_u {F^d}_v 
\Bigr) \\
\lambda^2 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} 
\Bigl(
{\delta^c}_u {\delta^d}_v {F^a}_s {F^b}_t 
+( {\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) ( {\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u ) 
+ {\delta^a}_s {\delta^b}_t  {F^c}_u {F^d}_v 
\Bigr) \\
\lambda^3 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} 
\Bigl(
- ( {\delta^a}_s {F^b}_t + {\delta^b}_t {F^a}_s ) {\delta^c}_u {\delta^d}_v 
- {\delta^a}_s {\delta^b}_t  ( {\delta^c}_u {F^d}_v + {\delta^d}_v {F^c}_u ) 
\Bigr) \\
\lambda^4 &:
\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} 
\Bigl(
{\delta^a}_s {\delta^b}_t {\delta^c}_u {\delta^d}_v 
\Bigr) \\
\end{align*}

By \eqnref{eqn:relElectroDynProblemSet3:660} the $\lambda^0$ coefficient is just $\Det \Norm{F_{i j}}$.

The $\lambda^3$ terms can be seen to be zero.  For example, the first one is

\begin{align*}
-\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} {\delta^a}_s {F^b}_t {\delta^c}_u {\delta^d}_v 
&=
-\inv{24} \epsilon^{s t u v} \epsilon_{s b u v} {F^b}_t \\
&=
-\inv{12} \delta^{t}_b {F^b}_t \\
&=
-\inv{12} {F^b}_b \\
&=
-\inv{12} F^{bu} g_{ub} \\
&= 0,
\end{align*}

where the final equality to zero comes from summing a symmetric and antisymmetric product.

Similarly the $\lambda$ coefficients can be shown to be zero.  Again the first as a sample is

\begin{align*}
-\inv{24} \epsilon^{s t u v} \epsilon_{a b c d} {\delta^c}_u {F^d}_v {F^a}_s {F^b}_t 
&=
-\inv{24} \epsilon^{u s t v} \epsilon_{u a b d} {F^d}_v {F^a}_s {F^b}_t  \\
&=
-\inv{24} 
\delta^{[s}_a
\delta^{t}_b
\delta^{v]}_d
{F^d}_v {F^a}_s {F^b}_t  \\
&=
-\inv{24} 
{F^a}_{[s}
{F^b}_{t}
{F^d}_{v]}
 \\
\end{align*}

Disregarding the $-1/24$ factor, let us just expand this antisymmetric sum

\begin{align*}
{F^a}_{[a}
{F^b}_{b}
{F^d}_{d]}
&=
{F^a}_{a}
{F^b}_{b}
{F^d}_{d}
+
{F^a}_{d}
{F^b}_{a}
{F^d}_{b}
+
{F^a}_{b}
{F^b}_{d}
{F^d}_{a} \\
&\qquad -
{F^a}_{a}
{F^b}_{d}
{F^d}_{b}
-
{F^a}_{d}
{F^b}_{b}
{F^d}_{a}
-
{F^a}_{b}
{F^b}_{a}
{F^d}_{d} \\
&=
{F^a}_{d}
{F^b}_{a}
{F^d}_{b}
+
{F^a}_{b}
{F^b}_{d}
{F^d}_{a} \\
\end{align*}

Of the two terms above that were retained, they are the only ones without a zero ${F^i}_i$ factor.  Consider the first part of this remaining part of the sum.  Employing the metric tensor, to raise indices so that the antisymmetry of $F^{ij}$ can be utilized, and then finally relabeling all the dummy indices we have

\begin{align*}
{F^a}_{d}
{F^b}_{a}
{F^d}_{b}
&=
F^{a u}
F^{b v}
F^{d w}
g_{d u}
g_{a v}
g_{b w} \\
&=
(-1)^3
F^{u a}
F^{v b}
F^{w d}
g_{d u}
g_{a v}
g_{b w} \\
&=
-
(F^{u a}
g_{a v})
(F^{v b}
g_{b w} 
)
(F^{w d}
g_{d u})
\\
&=
-
{F^u}_v
{F^v}_w
{F^w}_u
\\
&=
-
{F^a}_b
{F^b}_d
{F^d}_a
\\
\end{align*}

This is just the negative of the second term in the sum, leaving us with zero.

Finally, we have for the $\lambda^2$ coefficient ($\times 24$)

\begin{align*}
&
\epsilon^{s t u v} \epsilon_{a b c d} 
\Bigl(
{\delta^c}_u {\delta^d}_v {F^a}_s {F^b}_t 
+{\delta^a}_s {F^b}_t {\delta^c}_u {F^d}_v 
+{\delta^b}_t {F^a}_s {\delta^d}_v {F^c}_u  \\
&\qquad +{\delta^b}_t {F^a}_s {\delta^c}_u {F^d}_v 
+{\delta^a}_s {F^b}_t {\delta^d}_v {F^c}_u 
+ {\delta^a}_s {\delta^b}_t  {F^c}_u {F^d}_v 
\Bigr) \\
&=
\epsilon^{s t u v} \epsilon_{a b u v}   {F^a}_s {F^b}_t 
+
\epsilon^{s t u v} \epsilon_{s b u d}  {F^b}_t  {F^d}_v 
+
\epsilon^{s t u v} \epsilon_{a t c v}  {F^a}_s  {F^c}_u  \\
&\qquad +
\epsilon^{s t u v} \epsilon_{a t u d}  {F^a}_s  {F^d}_v 
+
\epsilon^{s t u v} \epsilon_{s b c v}  {F^b}_t  {F^c}_u 
+ 
\epsilon^{s t u v} \epsilon_{s t c d}    {F^c}_u {F^d}_v \\
&=
\epsilon^{s t u v} \epsilon_{a b u v}   {F^a}_s {F^b}_t 
+
\epsilon^{t v s u } \epsilon_{b d s u}  {F^b}_t  {F^d}_v 
+
\epsilon^{s u t v} \epsilon_{a c t v}  {F^a}_s  {F^c}_u  \\
&\qquad +
\epsilon^{s v t u} \epsilon_{a d t u}  {F^a}_s  {F^d}_v 
+
\epsilon^{t u s v} \epsilon_{b c s v}  {F^b}_t  {F^c}_u 
+ 
\epsilon^{u v s t} \epsilon_{c d s t}    {F^c}_u {F^d}_v \\
&=
6
\epsilon^{s t u v} \epsilon_{a b u v} {F^a}_s {F^b}_t  \\
&=
6 (2)
{\delta^{[s}}_a
{\delta^{t]}}_b
{F^a}_s {F^b}_t  \\
&=
12
{F^a}_{[a} {F^b}_{b]}  \\
&=
12( {F^a}_{a} {F^b}_{b} - {F^a}_{b} {F^b}_{a} ) \\
&=
-12 {F^a}_{b} {F^b}_{a} \\
&=
-12 F^{a b} F_{b a} \\
&=
12 F^{a b} F_{a b}
\end{align*}

Therefore, our characteristic polynomial is
\begin{equation}\label{eqn:relElectroDynProblemSet3:980}
\myBoxed{
P(\lambda) = \Det \Norm{F_{i j}} + \frac{\lambda^2}{2} F^{a b} F_{a b} + \lambda^4.
}
\end{equation}

Observe that in matrix form our strength tensors are

\begin{align}\label{eqn:relElectroDynProblemSet3:1000}
\Norm{ F^{ij} } &= 
\begin{bmatrix}
0 & -E_x & -E_y & -E_z \\
E_x & 0 & -B_z & B_y \\
E_y & B_z & 0 & -B_x \\
E_z & -B_y & B_x & 0
\end{bmatrix} \\
\Norm{ F_{ij} } &= 
\begin{bmatrix}
0 & E_x & E_y & E_z \\
-E_x & 0 & -B_z & B_y \\
-E_y & B_z & 0 & -B_x \\
-E_z & -B_y & B_x & 0
\end{bmatrix}.
\end{align}

From these we can compute $F^{a b} F_{a b}$ easily by inspection

\begin{equation}\label{eqn:relElectroDynProblemSet3:1020}
F^{a b} F_{a b} = 2 (\BB^2 - \BE^2).
\end{equation}

Computing the determinant is not so easy.  The dumb and simple way of expanding by cofactors takes two pages, and yields eventually 

\begin{equation}\label{eqn:relElectroDynProblemSet3:1040}
\Det \Norm{ F^{i j} } = (\BE \cdot \BB)^2.
\end{equation}

That supplies us with a relation for the characteristic polynomial in $\BE$ and $\BB$

\begin{equation}\label{eqn:relElectroDynProblemSet3:980b}
\myBoxed{
P(\lambda) = (\BE \cdot \BB)^2 + \lambda^2 (\BB^2 - \BE^2) + \lambda^4.
}
\end{equation}

Observe that we found this for the special case where $\BE$ and $\BB$ were perpendicular in homework 2.  Observe that when we have that perpendicularity, we can solve for the eigenvalues by inspection

\begin{equation}\label{eqn:relElectroDynProblemSet3:1060}
\lambda \in \{ 0, 0, \pm \sqrt{ \BE^2 - \BB^2 } \},
\end{equation}

and were able to diagonalize the matrix ${F^{i}}_j$ to solve the Lorentz force equation in parametric form.  When $\Abs{\BE} > \Abs{\BB}$ we had real eigenvalues and an orthogonal diagonalization when $\BB = 0$.  For the $\Abs{\BB} > \Abs{\BE}$, we had a two purely imaginary eigenvalues, and when $\BE = 0$ this was a Hermitian diagonalization.  For the general case, when one of $\BE$, or $\BB$ was zero, things did not have the same nice closed form solution.

In general our eigenvalues are

\begin{equation}\label{eqn:relElectroDynProblemSet3:1080}
\lambda = \pm \inv{\sqrt{2}} \sqrt{ \BE^2 - \BB^2 \pm \sqrt{ (\BE^2 - \BB^2)^2 - 4 (\BE \cdot \BB)^2 }}.
\end{equation}

For the purposes of this problem we really only wish to show that $\BE \cdot \BB$ and $\BE^2 - \BB^2$ are Lorentz invariants.  When $\lambda = 0$ we have $P(\lambda) = (\BE \cdot \BB)^2$, a Lorentz invariant.  This must mean that $\BE \cdot \BB$ is itself a Lorentz invariant.  Since that is invariant, and we require $P(\lambda)$ to be invariant for any other possible values of $\lambda$, the difference $\BE^2 - \BB^2$ must also be Lorentz invariant.

\subsection{7. Statement.  Show that the pseudoscalar invariant has only boundary effects}

Use integration by parts to show that $\int d^4 x \epsilon^{i j k l} F_{ i j } F_{ k l }$ only depends on the values of $A^i(x)$ at the ``boundary'' of spacetime (e.g. the ``surface'' depicted on page 105 of the notes) and hence does not affect the equations of motion for the electromagnetic field.

\subsection{7. Solution}

This proceeds in a fairly straightforward fashion

\begin{align*}
\int d^4 x \epsilon^{i j k l} F_{ i j } F_{ k l }
&=
\int d^4 x \epsilon^{i j k l} (\partial_i A_j - \partial_j A_i) F_{ k l } \\
&=
\int d^4 x 
\epsilon^{i j k l} (\partial_i A_j) F_{ k l } 
-\epsilon^{j i k l} (\partial_i A_j) F_{ k l } \\
&=
2 \int d^4 x 
\epsilon^{i j k l} (\partial_i A_j) F_{ k l } \\
&=
2 \int d^4 x 
\epsilon^{i j k l} \left( 
\PD{x^i}{}(A_j F_{ k l }
-A_j \PD{x^i}{ F_{ k l } }
\right)
\\
\end{align*}

Now, observe that by the Bianchi identity, this second term is zero

\begin{equation}\label{eqn:relElectroDynProblemSet3:1100}
\epsilon^{i j k l} \PD{x^i}{ F_{ k l } }
=
-\epsilon^{j i k l} \partial_i F_{ k l } = 0
\end{equation}

Now we have a set of perfect differentials, and can integrate

\begin{align*}
\int d^4 x \epsilon^{i j k l} F_{ i j } F_{ k l }
&= 
2 \int d^4 x 
\epsilon^{i j k l} 
\PD{x^i}{}(A_j F_{ k l })
\\
&= 
2 \int dx^j dx^k dx^l
\epsilon^{i j k l} 
\evalbar{(A_j F_{ k l })}{\Delta x^i}
\\
\end{align*}

We are left with a only contributions to the integral from the boundary terms on the spacetime hypervolume, three-volume normals bounding the four-volume integration  in the original integral.

\subsection{8. Statement.  Electromagnetic duality transformations}

Show that the Maxwell equations in vacuum are invariant under the transformation: $F_{i j} \rightarrow \tilde{F}_{i j}$, where $\tilde{F}_{i j} = \inv{2} \epsilon_{i j k l} F^{k l}$ is the dual electromagnetic stress tensor.  Replacing $F$ with $\tilde{F}$ is known as ``electric-magnetic duality''.  Explain this name by considering the transformation in terms of $\BE$ and $\BB$.  Are the Maxwell equations with sources invariant under electric-magnetic duality transformations?

\subsection{8. Solution}

Let us first consider the explanation of the name.  First recall what the expansions are of $F_{i j}$ and $F^{i j}$ in terms of $\BE$ and $\BE$.  These are

\begin{align*}
F_{0 \alpha} 
&= \partial_0 A_\alpha - \partial_\alpha A_0 \\
&= -\inv{c} \PD{t}{A^\alpha} - \PD{x^\alpha}{\phi} \\
&= E_\alpha
\end{align*}

with $F^{0 \alpha} = -E^\alpha$, and $E^\alpha = E_\alpha$.

The magnetic field components are

\begin{align*}
F_{\beta \alpha} 
&= \partial_\beta A_\alpha - \partial_\alpha A_\beta \\
&= -\partial_\beta A^\alpha + \partial_\alpha A^\beta \\
&= \epsilon_{\alpha \beta \sigma} B^\sigma
\end{align*}

with $F^{\beta \alpha} = \epsilon^{\alpha \beta \sigma} B_\sigma$ and $B_\sigma = B^\sigma$.

Now let us expand the dual tensors.  These are

\begin{align*}
\tilde{F}_{0 \alpha} 
&=
\inv{2} \epsilon_{0 \alpha i j} F^{i j} \\
&=
\inv{2} \epsilon_{0 \alpha \beta \sigma} F^{\beta \sigma} \\
&=
\inv{2} \epsilon_{0 \alpha \beta \sigma} \epsilon^{\sigma \beta \mu} B_\mu \\
&=
-\inv{2} \epsilon_{0 \alpha \beta \sigma} \epsilon^{\mu \beta \sigma} B_\mu \\
&=
-\inv{2} (2!) {\delta_\alpha}^\mu B_\mu \\
&=
- B_\alpha \\
\end{align*}

and

\begin{align*}
\tilde{F}_{\beta \alpha} 
&=
\inv{2} \epsilon_{\beta \alpha i j} F^{i j} \\
&=
\inv{2} \left(
\epsilon_{\beta \alpha 0 \sigma} F^{0 \sigma} 
+\epsilon_{\beta \alpha \sigma 0} F^{\sigma 0} 
\right) \\
&=
\epsilon_{0 \beta \alpha \sigma} (-E^\sigma) \\
&=
\epsilon_{\alpha \beta \sigma} E^\sigma
\end{align*}

Summarizing we have

\begin{align}\label{eqn:relElectroDynProblemSet3:1120}
F_{0 \alpha} &= E^\alpha \\
F^{0 \alpha} &= -E^\alpha \\
F^{\beta \alpha} &= F_{\beta \alpha} = \epsilon_{\alpha \beta \sigma} B^\sigma \\
\tilde{F}_{0 \alpha} &= - B_\alpha \\
\tilde{F}^{0 \alpha} &= B_\alpha \\
\tilde{F}_{\beta \alpha} &= \tilde{F}^{\beta \alpha} = \epsilon_{\alpha \beta \sigma} E^\sigma
\end{align}

Is there a sign error in the $\tilde{F}_{0 \alpha} = - B_\alpha$ result?  Other than that we have the same sort of structure for the tensor with $E$ and $B$ switched around.

Let us write these in matrix form, to compare

\begin{equation}\label{eqn:relElectroDynProblemSet3:1140}
\begin{array}{l l l l}
\Norm{ \tilde{F}_{i j} } &= 
\begin{bmatrix}
0 & -B_x & -B_y & -B_z \\
B_x & 0 & -E_z & E_y \\
B_y & E_z & 0 & E_x \\
B_z & -E_y & -E_x & 0 \\
\end{bmatrix} 
& \Norm{ \tilde{F}^{i j} } &= 
\begin{bmatrix}
0 & B_x & B_y & B_z \\
-B_x & 0 & -E_z & E_y \\
-B_y & E_z & 0 & -E_x \\
-B_z & -E_y & E_x & 0 \\
\end{bmatrix} \\
\Norm{ F^{ij} } &= 
\begin{bmatrix}
0 & -E_x & -E_y & -E_z \\
E_x & 0 & -B_z & B_y \\
E_y & B_z & 0 & -B_x \\
E_z & -B_y & B_x & 0
\end{bmatrix} 
& \Norm{ F_{ij} } &= 
\begin{bmatrix}
0 & E_x & E_y & E_z \\
-E_x & 0 & -B_z & B_y \\
-E_y & B_z & 0 & -B_x \\
-E_z & -B_y & B_x & 0
\end{bmatrix}.
\end{array}
\end{equation}

From these we can see by inspection that we have
\begin{equation}\label{eqn:relElectroDynProblemSet3:1160}
\tilde{F}^{i j} F_{ij} = \tilde{F}_{i j} F^{ij} = 4 (\BE \cdot \BB)
\end{equation}

This is consistent with the stated result in \citep{wiki:electromagneticTensor} (except for a factor of $c$ due to units differences), so it appears the signs above are all kosher.

Now, let us see if the if the dual tensor satisfies the vacuum equations.  

\begin{align*}
\partial_j \tilde{F}^{i j}
&=
\partial_j \inv{2} \epsilon^{i j k l} F_{k l} \\
&=
\inv{2} \epsilon^{i j k l} \partial_j (\partial_k A_l - \partial_l A_k) \\
&=
\inv{2} \epsilon^{i j k l} \partial_j \partial_k A_l - \inv{2} \epsilon^{i j l k} \partial_k A_l \\
&=
\inv{2} (\epsilon^{i j k l} - \epsilon^{i j k l} \partial_k A_l \\
&= 0 \qquad\square
\end{align*}

So the first checks out, provided we have no sources.  If we have sources, then we see here that Maxwell's equations do not hold since this would imply that the four current density must be zero.

How about the Bianchi identity?  That gives us

\begin{align*}
\epsilon^{i j k l} \partial_j \tilde{F}_{k l} 
&=
\epsilon^{i j k l} \partial_j \inv{2} \epsilon_{k l a b} F^{a b} \\
&=
\inv{2} \epsilon^{k l i j} \epsilon_{k l a b} \partial_j F^{a b} \\
&=
\inv{2} (2!) {\delta^i}_{[a} {\delta^j}_{b]} \partial_j F^{a b} \\
&=
\partial_j (F^{i j} - F^{j i} ) \\
&=
2 \partial_j F^{i j} .
\end{align*}

The factor of two is slightly curious.  Is there a mistake above?  If there is a mistake, it does not change the fact that Maxwell's equation

\begin{equation}\label{eqn:relElectroDynProblemSet3:1200}
\partial_k F^{k i} = \frac{4 \pi}{c} j^i
\end{equation}

Gives us zero for the Bianchi identity under source free conditions of $j^i = 0$.

\input{problems/relElectroDynProblemSet3TwoInternals}

\section{Problem 3.  Continuity equation for delta function current distributions}

\subsection{Statement}

Show explicitly that the electromagnetic 4-current $j^i$ for a particle moving with constant velocity (considered in class, p. 100-101 of notes) is conserved $\partial_i j^i = 0$.  Give a physical interpretation of this conservation law, for example by integrating $\partial_i j^i$ over some spacetime region and giving an integral form to the conservation law ($\partial_i j^i = 0$ is known as the ``continuity equation'').

\subsection{Solution}

First lets review.  Our four current was defined as

\begin{equation}\label{eqn:relElectroDynProblemSet3:1900}
j^i(x) = \sum_A c e_A \int_{x(\tau)} dx_A^i(\tau) \delta^4(x - x_A(\tau)).
\end{equation}

If each of the trajectories $x_A(\tau)$ represents constant motion we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:1920}
x_A(\tau) = x_A(0) + \gamma_A \tau ( c, \Bv_A ).
\end{equation}

The spacetime split of this four vector is

\begin{align}\label{eqn:relElectroDynProblemSet3:1940}
x_A^0(\tau) &= x_A^0(0) + \gamma_A \tau c \\
\Bx_A(\tau) &= \Bx_A(0) + \gamma_A \tau \Bv,
\end{align}

with differentials

\begin{align}\label{eqn:relElectroDynProblemSet3:1960}
dx_A^0(\tau) &= \gamma_A d\tau c \\
d\Bx_A(\tau) &= \gamma_A d\tau \Bv_A.
\end{align}

Writing out the delta functions explicitly we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:1980}
\begin{aligned}
j^i(x) = \sum_A &c e_A \int_{x(\tau)} dx_A^i(\tau) 
\delta(x^0 - x_A^0(0) - \gamma_A c \tau) 
\delta(x^1 - x_A^1(0) - \gamma_A v_A^1 \tau) \\
&\delta(x^2 - x_A^2(0) - \gamma_A v_A^2 \tau) 
\delta(x^3 - x_A^3(0) - \gamma_A v_A^3 \tau)
\end{aligned}
\end{equation}

So our time and space components of the current can be written

\begin{align}\label{eqn:relElectroDynProblemSet3:2000}
j^0(x) &= \sum_A c^2 e_A \gamma_A \int_{x(\tau)} d\tau
\delta(x^0 - x_A^0(0) - \gamma_A c \tau)
\delta^3(\Bx - \Bx_A(0) - \gamma_A \Bv_A \tau) \\
\Bj(x) &= \sum_A c e_A \Bv_A \gamma_A \int_{x(\tau)} d\tau
\delta(x^0 - x_A^0(0) - \gamma_A c \tau)
\delta^3(\Bx - \Bx_A(0) - \gamma_A \Bv_A \tau).
\end{align}

Each of these integrals can be evaluated with respect to the time coordinate delta function leaving the distribution

\begin{align}\label{eqn:relElectroDynProblemSet3:2020}
j^0(x) &= \sum_A c e_A 
\delta^3(\Bx - \Bx_A(0) - \frac{\Bv_A}{c} (x^0 - x_A^0(0))) \\
\Bj(x) &= \sum_A e_A \Bv_A 
\delta^3(\Bx - \Bx_A(0) - \frac{\Bv_A}{c} (x^0 - x_A^0(0)))
\end{align}

With this more general expression (multi-particle case) it should be possible to show that the four divergence is zero, however, the problem only asks for one particle.  For the one particle case, we can make things really easy by taking the initial point in space and time as the origin, and aligning our velocity with one of the coordinates (say $x$).

Doing so we have the result derived in class

\begin{equation}\label{eqn:relElectroDynProblemSet3:2040}
j = e 
\begin{bmatrix}
c \\
v \\
0 \\
0 
\end{bmatrix}
\delta(x - v x^0/c)
\delta(y)
\delta(z).
\end{equation}

Our divergence then has only two portions

\begin{align}\label{eqn:relElectroDynProblemSet3:2060}
\PD{x^0}{j^0} &= e c (-v/c) \delta'(x - v x^0/c) \delta(y) \delta(z) \\
\PD{x}{j^1} &= e v \delta'(x - v x^0/c) \delta(y) \delta(z).
\end{align}

and these cancel out when summed.  Note that this requires us to be loose with our delta functions, treating them like regular functions that are differentiable.

For the more general multiparticle case, we can treat the sum one particle at a time, and in each case, rotate coordinates so that the four divergence only picks up one term.

As for physical interpretation via integral, we have using the four dimensional divergence theorem

\begin{equation}\label{eqn:relElectroDynProblemSet3:2080}
\int d^4 x \partial_i j^i = \int j^i dS_i
\end{equation}

where $dS_i$ is the three-volume element perpendicular to a $x^i = \text{constant}$ plane.  These volume elements are detailed generally in the text \citep{landau1980classical}, however, they do note that one special case specifically $dS_0 = dx dy dz$, the element of the three-dimensional (spatial) volume ``normal'' to hyperplanes $ct = \text{constant}$.

Without actually computing the determinants, we have something that is roughly of the form

\begin{equation}\label{eqn:relElectroDynProblemSet3:2100}
0 
= \int j^i dS_i
=
\int c \rho dx dy dz
+\int \Bj \cdot (\Bn_x c dt dy dz + \Bn_y c dt dx dz + \Bn_z c dt dx dy).
\end{equation}

This is cheating a bit to just write $\Bn_x, \Bn_y, \Bn_z$.  Are there specific orientations required by the metric?  One way to be precise about this would be calculate the determinants detailed in the text, and then do the duality transformations.

Per unit time, we can write instead
\begin{equation}\label{eqn:relElectroDynProblemSet3:2120}
\PD{t}{} \int \rho dV
= -\int \Bj \cdot (\Bn_x dy dz + \Bn_y dx dz + \Bn_z dx dy)
\end{equation}

Rather loosely this appears to roughly describe that the rate of change of charge in a volume must be matched with the ``flow'' of current through the surface within that amount of time.

\section{Notes on grading of my solution}

Problem 2 was the graded problem.  I lost two marks.  One for \eqnref{eqn:relElectroDynProblemSet3:1460} where he wanted primes on the variables

\begin{align}\label{eqn:relElectroDynProblemSet3:1460b}
\BE' &= \frac{q}{{r'}^3}(x', \gamma y', \gamma z') \\
\BB' &= \gamma \frac{q v}{c {r'}^3} ( 0, -z', y' ),
\end{align}

however, I do not think that is correct.  Compare to problem set 2, problem 3, where this exactly matches the expected result, yet is only correct when the variables are the unprimed ones?

FIXME: Talk to Simon to see what he means.

Also, immediately before \eqnref{eqn:relElectroDynProblemSet3:1860} he underlined ``one velocity (not unique)'', and put an X beside it.
  
FIXME: is all that logic before \eqnref{eqn:relElectroDynProblemSet3:1860} wrong? (because that shows the boost velocity is not unique).  If I try the very simplest boost applied to the $\BE = E \Be_2$ and $\BB = B \Be_3$ I find a very different result (with no square root).  I think I am guilty of trying to be too general and not going back and checking for the simplest case.  Even so, where are my errors?
