%\documentclass[]{eliblog}
%\usepackage{color}
%\usepackage{txfonts} % for xi
%\input{../peeters_macros.tex}

\input{../peeter_prologue_print.tex}
\author{Peeter Joot}
\email{peeter.joot@utoronto.ca, 920798560}

\chapter{PHY450H1S Problem Set 3.}
\label{chap:relElectroDynProblemSet3}
%\blogpage{http://sites.google.com/site/peeterjoot/math2011/relElectroDynProblemSet3.pdf}
\date{Feb 15, 2011}
\revisionInfo{relElectroDynProblemSet3.tex}

\beginArtNoToc
%\beginArtWithToc
%\section{Disclaimer.}
%
%This problem set is as yet ungraded.

\section{Problem 1.  Fun with $\epsilon_{\alpha\beta\gamma}$, $\epsilon^{ijkl}$, $F_{ij}$, and the duality of Maxwell's equations in vacuum.}

\subsection{1. Statement}

Prove that

\begin{equation}\label{eqn:relElectroDynProblemSet3:10}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\delta_{\alpha\mu} \delta_{\beta\nu}
-\delta_{\alpha\nu} \delta_{\beta\mu}
\end{equation}

and use it to find the familar relation for

\begin{equation}\label{eqn:relElectroDynProblemSet3:30}
(\BA \cross \BB) \cdot (\BC \cross \BD)
\end{equation}

Also show that

\begin{equation}\label{eqn:relElectroDynProblemSet3:50}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
=
2 \delta_{\alpha\mu}.
\end{equation}

(Einstein summation implied all throughout this problem).

\subsection{1. Solution}

We can explicitly expand the (implied) sum over indexes $\gamma$.  This is

\begin{equation}\label{eqn:relElectroDynProblemSet3:70}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\epsilon_{\alpha \beta 1} \epsilon_{\mu \nu 1}
+\epsilon_{\alpha \beta 2} \epsilon_{\mu \nu 2}
+\epsilon_{\alpha \beta 3} \epsilon_{\mu \nu 3}
\end{equation}

For any $\alpha \ne \beta$ only one term is non-zero.  For example with $\alpha,\beta = 2,3$, we have just a contribution from the $\gamma = 1$ part of the sum

\begin{equation}\label{eqn:relElectroDynProblemSet3:90}
\epsilon_{2 3 1} \epsilon_{\mu \nu 1}.
\end{equation}

The value of this for $(\mu,\nu) = (\alpha,\beta)$ is

\begin{equation}\label{eqn:relElectroDynProblemSet3:110}
(\epsilon_{2 3 1})^2
\end{equation}

whereas for $(\mu,\nu) = (\beta,\alpha)$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:130}
-(\epsilon_{2 3 1})^2
\end{equation}

Our sum has value one when $(\alpha, \beta)$ matches $(\mu, \nu)$, and value minus one for when $(\mu, \nu)$ are permuted.  We can summarize this, by saying that when $\alpha \ne \beta$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:150}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \nu \gamma}
=
\delta_{\alpha\mu} \delta_{\beta\nu}
-\delta_{\alpha\nu} \delta_{\beta\mu} .
\end{equation}

However, observe that when $\alpha = \beta$ the RHS is

\begin{equation}\label{eqn:relElectroDynProblemSet3:170}
\delta_{\alpha\mu} \delta_{\alpha\nu}
-\delta_{\alpha\nu} \delta_{\alpha\mu} = 0,
\end{equation}

as desired, so this form works in general without any $\alpha \ne \beta$ qualifier, completing this part of the problem.

\begin{align*}
(\BA \cross \BB) \cdot (\BC \cross \BD)
&=
(\epsilon_{\alpha \beta \gamma} \Be^\alpha A^\beta B^\gamma ) \cdot
(\epsilon_{\mu \nu \sigma} \Be^\mu C^\nu D^\sigma ) \\
&=
\epsilon_{\alpha \beta \gamma} A^\beta B^\gamma
\epsilon_{\alpha \nu \sigma} C^\nu D^\sigma \\
&=
(
\delta_{\beta \nu} \delta_{\gamma\sigma}
-\delta_{\beta \sigma} \delta_{\gamma\nu} )
A^\beta B^\gamma
C^\nu D^\sigma \\
&=
A^\nu B^\sigma
C^\nu D^\sigma
-A^\sigma B^\nu
C^\nu D^\sigma.
\end{align*}

This gives us
\begin{equation}\label{eqn:relElectroDynProblemSet3:190}
(\BA \cross \BB) \cdot (\BC \cross \BD)
=
(\BA \cdot \BC)
(\BB \cdot \BD)
-
(\BA \cdot \BD)
(\BB \cdot \BC).
\end{equation}

We have one more identity to deal with.

\begin{equation}\label{eqn:relElectroDynProblemSet3:210}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
\end{equation}

We can expand out this (implied) sum slow and dumb as well

\begin{align*}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
&=
\epsilon_{\alpha 1 2} \epsilon_{\mu 1 2}
+\epsilon_{\alpha 2 1} \epsilon_{\mu 2 1} \\
&+\epsilon_{\alpha 1 3} \epsilon_{\mu 1 3}
+\epsilon_{\alpha 3 1} \epsilon_{\mu 3 1} \\
&+\epsilon_{\alpha 2 3} \epsilon_{\mu 2 3}
+\epsilon_{\alpha 3 2} \epsilon_{\mu 3 2} \\
&=
2 \epsilon_{\alpha 1 2} \epsilon_{\mu 1 2}
+ 2 \epsilon_{\alpha 1 3} \epsilon_{\mu 1 3}
+ 2 \epsilon_{\alpha 2 3} \epsilon_{\mu 2 3}
\end{align*}

Now, observe that for any $\alpha \in (1,2,3)$ only one term of this sum is picked up.  For example, with no loss of generality, pick $\alpha = 1$.  We are left with only

\begin{equation}\label{eqn:relElectroDynProblemSet3:230}
2 \epsilon_{1 2 3} \epsilon_{\mu 2 3}
\end{equation}

This has the value
\begin{equation}\label{eqn:relElectroDynProblemSet3:250}
2 (\epsilon_{1 2 3})^2 = 2
\end{equation}

when $\mu = \alpha$ and is zero otherwise.  We can therefore summarize the evaluation of this sum as 

\begin{equation}\label{eqn:relElectroDynProblemSet3:270}
\epsilon_{\alpha \beta \gamma}
\epsilon_{\mu \beta \gamma}
=  2\delta_{\alpha\mu},
\end{equation}

completing this problem.

\subsection{2. Statement}

Prove that for any $3 \times 3$ matrix $\Norm{A_{\alpha\beta}}$: $\epsilon_{\mu\nu\lambda} A_{\alpha \mu} A_{\beta\nu} A_{\gamma\lambda} = \epsilon_{\alpha \beta \gamma} \Det A$ and that $\epsilon_{\alpha\beta\gamma} \epsilon_{\mu\nu\lambda} A_{\alpha \mu} A_{\beta\nu} A_{\gamma\lambda} = 6 \Det A$.  

\subsection{2. Solution}

In class Simon showed us how the first identity can be arrived at using the triple product $\Ba \cdot (\Bb \cross \Bc) = \Det(\Ba \Bb \Bc)$.  It occured to me later that I'd seen the identity to be proven in the context of Geometric Algebra, but hadn't recognized it in this tensor form.  Basically, a wedge product can be expanded in sums of determinants, and when the dimension of the space is the same as the vector, we have a pseudoscalar times the determinant of the components.

For example, in \R{2}, let's take the wedge product of a pair of vectors.  As preparation for the relativistic \R{4} case We won't require an orthonormal basis, but express the vector in terms of a reciprocal frame and the associated components

\begin{equation}\label{eqn:relElectroDynProblemSet3:290}
a = a^i e_i = a_j e^j
\end{equation}

where 
\begin{equation}\label{eqn:relElectroDynProblemSet3:310}
e^i \cdot e_j = {\delta^i}_j.
\end{equation}

When we get to the relativistic case, we can pick (but don't have to) the standard basis

\begin{align}\label{eqn:relElectroDynProblemSet3:330}
e_0 &= (1, 0, 0, 0) \\
e_1 &= (0, 1, 0, 0) \\
e_2 &= (0, 0, 1, 0) \\
e_3 &= (0, 0, 0, 1),
\end{align}

for which our reciprocal frame is implicitly defined by the metric
\begin{align}\label{eqn:relElectroDynProblemSet3:350}
e^0 &= (1, 0, 0, 0) \\
e^1 &= (0, -1, 0, 0) \\
e^2 &= (0, 0, -1, 0) \\
e^3 &= (0, 0, 0, -1).
\end{align}

Anyways.  Back to the problem.  Let's examine the \R{2} case.  Our wedge product in coordinates is

\begin{equation}\label{eqn:relElectroDynProblemSet3:370}
a \wedge b
=
a^i b^j (e_i \wedge e_j)
\end{equation}

Since there are only two basis vectors we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:390}
a \wedge b
=
(a^1 b^2 - a^2 b^1) e_1 \wedge e_2 = \Det \Norm{a^i b^j} (e_1 \wedge e_2).
\end{equation}

Our wedge product is a product of the determinant of the vector coordinates, times the \R{2} pseudoscalar $e_1 \wedge e_2$.

This doesn't look quite like the \R{3} relation that we want to prove, which had an antisymmetric tensor factor for the determinant.  Observe that we get the determinant by picking off the $e_1 \wedge e_2$ component of the bivector result (the only component in this case), and we can do that by dotting with $e^2 \cdot e^1$.  To get an antisymmetric tensor times the determinant, we have only to dot with a different pseudoscalar (one that differs by a possible sign due to permutation of the indexes).  That is

\begin{align*}
(e^t \wedge e^s) \cdot (a \wedge b)
&=
a^i b^j (e^t \wedge e^s) \cdot (e_i \wedge e_j) \\
&=
a^i b^j 
\left( {\delta^{s}}_i {\delta^{t}}_j 
-{\delta^{t}}_i {\delta^{s}}_j  \right) \\
&=
a^i b^j 
{\delta^{[t}}_j {\delta^{s]}}_i \\
&=
a^i b^j 
{\delta^{t}}_{[j} {\delta^{s}}_{i]} \\
&=
a^{[i} b^{j]}
{\delta^{t}}_{j} {\delta^{s}}_{i} \\
&=
a^{[s} b^{t]}
\end{align*}

Now, if we write $a^i = A^{1 i}$ and $b^j = A^{2 j}$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:410}
(e^t \wedge e^s) \cdot (a \wedge b)
= 
A^{1 s} A^{2 t} -A^{1 t} A^{2 s}
\end{equation}

We can write this in two different ways.  One of which is

\begin{equation}\label{eqn:relElectroDynProblemSet3:430}
A^{1 s} A^{2 t} -A^{1 t} A^{2 s} =
\epsilon^{s t} \Det A
\end{equation}

and the other of which is by introducing free indexes for $1$ and $2$, and summing antisymmetrically over these.  That is

\begin{equation}\label{eqn:relElectroDynProblemSet3:450}
A^{1 s} A^{2 t} -A^{1 t} A^{2 s} 
=
A^{a s} A^{b t} \epsilon_{a b}
\end{equation}

So, we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:470}
A^{a s} A^{b t} \epsilon_{a b} = \epsilon^{s t} \Det A,
\end{equation}

This result hold regardless of the metric for the space, and does not require that we were using an orthonormal basis.  When the metric is Euclidean and we have an orthonormal basis, then all the indexes can be dropped.

The \R{3} and \R{4} cases follow in exactly the same way, we just need more vectors in the wedge products.

For the \R{3} case we have

\begin{align*}
(e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c) 
&=
a^i b^j c^k 
(e^u \wedge e^t \wedge e^s) \cdot (e_i \wedge e_j \wedge e_k) \\
&=
a^i b^j c^k 
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i \\
&=
a^{[s} b^t c^{u]} 
\end{align*}

Again, with $a^i = A^{1 i}$ and $b^j = A^{2 j}$, and $c^k = A^{3 k}$ we have

\begin{equation}\label{eqn:relElectroDynProblemSet3:490}
(e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c) 
=
A^{1 i} A^{2 j} A^{3 k}
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i 
\end{equation}

and we can choose to write this in either form, resulting in the identity

\begin{equation}\label{eqn:relElectroDynProblemSet3:510}
\epsilon^{s t u} \Det A
=
A^{1 i} A^{2 j} A^{3 k}
{\delta^{[u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i 
=
\epsilon_{a b c} A^{a s} A^{b t} A^{c u}.
\end{equation}

The \R{4} case follows exactly the same way, and we have

\begin{align*}
(e^v \wedge e^u \wedge e^t \wedge e^s) \cdot ( a \wedge b \wedge c \wedge d) 
&=
a^i b^j c^k d^l
(e^v \wedge e^u \wedge e^t \wedge e^s) \cdot (e_i \wedge e_j \wedge e_k \wedge e_l) \\
&=
a^i b^j c^k d^l
{\delta^{[v}}_l
{\delta^{u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i \\
&=
a^{[s} b^t c^{u} d^{v]} 
\end{align*}

and we have again
\begin{equation}\label{eqn:relElectroDynProblemSet3:530}
\epsilon^{s t u v} \Det A
=
A^{1 i} A^{2 j} A^{3 k} A^{4 l}
{\delta^{[v}}_k
{\delta^{u}}_k
{\delta^{t}}_j
{\delta^{s]}}_i 
=
\epsilon_{a b c d} A^{a s} A^{b t} A^{c u} A^{d u}.
\end{equation}

This one is almost the identity to be established later in problem 1.4.  We have only to raise and lower some indexes to get that one.  Note that in the Minkowski standard basis above, because $s, t, u, v$ must be a permutation of $0,1,2,3$ for a non-zero result, we must have

\begin{equation}\label{eqn:relElectroDynProblemSet3:550}
\epsilon^{s t u v} = (-1)^3 (+1) \epsilon_{s t u v}.
\end{equation}

So raising and lowering the identity above gives us

\begin{equation}\label{eqn:relElectroDynProblemSet3:570}
-\epsilon_{s t u v} \Det A
=
\epsilon^{a b c d} A_{a s} A_{b t} A_{c u} A_{d u}.
\end{equation}

No sign changes were required for the indexes $a, b, c, d$, since they are paired.

Until we did the raising and lowering operations here, there was no specific metric required, so our first result \ref{eqn:relElectroDynProblemSet3:530} is the more general one.

\subsection{3. Statement}
\subsection{3. Solution}
\subsection{4. Statement}
\subsection{4. Solution}
\subsection{5. Statement}
\subsection{5. Solution}
\subsection{6. Statement}
\subsection{6. Solution}
\subsection{7. Statement}
\subsection{7. Solution}
\subsection{8. Statement}
\subsection{8. Solution}

\section{Problem 2.}
\subsection{1. Statement}
\subsection{1. Solution}
\subsection{2. Statement}
\subsection{2. Solution}

\section{Problem 3.}
\subsection{Statement}
\subsection{Solution}

%\EndArticle
\EndNoBibArticle
