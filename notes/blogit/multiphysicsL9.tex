%
% Copyright © 2014 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
% for template copy, run:
%
% ~/bin/ct multiphysicsL1  multiphysicsLectureN tl1
%
\input{../blogpost.tex}
\renewcommand{\basename}{multiphysicsL9}
\renewcommand{\dirname}{notes/ece1254/}
\newcommand{\keywords}{Condensed matter physics, ECE1254H}
\input{../peeter_prologue_print2.tex}

%\usepackage{kbordermatrix}

\beginArtNoToc
\generatetitle{ECE1254H Modeling of Multiphysics Systems.  Lecture 9: Conjugate gradient methods.  Taught by Prof.\ Piero Triverio}
%\chapter{Conjugate gradient methods}
\label{chap:multiphysicsL9}

\section{Disclaimer}

Peeter's lecture notes from class.  These may be incoherent and rough.

\section{Conjugate gradient convergence}

For \( k \ll n \), convergence orders are

\captionedTable{Convergence}{tab:multiphysicsL9:20}{
\begin{tabular}{|l|l|}
\hline
       & Full     \\ \hline
Direct & \(O(n^3)\)   \\ \hline
C.G.   & \(O(k n^2)\) \\ \hline
\end{tabular}
}

We define a matrix norm, similar to \( \Norm{ \Bx } = \sqrt{ \Bx^\T \Bx } \), with

\begin{equation}\label{eqn:multiphysicsL9:40}
\Norm{\Bx}_M \equiv \sqrt{ \Bx^\T M \Bx }.
\end{equation}

Note that our use of this is for CG which only applies to positive definite matrices (or it will not converge), so this norm is real valued.

... lots on slides...

\begin{equation}\label{eqn:multiphysicsL9:60}
K(M) = \frac
{\sigma_{\mathrm{max}}}
{\sigma_{\mathrm{min}}}
\end{equation}

... 

We need some fast ways to estimate the conditioning number.

\sectionAndIndex{Gershgorin circle theorem}

\maketheorem{Gershgorin circle theorem}{thm:multiphysicsL9:1}{
Given \( M \), for any eigenvalue of \( M \) there is an \( i \in [1, n] \) such that 

\begin{equation*}
\Abs{ \lambda - M_{i i} } \le \sum_{j \ne i} \Abs{ M_{i j} }
\end{equation*}
}

Consider this in the complex plane for row \( i \)

\begin{equation}\label{eqn:multiphysicsL9:80}
\begin{bmatrix}
M_{i 1} & 
M_{i 2} &  \cdots M_{i i} & \cdots M_{i n}
\end{bmatrix}
\end{equation}

This inequality covers a circular region in the complex plane as illustrated in

F1

These are called \textAndIndex{Gershgorin circles}.

\makeexample{Leaky bar}{example:multiphysicsL9:1}{
For the leaky bar of 

F2

Our matrix is

\begin{equation}\label{eqn:multiphysicsL9:100}
M = 
\begin{bmatrix}
2  & -1 &        &    &    \\
-1 & 3  & -1     &    &    \\
   & -1 & 3      & -1 &    \\
   &    &        & \ddots &    \\
   &    &        &    & -1     \\
   &    &        & -1 & 2    \\
\end{bmatrix}
\end{equation}

Our Gershgorin circles are

F3

We must then have

\begin{equation}\label{eqn:multiphysicsL9:120}
1 \le \lambda(M) \le 5,
\end{equation}

so that

\begin{equation}\label{eqn:multiphysicsL9:140}
K(M) = 
\frac{\lambda_{\mathrm{max}}}
{\lambda_{\mathrm{max}}} 
\le 5.
\end{equation}

On slides: example with smaller leakage to ground.
On slides: example with no leakage to ground.

These had, progressively larger and larger (possibly indefinite for the latter) conditioning number estimates.

The latter had the form of

\begin{equation}\label{eqn:multiphysicsL9:160}
M =
\begin{bmatrix}
     1  & -1  &  0  &  0 \\
    -1  &  2  & -1  &  0 \\
     0  & -1  &  2  &  1 \\
     0  &  0  & -1  &  1
\end{bmatrix}
\end{equation}

The exact eigenvalues for this system happens to be
\begin{equation}\label{eqn:multiphysicsL9:180}
\lambda \in
\{
 3.1069 
 0.2833,
 1.3049 + 0.7545i, 1.3049 - 0.7545i 
\}
\end{equation}

so the exact conditioning number is \( 3.1/0.28 \approx 11 \).

FIXME: compare to estimate.
}

\section{Preconditioning}

Goal is to take 

\begin{equation}\label{eqn:multiphysicsL9:280}
M \Bx = \Bb
\end{equation}

and introduce an easy to invert matrix \( P \) to change the problem to

\begin{equation}\label{eqn:multiphysicsL9:200}
P^{-1} M \Bx = P^{-1} \Bb.
\end{equation}

This system has the same solution, but we want to choose \( P \) to maximize the convergence speed.

\section{Symmetric preconditioning}

We want to precondition in a way that preserves the symmetric positive definite nature of the matrix so that we can continue to use congugate gradient methods.

Take \( P \) and split into square root factors

\begin{equation}\label{eqn:multiphysicsL9:220}
P = P^{1/2} P^{1/2},
\end{equation}

and apply to \( M \Bx = \Bb \) as

\begin{equation}\label{eqn:multiphysicsL9:240}
P^{-1/2} M 
\mathLabelBox{P^{-1/2} P^{1/2}}{\(= I\)} \Bx = P^{-1/2} \Bb.
\end{equation}

and introduce a change of variables \( \By = P^{1/2} \Bx \), so that we solve

\begin{equation}\label{eqn:multiphysicsL9:260}
P^{-1/2} M P^{-1/2} \By = \Bb'.
\end{equation}

Some options
\begin{itemize}
\item Diagonal preconditioner: \( \BP = \text{diag}\{M\} \)
\item Incomplete LU or Cholesky factorization.  Cheap, approximate decomposition where we pick \( M \simeq L U = P \).  An incomplete LU factorization would be easy to invert since lower or upper triangular matrices are easy to invert.  In matlab we can use the \( \text{ilu}() \) function to do an incomplete LU factorization.
\item ... (many preconditers are available).
\end{itemize}

For a symmetric positive definite matrix \( M \), we can compute a LU decomposition of the form \( M = L L^\T \), called the \textAndIndex{Cholesky factorization}.

Example:

F4

\section{Preconditioned conjugate gradient}

On slides.

We avoid the actually inverting the preconditioner by requiring that the LU decomposition of \( P \) be easily computed, so that we can solve 

\begin{equation}\label{eqn:multiphysicsL9:300}
P \Bz^k = \Br^k
\end{equation}

by successive forward and back substitution.

%\EndArticle
\EndNoBibArticle
